{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61668c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem\n",
    "from molvecgen.vectorizers import SmilesVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('small_molecules_smiles_only_for_deep_learning_sm_10032024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f4ca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:57:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:57:44] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>canon_smiles</th>\n",
       "      <th>Molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CC1(C)CCC(c2ccc(Cl)cc2)=C(CN2CCN(c3ccc(C(=O)NS...</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000020180D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CN(C)CC[C@H](CSc1ccccc1)Nc1ccc(S(=O)(=O)NC(=O)...</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000020180D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cc1ccc(F)c(NC(=O)Nc2ccc(-c3cccc4[nH]nc(N)c34)c...</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000020180D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>C[C@@]1(c2nc3c(C(N)=O)cccc3[nH]2)CCCN1</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000020180D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>CNC(=O)c1ccccc1Sc1ccc2c(/C=C/c3ccccn3)n[nH]c2c1</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000020180D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   good                                       canon_smiles  \\\n",
       "0     0  CC1(C)CCC(c2ccc(Cl)cc2)=C(CN2CCN(c3ccc(C(=O)NS...   \n",
       "1     0  CN(C)CC[C@H](CSc1ccccc1)Nc1ccc(S(=O)(=O)NC(=O)...   \n",
       "2     0  Cc1ccc(F)c(NC(=O)Nc2ccc(-c3cccc4[nH]nc(N)c34)c...   \n",
       "3     0             C[C@@]1(c2nc3c(C(N)=O)cccc3[nH]2)CCCN1   \n",
       "4     0    CNC(=O)c1ccccc1Sc1ccc2c(/C=C/c3ccccn3)n[nH]c2c1   \n",
       "\n",
       "                                            Molecule  \n",
       "0  <rdkit.Chem.rdchem.Mol object at 0x0000020180D...  \n",
       "1  <rdkit.Chem.rdchem.Mol object at 0x0000020180D...  \n",
       "2  <rdkit.Chem.rdchem.Mol object at 0x0000020180D...  \n",
       "3  <rdkit.Chem.rdchem.Mol object at 0x0000020180D...  \n",
       "4  <rdkit.Chem.rdchem.Mol object at 0x0000020180D...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(df, 'canon_smiles', 'Molecule')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15149899",
   "metadata": {},
   "outputs": [],
   "source": [
    "smivec = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec.fit(df.Molecule.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a8a914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z]oNu7.#e+)42\\(5t1cS-C@3HRsBMKPan/rF[I6l=O^$?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(275, 45)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(smivec.charset)\n",
    "smivec.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507d007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['good'].values.reshape((-1, 1)).astype(np.float32)  # Ensure y is float32\n",
    "X = df.Molecule.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "046aaa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183de984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class wraps the SMILES data and their corresponding labels into a format compatible with PyTorch 'DataLoader'.\n",
    "# It uses the SMILES vectorizer to convert the SMILES strings into numeric vectors during data retrieval\n",
    "\n",
    "class SMILESMolDataset(Dataset):\n",
    "    def __init__(self, molecules, y, vectorizer):\n",
    "        self.molecules = molecules\n",
    "        self.y = y\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.molecules)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        mols = self.molecules[idx]\n",
    "\n",
    "        # Transform the SMILES string into a vector\n",
    "        sample = self.vectorizer.transform([mols])[0]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        # Ensure sample is converted to float32\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "\n",
    "        return sample, torch.tensor(label, dtype=torch.float32)  # Also convert label to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cc2f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SMILESMolDataset(X_train, y_train, smivec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "031d31a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b7695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_t = smivec.transform(X_val, canonical=False)\n",
    "X_val_t = torch.tensor(X_val_t, device=device, dtype=torch.float32)  # Set dtype to float32\n",
    "y_val_t = torch.tensor(y_val, device=device, dtype=torch.float32)  # Set dtype to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d90eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dimensions, lstm_sizes, hidden_size, dropout_rate, out_size=1):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        number_tokens = dimensions[1]\n",
    "\n",
    "        # LSTM layers list\n",
    "        self.lstms = nn.ModuleList()\n",
    "\n",
    "        input_size = number_tokens\n",
    "        for lstm_size in lstm_sizes:\n",
    "            self.lstms.append(nn.LSTM(input_size=input_size, hidden_size=lstm_size, num_layers=1, batch_first=True))\n",
    "            input_size = lstm_size\n",
    "\n",
    "        # Only add dropout if there's more than 1 LSTM layer\n",
    "        if len(lstm_sizes) > 1:\n",
    "            self.dropouts = nn.Dropout(dropout_rate)\n",
    "        else:\n",
    "            self.dropouts = None  # No dropout needed for a single LSTM layer\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(lstm_sizes[-1], hidden_size)  # Hidden layer\n",
    "        self.activation = nn.ReLU()  # Activation function for hidden layer\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through LSTM layers\n",
    "        for lstm in self.lstms:\n",
    "            x, _ = lstm(x)\n",
    "\n",
    "        # Apply dropout if there is more than 1 LSTM layer\n",
    "        if self.dropouts:\n",
    "            x = self.dropouts(x)\n",
    "\n",
    "        # Use the last hidden state from the last LSTM layer\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        # Pass through the hidden layer and activation function\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Final output layer\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc3b94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50  # I can implement early stopping to halt training when the validation loss stops improving.\n",
    "dims = smivec.dims  # This is necessary to define the input dimensions. Ensure 'smivec.dims' returns the correct shape: '[sequence_length, number_tokens]'.\n",
    "lstm_size = [32, 16]  # The size of the LSTM hidden state. I may experiment with larger size (e.g., 256 or 512) if necessary.\n",
    "hidden_size = 64  # This number is a typical one. I'll adjust it based on the model's performance\n",
    "dropout_rate = 0.5  # A dropout rate of 0.5 is standard for preventing overfitting. I may reduce it to 0.3 if underfitting occurs.\n",
    "output_size = 1  # This is for binary classification, as the output is a single probability value.\n",
    "batch_size = 12  # A batch size of 128 is commonly used and generally effective. Depending on GPU memory, I may try different sizes (e.g., 64 or 256).\n",
    "learning_rate = 0.0005  # If the training is unstable, I'll lower it to 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8037b277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lstms): ModuleList(\n",
       "    (0): LSTM(45, 32, batch_first=True)\n",
       "    (1): LSTM(32, 16, batch_first=True)\n",
       "  )\n",
       "  (dropouts): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(dims, lstm_size, hidden_size, dropout_rate, output_size).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620c2dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe000299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Ensure y_train is a 1D array\n",
    "y_train_flat = np.ravel(y_train)  # Flatten y_train if needed\n",
    "\n",
    "# Compute class weights based on your labels\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_flat), y=y_train_flat)\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27678e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5118, 21.6000], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96309dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.6000, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e98d19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd7a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "\n",
    "# for pos_weight_value in custom_pos_weights:\n",
    "#     class_weights = torch.FloatTensor([1.0, pos_weight_value]).to(device)  # Set pos_weight for binary class\n",
    "\n",
    "#     # Define criterion with the chosen pos_weight\n",
    "#     criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#     lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     train_losses, validation_losses = [], []\n",
    "\n",
    "#     # Early stopping setup\n",
    "#     early_stopping_patience = 10\n",
    "#     best_val_loss = float('inf')\n",
    "#     epochs_without_improvement = 0\n",
    "\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         running_loss = 0.0\n",
    "#         model.train()\n",
    "        \n",
    "#         for smiles, labels in train_loader:\n",
    "#             smiles = smiles.clone().detach().float().to(device)\n",
    "#             labels = labels.clone().detach().float().to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(smiles)\n",
    "#             loss = criterion(output, labels)\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             running_loss += loss.item()\n",
    "        \n",
    "#         # Validation step\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             val_outputs = model(X_val_t)\n",
    "#             val_loss = criterion(val_outputs, y_val_t).item()\n",
    "        \n",
    "#         train_loss = running_loss / len(train_loader)\n",
    "#         train_losses.append(train_loss)\n",
    "#         validation_losses.append(val_loss)\n",
    "\n",
    "#         lr_scheduler.step(val_loss)\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             epochs_without_improvement = 0\n",
    "#             torch.save(model.state_dict(), f'best_model_pos_weight_{pos_weight_value}.pth')\n",
    "#         else:\n",
    "#             epochs_without_improvement += 1\n",
    "\n",
    "#         if epochs_without_improvement >= early_stopping_patience:\n",
    "#             print(f'Early stopping at epoch {epoch + 1}')\n",
    "#             break\n",
    "\n",
    "#         if (epoch + 1) % 2 == 0:\n",
    "#             print(f'Pos_weight: {pos_weight_value}, Epoch {epoch+1}, Training loss: {train_loss:.2f}, Validation loss: {val_loss:.2f}')\n",
    "        \n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     total_time = time.time() - start_time\n",
    "#     results[pos_weight_value] = {\n",
    "#         'train_losses': train_losses,\n",
    "#         'validation_losses': validation_losses,\n",
    "#         'best_val_loss': best_val_loss,\n",
    "#         'training_time': total_time / 60\n",
    "#     }\n",
    "#     print(f'Pos_weight: {pos_weight_value}, Total training time: {total_time/60:.2f} mins')\n",
    "\n",
    "# # After training, analyze results for each pos_weight\n",
    "# for pos_weight, result in results.items():\n",
    "#     print(f\"\\nPos_weight {pos_weight}: Best Validation Loss = {result['best_val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8e235",
   "metadata": {},
   "source": [
    "# Try to use optuna and ray for hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d316f31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using PyTorch\n",
    "import torch\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20ce8d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "num_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93b3c182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-10-26 10:14:18</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:17.36        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.4/29.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 1.0/24 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 25<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_254d63a4</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_254d63a4/error.txt</td></tr>\n",
       "<tr><td>train_model_3041666e</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_3041666e/error.txt</td></tr>\n",
       "<tr><td>train_model_49bf2b64</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_49bf2b64/error.txt</td></tr>\n",
       "<tr><td>train_model_d5c545d8</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_d5c545d8/error.txt</td></tr>\n",
       "<tr><td>train_model_6bf6bedc</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_6bf6bedc/error.txt</td></tr>\n",
       "<tr><td>train_model_88ec23b2</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_88ec23b2/error.txt</td></tr>\n",
       "<tr><td>train_model_317aff42</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_317aff42/error.txt</td></tr>\n",
       "<tr><td>train_model_98ec385a</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_98ec385a/error.txt</td></tr>\n",
       "<tr><td>train_model_3dcf099c</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_3dcf099c/error.txt</td></tr>\n",
       "<tr><td>train_model_5b058ad5</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_5b058ad5/error.txt</td></tr>\n",
       "<tr><td>train_model_75e89fa9</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_75e89fa9/error.txt</td></tr>\n",
       "<tr><td>train_model_9134b7d5</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_9134b7d5/error.txt</td></tr>\n",
       "<tr><td>train_model_ef02a77d</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_ef02a77d/error.txt</td></tr>\n",
       "<tr><td>train_model_010ada71</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_010ada71/error.txt</td></tr>\n",
       "<tr><td>train_model_4758663c</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_4758663c/error.txt</td></tr>\n",
       "<tr><td>train_model_f571f4c0</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_f571f4c0/error.txt</td></tr>\n",
       "<tr><td>train_model_9a1f2ab2</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_9a1f2ab2/error.txt</td></tr>\n",
       "<tr><td>train_model_12f8d419</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_12f8d419/error.txt</td></tr>\n",
       "<tr><td>train_model_1d04ba99</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_1d04ba99/error.txt</td></tr>\n",
       "<tr><td>train_model_46221966</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_46221966/error.txt</td></tr>\n",
       "<tr><td>train_model_d34d1d3c</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_d34d1d3c/error.txt</td></tr>\n",
       "<tr><td>train_model_909de791</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_909de791/error.txt</td></tr>\n",
       "<tr><td>train_model_0a9044e3</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_0a9044e3/error.txt</td></tr>\n",
       "<tr><td>train_model_2d68fb9d</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_2d68fb9d/error.txt</td></tr>\n",
       "<tr><td>train_model_5600e54c</td><td style=\"text-align: right;\">           1</td><td>C:/Users/mashu/AppData/Local/Temp/ray/session_2024-10-26_09-54-36_880554_16748/artifacts/2024-10-26_10-13-01/tune_experiment/driver_artifacts/trial_5600e54c/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  learning_rate</th><th>lstm_size         </th><th style=\"text-align: right;\">  pos_weight</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_caf928eb</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.735067</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">    0.000515552</td><td>[256, 128, 32]    </td><td style=\"text-align: right;\">          78</td></tr>\n",
       "<tr><td>train_model_254d63a4</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.233199</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">           32</td><td style=\"text-align: right;\">    0.00015945 </td><td>[256, 128, 64, 32]</td><td style=\"text-align: right;\">          16</td></tr>\n",
       "<tr><td>train_model_3041666e</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      0.314207</td><td style=\"text-align: right;\">      46</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.00647789 </td><td>[128, 64, 32]     </td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>train_model_49bf2b64</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      0.777264</td><td style=\"text-align: right;\">      35</td><td style=\"text-align: right;\">           32</td><td style=\"text-align: right;\">    0.00288229 </td><td>[256, 128, 64]    </td><td style=\"text-align: right;\">          63</td></tr>\n",
       "<tr><td>train_model_d5c545d8</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.617982</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">    0.00130186 </td><td>[64, 32]          </td><td style=\"text-align: right;\">           2</td></tr>\n",
       "<tr><td>train_model_6bf6bedc</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      0.207846</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">    0.00817566 </td><td>[256, 128, 32]    </td><td style=\"text-align: right;\">          79</td></tr>\n",
       "<tr><td>train_model_88ec23b2</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.259966</td><td style=\"text-align: right;\">      41</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.000142627</td><td>[32, 16]          </td><td style=\"text-align: right;\">           5</td></tr>\n",
       "<tr><td>train_model_317aff42</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.312665</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.000430994</td><td>[256, 128, 64]    </td><td style=\"text-align: right;\">          56</td></tr>\n",
       "<tr><td>train_model_98ec385a</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.238381</td><td style=\"text-align: right;\">      42</td><td style=\"text-align: right;\">           32</td><td style=\"text-align: right;\">    0.000155751</td><td>[256, 128, 32]    </td><td style=\"text-align: right;\">          13</td></tr>\n",
       "<tr><td>train_model_3dcf099c</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.223335</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.00683345 </td><td>[64, 32, 16]      </td><td style=\"text-align: right;\">          31</td></tr>\n",
       "<tr><td>train_model_5b058ad5</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.722947</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.000798159</td><td>[32, 16]          </td><td style=\"text-align: right;\">          47</td></tr>\n",
       "<tr><td>train_model_75e89fa9</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.646054</td><td style=\"text-align: right;\">      39</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">    0.00774166 </td><td>[256, 128, 64]    </td><td style=\"text-align: right;\">          57</td></tr>\n",
       "<tr><td>train_model_9134b7d5</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.619793</td><td style=\"text-align: right;\">      26</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.000105144</td><td>[128, 64, 32]     </td><td style=\"text-align: right;\">          26</td></tr>\n",
       "<tr><td>train_model_ef02a77d</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.268687</td><td style=\"text-align: right;\">      33</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.000157668</td><td>[256, 128, 32]    </td><td style=\"text-align: right;\">          53</td></tr>\n",
       "<tr><td>train_model_010ada71</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">      0.329667</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.00059538 </td><td>[64, 32, 16]      </td><td style=\"text-align: right;\">          31</td></tr>\n",
       "<tr><td>train_model_4758663c</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.528191</td><td style=\"text-align: right;\">      38</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.00306355 </td><td>[128, 64, 32]     </td><td style=\"text-align: right;\">          24</td></tr>\n",
       "<tr><td>train_model_f571f4c0</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.425262</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.000168401</td><td>[128, 64, 32]     </td><td style=\"text-align: right;\">          41</td></tr>\n",
       "<tr><td>train_model_9a1f2ab2</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.460329</td><td style=\"text-align: right;\">      41</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.000742705</td><td>[64, 32]          </td><td style=\"text-align: right;\">          17</td></tr>\n",
       "<tr><td>train_model_12f8d419</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.520596</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.00716445 </td><td>[64, 32, 16]      </td><td style=\"text-align: right;\">          98</td></tr>\n",
       "<tr><td>train_model_1d04ba99</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">      0.515689</td><td style=\"text-align: right;\">      42</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.00516555 </td><td>[128, 64, 32]     </td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>train_model_46221966</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">      0.232864</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.0008166  </td><td>[64, 32]          </td><td style=\"text-align: right;\">          24</td></tr>\n",
       "<tr><td>train_model_d34d1d3c</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.214687</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.00546064 </td><td>[128, 64, 32]     </td><td style=\"text-align: right;\">          40</td></tr>\n",
       "<tr><td>train_model_909de791</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.233314</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">    0.00212366 </td><td>[256, 128, 32]    </td><td style=\"text-align: right;\">           8</td></tr>\n",
       "<tr><td>train_model_0a9044e3</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.3698  </td><td style=\"text-align: right;\">      45</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">    0.00103098 </td><td>[32, 16]          </td><td style=\"text-align: right;\">          60</td></tr>\n",
       "<tr><td>train_model_2d68fb9d</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.396324</td><td style=\"text-align: right;\">      17</td><td style=\"text-align: right;\">           32</td><td style=\"text-align: right;\">    0.00189824 </td><td>[256, 128, 32]    </td><td style=\"text-align: right;\">          88</td></tr>\n",
       "<tr><td>train_model_5600e54c</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      0.396958</td><td style=\"text-align: right;\">      34</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">    0.00834032 </td><td>[64, 32]          </td><td style=\"text-align: right;\">          22</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (13 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:04,366\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_254d63a4\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 46d6b492aa4b24b14d832d6101000000\n",
      "\tpid: 25280\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff46d6b492aa4b24b14d832d6101000000 Worker ID: a83f2487245c384aaf06300228b8a72b00c405c523a7484231912c22 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53442 Worker PID: 25280 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:07,780\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_3041666e\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 0031030f6bbbb256d98f49f901000000\n",
      "\tpid: 11100\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:10,724\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_49bf2b64\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 4a334c45e7b4580dcfc94b1f01000000\n",
      "\tpid: 23096\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff0031030f6bbbb256d98f49f901000000 Worker ID: 1048036c854e3083cbc4697508195a8427da4dc5b3c5c69fd04e733a Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53457 Worker PID: 11100 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff4a334c45e7b4580dcfc94b1f01000000 Worker ID: a6bc246653c1b1221194f4b4933b768657c7be9afe30498f9d2c637e Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53471 Worker PID: 23096 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:13,425\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_d5c545d8\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 02c5da2863558af77892488c01000000\n",
      "\tpid: 18628\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:16,412\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_6bf6bedc\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: f20971f00dc2caf9c64de73f01000000\n",
      "\tpid: 17420\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff02c5da2863558af77892488c01000000 Worker ID: 1f0dc7b33aefafe93c8b26cd612a7c194b4d875b0908ba184852f020 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53489 Worker PID: 18628 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: fffffffffffffffff20971f00dc2caf9c64de73f01000000 Worker ID: 311e9dc791129324b3defc16ceec55195162b7d0fb9241181764ea09 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53503 Worker PID: 17420 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:19,311\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_88ec23b2\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 60669bb7e6cc5b398511112801000000\n",
      "\tpid: 21564\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:22,523\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_317aff42\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 474515a6978e95c7fa1a650901000000\n",
      "\tpid: 2816\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff60669bb7e6cc5b398511112801000000 Worker ID: 103369e4d997cb7c1c3f8c11e5d0b2b41f93d505eb811426b4bcdfcb Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53517 Worker PID: 21564 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff474515a6978e95c7fa1a650901000000 Worker ID: f0d9f68835a19cbe227da3270e27ea78fb75964e66e35f6ddd9aaadb Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53534 Worker PID: 2816 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:25,236\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_98ec385a\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: cd0563269cb8eade4b7b207c01000000\n",
      "\tpid: 404\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:28,397\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_3dcf099c\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: d3302fb3c75a1ebb94fcdc8101000000\n",
      "\tpid: 21948\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffcd0563269cb8eade4b7b207c01000000 Worker ID: 2f90c5b090a796bc476f5851851c1aed2e2ac745d735a7af85a95482 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53548 Worker PID: 404 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd3302fb3c75a1ebb94fcdc8101000000 Worker ID: e3bcb2e2f34c99545597eefd689f3c73d1341d7f747cab7e01296e06 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53564 Worker PID: 21948 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:31,450\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_5b058ad5\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 41041ad1a3c56a869b637b3801000000\n",
      "\tpid: 23080\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:34,360\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_75e89fa9\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 9c36bc3b9a66fd0d6568416801000000\n",
      "\tpid: 2264\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff41041ad1a3c56a869b637b3801000000 Worker ID: 87f1c3cc41fad5558392053b4ad3be68b99cdffb243f01f9993b076a Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53580 Worker PID: 23080 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff9c36bc3b9a66fd0d6568416801000000 Worker ID: cf975143c40dc7f079ae6bccdb30c100137c366594533a862f83d314 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53595 Worker PID: 2264 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:37,187\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_9134b7d5\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 3b6bf002c4883dd8dfdf607c01000000\n",
      "\tpid: 15480\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:40,505\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_ef02a77d\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: face9c5d4a847a5d689bb65d01000000\n",
      "\tpid: 21572\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff3b6bf002c4883dd8dfdf607c01000000 Worker ID: e78e83c3cfae3ab4b2136755b2eee4bf94149ed5f61a584b85edbd53 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53609 Worker PID: 15480 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffface9c5d4a847a5d689bb65d01000000 Worker ID: 1820c98ccf64dcdc676c4e56be6ccd1e3cbe37f1d2a4fbf4c6a43a5e Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53626 Worker PID: 21572 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:43,859\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_010ada71\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 058baf1d6a82c24f4583cba301000000\n",
      "\tpid: 5024\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:46,635\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_4758663c\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: bc1453e011e1072754810a4101000000\n",
      "\tpid: 21664\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff058baf1d6a82c24f4583cba301000000 Worker ID: 978b881e16ee2e04f4c8089bb55f9e670311b8b87c686b2a75520f36 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53640 Worker PID: 5024 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffbc1453e011e1072754810a4101000000 Worker ID: 08d08e6b8aa45e22611073d27368749f1b7f4a56e0f9eeedf7006fc0 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53654 Worker PID: 21664 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:49,432\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_f571f4c0\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 6281a068c56c21f12a55149601000000\n",
      "\tpid: 24636\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:52,175\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_9a1f2ab2\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 6c085876124a3569cb9758b501000000\n",
      "\tpid: 22640\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff6281a068c56c21f12a55149601000000 Worker ID: cf582869d6cce57e8409a421006ac4309b8b86f9f82f345b3882b5b9 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53669 Worker PID: 24636 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff6c085876124a3569cb9758b501000000 Worker ID: 451a3b3e9f7a67760efb86108d876c401138b409563e473eac510328 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53684 Worker PID: 22640 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:13:55,534\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_12f8d419\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: ba39a3c789017b91bd89577301000000\n",
      "\tpid: 5920\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:13:58,347\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_1d04ba99\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 56ac9ddc5cf3da96859a875b01000000\n",
      "\tpid: 20092\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffba39a3c789017b91bd89577301000000 Worker ID: fdb64c5300bee68e876d34ecc1ae3260725bcf91623a1e53de38c4f6 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53699 Worker PID: 5920 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff56ac9ddc5cf3da96859a875b01000000 Worker ID: 114ac83e5e9c8d16eee53641a2a3814be2f4516b6ec4abb63ffeb397 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53713 Worker PID: 20092 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:14:01,175\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_46221966\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 518e0f89f0d13df713a76ef001000000\n",
      "\tpid: 564\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:14:04,434\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_d34d1d3c\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: a489a61b9371e605bfe4307a01000000\n",
      "\tpid: 5344\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff518e0f89f0d13df713a76ef001000000 Worker ID: 7a95b960d4edd08c7f87cef08e261818a3a3eff9ba967cfb42673b59 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53727 Worker PID: 564 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffa489a61b9371e605bfe4307a01000000 Worker ID: dd6047e2af835c622017996c5a6367eac4e731cc6bb4addb64f91788 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53744 Worker PID: 5344 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:14:07,505\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_909de791\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: 14ed5808fb87976e76dcfd7b01000000\n",
      "\tpid: 20176\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:14:10,596\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_0a9044e3\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: d8604359f24268d78a78154c01000000\n",
      "\tpid: 20444\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff14ed5808fb87976e76dcfd7b01000000 Worker ID: 69679b83e155a073dc6f47780f15bc4ea74c6440a43e9df013fc0639 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53759 Worker PID: 20176 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd8604359f24268d78a78154c01000000 Worker ID: 311678af76d08307feedc38cf75cd0ca7432e531fb00ca05476b9598 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53775 Worker PID: 20444 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:14:13,561\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_2d68fb9d\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: d9b4f7be349044818497a13f01000000\n",
      "\tpid: 19444\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2024-10-26 10:14:16,319\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_5600e54c\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 903, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: c109d6cbc1904007c65a9c3901000000\n",
      "\tpid: 18008\n",
      "\tnamespace: 5325a05d-c51c-4306-8341-2a4c478b1ad2\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd9b4f7be349044818497a13f01000000 Worker ID: 50640f585c8b5c2b4a87162548883fe62ce387404c8585994a535370 Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53790 Worker PID: 19444 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffc109d6cbc1904007c65a9c3901000000 Worker ID: f14a85c93e89c073555a2276a24f37d69233f316d6993286311a31df Node ID: 5998b714f53c4a2c54f0e90a941e8750430706a9ec71b962a2a41ab0 Worker IP address: 127.0.0.1 Worker port: 53804 Worker PID: 18008 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1957, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2254, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2150, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1805, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1806, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2044, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1037, in ray._raylet.store_task_errors\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 608, in temporary_actor_method\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 647, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\storage.py\", line 520, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b), weights_only=False)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1384, in load\n",
      "    return _legacy_load(\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1638, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 1566, in persistent_load\n",
      "    obj = restore_location(obj, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 601, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 539, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"C:\\Users\\mashu\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 518, in _validate_device\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.\n",
      "\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:14:18,722\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-10-26 10:14:18,742\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/RayResults/tune_experiment' in 0.0205s.\n",
      "2024-10-26 10:14:19,151\tERROR tune.py:1037 -- Trials did not complete: [train_model_254d63a4, train_model_3041666e, train_model_49bf2b64, train_model_d5c545d8, train_model_6bf6bedc, train_model_88ec23b2, train_model_317aff42, train_model_98ec385a, train_model_3dcf099c, train_model_5b058ad5, train_model_75e89fa9, train_model_9134b7d5, train_model_ef02a77d, train_model_010ada71, train_model_4758663c, train_model_f571f4c0, train_model_9a1f2ab2, train_model_12f8d419, train_model_1d04ba99, train_model_46221966, train_model_d34d1d3c, train_model_909de791, train_model_0a9044e3, train_model_2d68fb9d, train_model_5600e54c]\n",
      "2024-10-26 10:14:19,151\tINFO tune.py:1041 -- Total run time: 78.20 seconds (77.34 seconds for the tuning loop).\n",
      "2024-10-26 10:14:19,152\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"C:/RayResults/tune_experiment\", trainable=...)\n",
      "2024-10-26 10:14:19,177\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 26 trial(s):\n",
      "- train_model_254d63a4: FileNotFoundError('Could not fetch metrics for train_model_254d63a4: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_254d63a4')\n",
      "- train_model_3041666e: FileNotFoundError('Could not fetch metrics for train_model_3041666e: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_3041666e')\n",
      "- train_model_49bf2b64: FileNotFoundError('Could not fetch metrics for train_model_49bf2b64: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_49bf2b64')\n",
      "- train_model_d5c545d8: FileNotFoundError('Could not fetch metrics for train_model_d5c545d8: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_d5c545d8')\n",
      "- train_model_6bf6bedc: FileNotFoundError('Could not fetch metrics for train_model_6bf6bedc: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_6bf6bedc')\n",
      "- train_model_88ec23b2: FileNotFoundError('Could not fetch metrics for train_model_88ec23b2: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_88ec23b2')\n",
      "- train_model_317aff42: FileNotFoundError('Could not fetch metrics for train_model_317aff42: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_317aff42')\n",
      "- train_model_98ec385a: FileNotFoundError('Could not fetch metrics for train_model_98ec385a: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_98ec385a')\n",
      "- train_model_3dcf099c: FileNotFoundError('Could not fetch metrics for train_model_3dcf099c: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_3dcf099c')\n",
      "- train_model_5b058ad5: FileNotFoundError('Could not fetch metrics for train_model_5b058ad5: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_5b058ad5')\n",
      "- train_model_75e89fa9: FileNotFoundError('Could not fetch metrics for train_model_75e89fa9: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_75e89fa9')\n",
      "- train_model_9134b7d5: FileNotFoundError('Could not fetch metrics for train_model_9134b7d5: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_9134b7d5')\n",
      "- train_model_ef02a77d: FileNotFoundError('Could not fetch metrics for train_model_ef02a77d: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_ef02a77d')\n",
      "- train_model_010ada71: FileNotFoundError('Could not fetch metrics for train_model_010ada71: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_010ada71')\n",
      "- train_model_4758663c: FileNotFoundError('Could not fetch metrics for train_model_4758663c: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_4758663c')\n",
      "- train_model_f571f4c0: FileNotFoundError('Could not fetch metrics for train_model_f571f4c0: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_f571f4c0')\n",
      "- train_model_9a1f2ab2: FileNotFoundError('Could not fetch metrics for train_model_9a1f2ab2: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_9a1f2ab2')\n",
      "- train_model_12f8d419: FileNotFoundError('Could not fetch metrics for train_model_12f8d419: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_12f8d419')\n",
      "- train_model_1d04ba99: FileNotFoundError('Could not fetch metrics for train_model_1d04ba99: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_1d04ba99')\n",
      "- train_model_46221966: FileNotFoundError('Could not fetch metrics for train_model_46221966: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_46221966')\n",
      "- train_model_d34d1d3c: FileNotFoundError('Could not fetch metrics for train_model_d34d1d3c: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_d34d1d3c')\n",
      "- train_model_909de791: FileNotFoundError('Could not fetch metrics for train_model_909de791: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_909de791')\n",
      "- train_model_0a9044e3: FileNotFoundError('Could not fetch metrics for train_model_0a9044e3: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_0a9044e3')\n",
      "- train_model_2d68fb9d: FileNotFoundError('Could not fetch metrics for train_model_2d68fb9d: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_2d68fb9d')\n",
      "- train_model_5600e54c: FileNotFoundError('Could not fetch metrics for train_model_5600e54c: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_5600e54c')\n",
      "- train_model_caf928eb: FileNotFoundError('Could not fetch metrics for train_model_caf928eb: both result.json and progress.csv were not found at C:/RayResults/tune_experiment/trial_caf928eb')\n",
      "2024-10-26 10:14:19,180\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 224\u001b[0m\n\u001b[0;32m    221\u001b[0m     ray\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 217\u001b[0m, in \u001b[0;36mtune_hyperparameters\u001b[1;34m()\u001b[0m\n\u001b[0;32m    198\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[0;32m    199\u001b[0m     train_model,\n\u001b[0;32m    200\u001b[0m     tune_config\u001b[38;5;241m=\u001b[39mtune\u001b[38;5;241m.\u001b[39mTuneConfig(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m     )\n\u001b[0;32m    213\u001b[0m )\n\u001b[0;32m    215\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m--> 217\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_result\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final validation loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ray\\tune\\result_grid.py:161\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[1;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[0;32m    150\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools, AllChem\n",
    "from molvecgen.vectorizers import SmilesVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray import air\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.air import RunConfig\n",
    "from ray.tune.logger import JsonLogger, CSVLogger\n",
    "\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "storage_path = os.path.abspath(\"C:/RayResults\")\n",
    "os.makedirs(storage_path, exist_ok=True)\n",
    "\n",
    "# Disable TensorBoard logging\n",
    "os.environ[\"TUNE_DISABLE_AUTO_CALLBACK_LOGGERS\"] = \"1\"\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('small_molecules_smiles_only_for_deep_learning_sm_10032024.csv')\n",
    "PandasTools.AddMoleculeColumnToFrame(df, 'canon_smiles', 'Molecule')\n",
    "\n",
    "smivec = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec.fit(df.Molecule.values)\n",
    "\n",
    "y = df['good'].values.reshape((-1, 1)).astype(np.float32)\n",
    "X = df.Molecule.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "class SMILESMolDataset(Dataset):\n",
    "    def __init__(self, molecules, y, vectorizer):\n",
    "        self.molecules = molecules\n",
    "        self.y = y\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.molecules)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        mols = self.molecules[idx]\n",
    "        sample = self.vectorizer.transform([mols])[0]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        return sample, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "train_dataset = SMILESMolDataset(X_train, y_train, smivec)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "X_val_t = smivec.transform(X_val, canonical=False)\n",
    "X_val_t = torch.tensor(X_val_t, device=device, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dimensions, lstm_sizes, hidden_size, dropout_rate, out_size=1):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        number_tokens = dimensions[1]\n",
    "\n",
    "        self.lstms = nn.ModuleList()\n",
    "\n",
    "        input_size = number_tokens\n",
    "        for lstm_size in lstm_sizes:\n",
    "            self.lstms.append(nn.LSTM(input_size=input_size, hidden_size=lstm_size, num_layers=1, batch_first=True))\n",
    "            input_size = lstm_size\n",
    "\n",
    "        self.dropouts = nn.Dropout(dropout_rate) if len(lstm_sizes) > 1 else None\n",
    "\n",
    "        self.fc1 = nn.Linear(lstm_sizes[-1], hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for lstm in self.lstms:\n",
    "            x, _ = lstm(x)\n",
    "\n",
    "        if self.dropouts:\n",
    "            x = self.dropouts(x)\n",
    "\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Global variables\n",
    "dims = smivec.dims\n",
    "lstm_size = [32, 16]\n",
    "hidden_size = 64\n",
    "dropout_rate = 0.5\n",
    "output_size = 1\n",
    "batch_size = 12\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def train_model(config):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Net(dims, \n",
    "                config['lstm_size'], \n",
    "                config['hidden_size'], \n",
    "                config['dropout_rate'], \n",
    "                output_size).to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([config[\"pos_weight\"]], device=device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for smiles, labels in train_loader:\n",
    "            smiles, labels = smiles.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(smiles)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_t.to(device))\n",
    "            val_loss = criterion(val_outputs, y_val_t.to(device)).item()\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "        # Report metrics\n",
    "        train.report({\"val_loss\": val_loss, \"training_loss\": running_loss / len(train_loader)})\n",
    "    \n",
    "    # Save final results\n",
    "    train.save_checkpoint({\"best_val_loss\": best_val_loss})\n",
    "\n",
    "def short_dirname_creator(trial):\n",
    "    return f\"trial_{trial.trial_id[:8]}\"\n",
    "\n",
    "print(device)\n",
    "\n",
    "def tune_hyperparameters():\n",
    "    if not ray.is_initialized():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        ray.init(num_cpus=24, num_gpus=num_gpus, ignore_reinit_error=True)\n",
    "        \n",
    "    storage_path = os.path.abspath(\"C:/RT\")  # Shorter path\n",
    "    os.makedirs(storage_path, exist_ok=True)\n",
    "\n",
    "    config = {\n",
    "        \"hidden_size\": tune.choice([32, 64, 128, 256]),\n",
    "        \"lstm_size\": tune.choice([[32, 16], [64, 32], [64, 32, 16], [128, 64, 32], [256, 128, 64], [256, 128, 32], [256, 128, 64, 32]]),\n",
    "        \"dropout_rate\": tune.loguniform(0.2, 0.8),\n",
    "        \"learning_rate\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"batch_size\": tune.choice([4, 8, 16, 32, 64]),\n",
    "        \"epochs\": tune.randint(10, 50),\n",
    "        \"pos_weight\": tune.randint(1, 100)\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=50,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "\n",
    "    search_alg = OptunaSearch()\n",
    "\n",
    "    storage_path = os.path.abspath(\"C:/RayResults\")\n",
    "    os.makedirs(storage_path, exist_ok=True)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        train_model,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            search_alg=search_alg,\n",
    "            num_samples=50,\n",
    "            trial_dirname_creator=short_dirname_creator,\n",
    "        ),\n",
    "        param_space=config,\n",
    "        run_config=air.RunConfig(\n",
    "            name=\"tune_experiment\",\n",
    "            storage_path=storage_path,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(\"val_loss\", \"min\")\n",
    "    print(\"Best trial config:\", best_result.config)\n",
    "    print(\"Best trial final validation loss:\", best_result.metrics[\"val_loss\"])\n",
    "\n",
    "    ray.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tune_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322791ee",
   "metadata": {},
   "source": [
    "# Use regular gridsearchCV to tune hyperparameters (it can work but take too long time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d88299",
   "metadata": {},
   "source": [
    "### lstm_sizes, hidden_size, dropout_rate, learning_rate, batch_size, pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebe62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:45:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:45:13] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1078, Valid Loss: 0.1078\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1074, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1104, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.43 seconds\n",
      "Epoch 4, Train Loss: 0.1277, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1252, Valid Loss: 0.0958\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.74 seconds\n",
      "Epoch 4, Train Loss: 0.1239, Valid Loss: 0.0948\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1152, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1148, Valid Loss: 0.1006\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.34 seconds\n",
      "Epoch 4, Train Loss: 0.5838, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.7287, Valid Loss: 0.5321\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6795, Valid Loss: 0.6331\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.87 seconds\n",
      "Epoch 4, Train Loss: 0.6690, Valid Loss: 0.5194\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6695, Valid Loss: 0.5330\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.80 seconds\n",
      "Epoch 4, Train Loss: 0.8274, Valid Loss: 0.5161\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6180, Valid Loss: 0.5157\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.86 seconds\n",
      "Epoch 4, Train Loss: 1.9369, Valid Loss: 1.9510\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9677, Valid Loss: 1.8476\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9604, Valid Loss: 1.8245\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.15 seconds\n",
      "Epoch 4, Train Loss: 2.5629, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1301, Valid Loss: 1.8823\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0905, Valid Loss: 1.8349\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.12 seconds\n",
      "Epoch 4, Train Loss: 2.0620, Valid Loss: 1.8293\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0733, Valid Loss: 1.8049\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0561, Valid Loss: 1.8033\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.2198, Valid Loss: 1.7571\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0482, Valid Loss: 1.8289\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0397, Valid Loss: 1.8492\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.66 seconds\n",
      "Epoch 4, Train Loss: 0.1152, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1281, Valid Loss: 0.0957\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.03 seconds\n",
      "Epoch 4, Train Loss: 0.1299, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1283, Valid Loss: 0.0961\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.75 seconds\n",
      "Epoch 4, Train Loss: 0.1232, Valid Loss: 0.1015\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1207, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.69 seconds\n",
      "Epoch 4, Train Loss: 0.5998, Valid Loss: 0.5089\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5962, Valid Loss: 0.5122\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5846, Valid Loss: 0.5268\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.53 seconds\n",
      "Epoch 4, Train Loss: 0.6882, Valid Loss: 0.5094\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6367, Valid Loss: 0.5348\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.75 seconds\n",
      "Epoch 4, Train Loss: 0.6371, Valid Loss: 0.5641\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6132, Valid Loss: 0.5417\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6123, Valid Loss: 0.5234\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.63 seconds\n",
      "Epoch 4, Train Loss: 1.9400, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9406, Valid Loss: 1.8285\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9266, Valid Loss: 1.8288\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 8.90 seconds\n",
      "Epoch 4, Train Loss: 2.0334, Valid Loss: 1.8980\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1459, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1011, Valid Loss: 1.8466\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.37 seconds\n",
      "Epoch 4, Train Loss: 2.1170, Valid Loss: 1.8259\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0873, Valid Loss: 1.8309\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0785, Valid Loss: 1.8423\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.17 seconds\n",
      "Epoch 4, Train Loss: 0.1169, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1114, Valid Loss: 0.0949\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1151, Valid Loss: 0.0951\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.92 seconds\n",
      "Epoch 4, Train Loss: 0.1302, Valid Loss: 0.0970\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1290, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.82 seconds\n",
      "Epoch 4, Train Loss: 0.1225, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1233, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.63 seconds\n",
      "Epoch 4, Train Loss: 0.5995, Valid Loss: 0.5191\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.7426, Valid Loss: 0.5509\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5698, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.02 seconds\n",
      "Epoch 4, Train Loss: 0.6440, Valid Loss: 0.5330\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6368, Valid Loss: 0.5086\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.64 seconds\n",
      "Epoch 4, Train Loss: 0.6313, Valid Loss: 0.5461\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6168, Valid Loss: 0.5262\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.66 seconds\n",
      "Epoch 4, Train Loss: 2.0181, Valid Loss: 1.8309\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9322, Valid Loss: 1.8301\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9284, Valid Loss: 1.8289\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.05 seconds\n",
      "Epoch 4, Train Loss: 2.1110, Valid Loss: 1.8287\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0846, Valid Loss: 1.8366\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.58 seconds\n",
      "Epoch 4, Train Loss: 2.3491, Valid Loss: 1.9176\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0516, Valid Loss: 1.8574\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.60 seconds\n",
      "Epoch 4, Train Loss: 0.1059, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1092, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.53 seconds\n",
      "Epoch 4, Train Loss: 0.1317, Valid Loss: 0.0951\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1240, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.07 seconds\n",
      "Epoch 4, Train Loss: 0.1183, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1183, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.67 seconds\n",
      "Epoch 4, Train Loss: 0.5604, Valid Loss: 0.5183\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5806, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5317, Valid Loss: 0.4952\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5122, Valid Loss: 0.5383\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4164, Valid Loss: 0.6765\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 14.05 seconds\n",
      "Epoch 4, Train Loss: 0.6521, Valid Loss: 0.5291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6301, Valid Loss: 0.5215\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.67 seconds\n",
      "Epoch 4, Train Loss: 0.6137, Valid Loss: 0.5104\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6109, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.83 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.0337, Valid Loss: 1.8579\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8488, Valid Loss: 1.8497\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9358, Valid Loss: 1.8243\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9516, Valid Loss: 1.8122\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.84 seconds\n",
      "Epoch 4, Train Loss: 2.1798, Valid Loss: 1.8210\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1260, Valid Loss: 1.8323\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1051, Valid Loss: 1.8451\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.02 seconds\n",
      "Epoch 4, Train Loss: 2.0681, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0632, Valid Loss: 1.8433\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0545, Valid Loss: 1.8533\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.90 seconds\n",
      "Epoch 4, Train Loss: 0.1066, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1044, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.46 seconds\n",
      "Epoch 4, Train Loss: 0.1210, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1185, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.50 seconds\n",
      "Epoch 4, Train Loss: 0.1161, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1150, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.33 seconds\n",
      "Epoch 4, Train Loss: 0.5885, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5696, Valid Loss: 0.5126\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.75 seconds\n",
      "Epoch 4, Train Loss: 0.6543, Valid Loss: 0.5368\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6482, Valid Loss: 0.5122\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.66 seconds\n",
      "Epoch 4, Train Loss: 0.6462, Valid Loss: 0.5274\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6228, Valid Loss: 0.5170\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.64 seconds\n",
      "Epoch 4, Train Loss: 1.9348, Valid Loss: 1.8188\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9528, Valid Loss: 1.8625\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9095, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.43 seconds\n",
      "Epoch 4, Train Loss: 2.1245, Valid Loss: 1.8358\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0601, Valid Loss: 1.8596\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0957, Valid Loss: 1.8651\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.99 seconds\n",
      "Epoch 4, Train Loss: 2.0543, Valid Loss: 1.8219\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0705, Valid Loss: 1.9115\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0232, Valid Loss: 1.8356\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.61 seconds\n",
      "Epoch 4, Train Loss: 0.1042, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1130, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.06 seconds\n",
      "Epoch 4, Train Loss: 0.1196, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1254, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.83 seconds\n",
      "Epoch 4, Train Loss: 0.1250, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1173, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.80 seconds\n",
      "Epoch 4, Train Loss: 0.5717, Valid Loss: 0.5128\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5673, Valid Loss: 0.5090\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.29 seconds\n",
      "Epoch 4, Train Loss: 0.6488, Valid Loss: 0.5300\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6390, Valid Loss: 0.5301\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6490, Valid Loss: 0.5133\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.60 seconds\n",
      "Epoch 4, Train Loss: 0.6079, Valid Loss: 0.5105\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.5979, Valid Loss: 0.5139\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.83 seconds\n",
      "Epoch 4, Train Loss: 1.9125, Valid Loss: 1.8413\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9199, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9290, Valid Loss: 1.8256\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.69 seconds\n",
      "Epoch 4, Train Loss: 2.1303, Valid Loss: 1.8456\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0841, Valid Loss: 1.8513\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1187, Valid Loss: 1.8502\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.41 seconds\n",
      "Epoch 4, Train Loss: 2.0602, Valid Loss: 1.8302\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0496, Valid Loss: 1.8316\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0174, Valid Loss: 1.8525\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.84 seconds\n",
      "Epoch 4, Train Loss: 0.1052, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1078, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.95 seconds\n",
      "Epoch 4, Train Loss: 0.1292, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1238, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.96 seconds\n",
      "Epoch 4, Train Loss: 0.1144, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1163, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.83 seconds\n",
      "Epoch 4, Train Loss: 0.5375, Valid Loss: 0.5092\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5659, Valid Loss: 0.5128\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5646, Valid Loss: 0.5123\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.75 seconds\n",
      "Epoch 4, Train Loss: 0.6361, Valid Loss: 0.5207\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6170, Valid Loss: 0.5152\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6006, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6388, Valid Loss: 0.5244\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.13 seconds\n",
      "Epoch 4, Train Loss: 0.6064, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6029, Valid Loss: 0.5152\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.66 seconds\n",
      "Epoch 4, Train Loss: 1.9820, Valid Loss: 1.8282\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8454, Valid Loss: 1.8413\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.6707, Valid Loss: 1.9829\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.5254, Valid Loss: 1.9547\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.4266, Valid Loss: 2.3058\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.86 seconds\n",
      "Epoch 4, Train Loss: 2.1477, Valid Loss: 1.8217\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1057, Valid Loss: 1.8140\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1423, Valid Loss: 1.8060\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.6162, Valid Loss: 1.3721\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.5313, Valid Loss: 2.5670\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8245, Valid Loss: 1.8156\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.03 seconds\n",
      "Epoch 4, Train Loss: 2.0745, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0957, Valid Loss: 1.8199\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9396, Valid Loss: 1.7555\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.6133, Valid Loss: 1.8353\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 4.4296, Valid Loss: 1.5963\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0903, Valid Loss: 1.6511\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7277, Valid Loss: 1.6379\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 20.55 seconds\n",
      "Epoch 4, Train Loss: 0.1051, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1029, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.71 seconds\n",
      "Epoch 4, Train Loss: 0.1218, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1228, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.62 seconds\n",
      "Epoch 4, Train Loss: 0.1156, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1108, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.18 seconds\n",
      "Epoch 4, Train Loss: 0.5472, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5419, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.32 seconds\n",
      "Epoch 4, Train Loss: 0.6357, Valid Loss: 0.5135\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6257, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.35 seconds\n",
      "Epoch 4, Train Loss: 0.5972, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6105, Valid Loss: 0.5154\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.50 seconds\n",
      "Epoch 4, Train Loss: 1.9166, Valid Loss: 1.8062\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.6607, Valid Loss: 1.5310\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.8772, Valid Loss: 1.9314\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.6348, Valid Loss: 1.9962\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.12 seconds\n",
      "Epoch 4, Train Loss: 2.1337, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0902, Valid Loss: 1.8449\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1013, Valid Loss: 1.8503\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.43 seconds\n",
      "Epoch 4, Train Loss: 2.0557, Valid Loss: 1.8110\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8873, Valid Loss: 1.5493\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0862, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0167, Valid Loss: 1.8385\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.86 seconds\n",
      "Epoch 4, Train Loss: 0.1028, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1098, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.84 seconds\n",
      "Epoch 4, Train Loss: 0.1238, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1192, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.70 seconds\n",
      "Epoch 4, Train Loss: 0.1188, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1184, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1160, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.05 seconds\n",
      "Epoch 4, Train Loss: 0.5514, Valid Loss: 0.5089\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5485, Valid Loss: 0.5082\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.77 seconds\n",
      "Epoch 4, Train Loss: 0.6204, Valid Loss: 0.5170\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6405, Valid Loss: 0.5155\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6447, Valid Loss: 0.5209\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.19 seconds\n",
      "Epoch 4, Train Loss: 0.6169, Valid Loss: 0.5163\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6155, Valid Loss: 0.5194\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.31 seconds\n",
      "Epoch 4, Train Loss: 2.0771, Valid Loss: 1.8767\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9352, Valid Loss: 1.8227\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9597, Valid Loss: 1.8251\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9175, Valid Loss: 1.8272\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.39 seconds\n",
      "Epoch 4, Train Loss: 2.1007, Valid Loss: 1.8232\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0783, Valid Loss: 1.8551\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 2.0633, Valid Loss: 1.8485\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.18 seconds\n",
      "Epoch 4, Train Loss: 2.1188, Valid Loss: 1.8275\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0649, Valid Loss: 1.8423\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9270, Valid Loss: 1.6441\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7537, Valid Loss: 1.4815\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7245, Valid Loss: 2.4598\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5214, Valid Loss: 2.5184\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.2182, Valid Loss: 2.0923\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 22.31 seconds\n",
      "Epoch 4, Train Loss: 0.1306, Valid Loss: 0.1079\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1117, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1119, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1024, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.77 seconds\n",
      "Epoch 4, Train Loss: 0.1320, Valid Loss: 0.1016\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1197, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1249, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.73 seconds\n",
      "Epoch 4, Train Loss: 0.1336, Valid Loss: 0.1060\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1206, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1158, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1104, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.78 seconds\n",
      "Epoch 4, Train Loss: 0.5817, Valid Loss: 0.5151\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5552, Valid Loss: 0.5099\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5284, Valid Loss: 0.5079\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.67 seconds\n",
      "Epoch 4, Train Loss: 0.6317, Valid Loss: 0.5313\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6343, Valid Loss: 0.5194\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6115, Valid Loss: 0.5161\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6218, Valid Loss: 0.5168\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.55 seconds\n",
      "Epoch 4, Train Loss: 0.6296, Valid Loss: 0.5449\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6077, Valid Loss: 0.5181\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6213, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6123, Valid Loss: 0.5156\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.96 seconds\n",
      "Epoch 4, Train Loss: 2.0255, Valid Loss: 1.8820\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0100, Valid Loss: 1.8647\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9543, Valid Loss: 1.8417\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9185, Valid Loss: 1.8209\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9176, Valid Loss: 1.8552\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8639, Valid Loss: 1.8297\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8196, Valid Loss: 1.7811\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7747, Valid Loss: 1.7774\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6507, Valid Loss: 1.7557\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.6587, Valid Loss: 1.8746\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5260, Valid Loss: 1.7266\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.5106, Valid Loss: 1.6761\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 33.58 seconds\n",
      "Epoch 4, Train Loss: 2.2605, Valid Loss: 1.8709\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1786, Valid Loss: 1.8363\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1111, Valid Loss: 1.8205\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 2.0487, Valid Loss: 1.8339\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0577, Valid Loss: 1.8253\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.23 seconds\n",
      "Epoch 4, Train Loss: 2.2444, Valid Loss: 1.9085\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1781, Valid Loss: 1.8668\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0785, Valid Loss: 1.8202\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0498, Valid Loss: 1.8197\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9946, Valid Loss: 1.8085\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9804, Valid Loss: 1.7710\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9335, Valid Loss: 1.7641\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8724, Valid Loss: 1.6936\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8238, Valid Loss: 1.6587\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.8751, Valid Loss: 1.7212\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.7798, Valid Loss: 1.5920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.8699, Valid Loss: 1.7316\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 32.51 seconds\n",
      "Epoch 4, Train Loss: 0.1067, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1096, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1064, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.04 seconds\n",
      "Epoch 4, Train Loss: 0.1228, Valid Loss: 0.0960\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1215, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1204, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.15 seconds\n",
      "Epoch 4, Train Loss: 0.1153, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1152, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1161, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.40 seconds\n",
      "Epoch 4, Train Loss: 0.5700, Valid Loss: 0.5121\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5448, Valid Loss: 0.5097\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5451, Valid Loss: 0.5090\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.98 seconds\n",
      "Epoch 4, Train Loss: 0.6376, Valid Loss: 0.5176\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6143, Valid Loss: 0.5180\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6253, Valid Loss: 0.5184\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.15 seconds\n",
      "Epoch 4, Train Loss: 0.6208, Valid Loss: 0.5136\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6032, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5941, Valid Loss: 0.5109\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.14 seconds\n",
      "Epoch 4, Train Loss: 2.0086, Valid Loss: 1.8647\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9482, Valid Loss: 1.8385\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9021, Valid Loss: 1.8159\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8056, Valid Loss: 1.7831\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0232, Valid Loss: 1.9228\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9557, Valid Loss: 1.8477\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9161, Valid Loss: 1.8366\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.77 seconds\n",
      "Epoch 4, Train Loss: 2.4358, Valid Loss: 1.9554\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1141, Valid Loss: 1.8223\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0780, Valid Loss: 1.8386\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1042, Valid Loss: 1.8499\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.46 seconds\n",
      "Epoch 4, Train Loss: 2.3383, Valid Loss: 1.9479\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0698, Valid Loss: 1.8220\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 2.0106, Valid Loss: 1.8373\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0817, Valid Loss: 1.8378\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.75 seconds\n",
      "Epoch 4, Train Loss: 0.1310, Valid Loss: 0.1070\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1051, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1023, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.0980, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.90 seconds\n",
      "Epoch 4, Train Loss: 0.1620, Valid Loss: 0.1213\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1255, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1245, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1195, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 13.01 seconds\n",
      "Epoch 4, Train Loss: 0.1325, Valid Loss: 0.1037\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1103, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1175, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1133, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 13.12 seconds\n",
      "Epoch 4, Train Loss: 0.5651, Valid Loss: 0.5235\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5536, Valid Loss: 0.5114\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5466, Valid Loss: 0.5108\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5811, Valid Loss: 0.5115\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.12 seconds\n",
      "Epoch 4, Train Loss: 0.6452, Valid Loss: 0.5452\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6064, Valid Loss: 0.5204\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6428, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6319, Valid Loss: 0.5172\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.72 seconds\n",
      "Epoch 4, Train Loss: 0.6162, Valid Loss: 0.5423\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5899, Valid Loss: 0.5186\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6074, Valid Loss: 0.5148\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5998, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.77 seconds\n",
      "Epoch 4, Train Loss: 2.1473, Valid Loss: 1.9618\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0320, Valid Loss: 1.8586\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9717, Valid Loss: 1.8158\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8907, Valid Loss: 1.7839\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7828, Valid Loss: 1.7850\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.7071, Valid Loss: 1.7567\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.6726, Valid Loss: 1.7111\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6184, Valid Loss: 1.8815\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6304, Valid Loss: 1.8215\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5541, Valid Loss: 2.0235\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 29.43 seconds\n",
      "Epoch 4, Train Loss: 2.4510, Valid Loss: 1.9529\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1623, Valid Loss: 1.8334\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1325, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1032, Valid Loss: 1.8303\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0558, Valid Loss: 1.8400\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.83 seconds\n",
      "Epoch 4, Train Loss: 2.0997, Valid Loss: 1.8341\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0640, Valid Loss: 1.8183\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0432, Valid Loss: 1.8078\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 1.9637, Valid Loss: 1.8245\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9392, Valid Loss: 1.7245\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9161, Valid Loss: 1.7384\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9611, Valid Loss: 1.7122\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7374, Valid Loss: 1.6674\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6894, Valid Loss: 1.5163\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.3538, Valid Loss: 2.4432\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.3119, Valid Loss: 2.1423\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.4284, Valid Loss: 2.3534\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 34.08 seconds\n",
      "Epoch 4, Train Loss: 0.1208, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1129, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1086, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.44 seconds\n",
      "Epoch 4, Train Loss: 0.1293, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1331, Valid Loss: 0.0977\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1363, Valid Loss: 0.1061\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.40 seconds\n",
      "Epoch 4, Train Loss: 0.1436, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1185, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.82 seconds\n",
      "Epoch 4, Train Loss: 0.6085, Valid Loss: 0.5127\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5931, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.05 seconds\n",
      "Epoch 4, Train Loss: 0.6462, Valid Loss: 0.5131\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6494, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6245, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.59 seconds\n",
      "Epoch 4, Train Loss: 0.6445, Valid Loss: 0.5038\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6385, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5912, Valid Loss: 0.5052\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6063, Valid Loss: 0.5332\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5916, Valid Loss: 0.5200\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.6025, Valid Loss: 1.2727\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 16.23 seconds\n",
      "Epoch 4, Train Loss: 2.0669, Valid Loss: 1.8858\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9737, Valid Loss: 1.8510\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9611, Valid Loss: 1.8463\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.35 seconds\n",
      "Epoch 4, Train Loss: 2.1144, Valid Loss: 1.9290\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2966, Valid Loss: 1.8313\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.15 seconds\n",
      "Epoch 4, Train Loss: 2.0610, Valid Loss: 1.8664\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0430, Valid Loss: 1.8326\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0438, Valid Loss: 1.8362\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.14 seconds\n",
      "Epoch 4, Train Loss: 0.1189, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1109, Valid Loss: 0.0984\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.20 seconds\n",
      "Epoch 4, Train Loss: 0.1327, Valid Loss: 0.0984\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1282, Valid Loss: 0.1131\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1172, Valid Loss: 0.1109\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.38 seconds\n",
      "Epoch 4, Train Loss: 0.1357, Valid Loss: 0.1069\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1146, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.30 seconds\n",
      "Epoch 4, Train Loss: 0.6258, Valid Loss: 0.5805\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.5938, Valid Loss: 0.5327\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5548, Valid Loss: 0.5092\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5521, Valid Loss: 0.5126\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.41 seconds\n",
      "Epoch 4, Train Loss: 0.6706, Valid Loss: 0.5184\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6567, Valid Loss: 0.5266\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6411, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.76 seconds\n",
      "Epoch 4, Train Loss: 0.6478, Valid Loss: 0.5119\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6230, Valid Loss: 0.5083\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6060, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.50 seconds\n",
      "Epoch 4, Train Loss: 1.9911, Valid Loss: 1.8306\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9673, Valid Loss: 1.8343\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.84 seconds\n",
      "Epoch 4, Train Loss: 2.0883, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0829, Valid Loss: 1.8504\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0804, Valid Loss: 1.8515\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.36 seconds\n",
      "Epoch 4, Train Loss: 2.1477, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0425, Valid Loss: 1.8245\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0030, Valid Loss: 1.8272\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.19 seconds\n",
      "Epoch 4, Train Loss: 0.1139, Valid Loss: 0.1037\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1118, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1102, Valid Loss: 0.0955\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.26 seconds\n",
      "Epoch 4, Train Loss: 0.1225, Valid Loss: 0.1555\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1292, Valid Loss: 0.0957\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.48 seconds\n",
      "Epoch 4, Train Loss: 0.1252, Valid Loss: 0.0953\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1295, Valid Loss: 0.0998\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.56 seconds\n",
      "Epoch 4, Train Loss: 0.5755, Valid Loss: 0.5131\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5718, Valid Loss: 0.5181\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5635, Valid Loss: 0.5118\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.62 seconds\n",
      "Epoch 4, Train Loss: 0.6716, Valid Loss: 0.5826\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6450, Valid Loss: 0.5305\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6395, Valid Loss: 0.5358\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.38 seconds\n",
      "Epoch 4, Train Loss: 0.6064, Valid Loss: 0.5285\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6094, Valid Loss: 0.5164\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6068, Valid Loss: 0.5343\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.91 seconds\n",
      "Epoch 4, Train Loss: 1.9478, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9336, Valid Loss: 1.8244\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9328, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.23 seconds\n",
      "Epoch 4, Train Loss: 2.1008, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1015, Valid Loss: 1.8295\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1017, Valid Loss: 1.8348\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.61 seconds\n",
      "Epoch 4, Train Loss: 2.0749, Valid Loss: 1.8473\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0502, Valid Loss: 1.8515\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.87 seconds\n",
      "Epoch 4, Train Loss: 0.1087, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1042, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 6.75 seconds\n",
      "Epoch 4, Train Loss: 0.1298, Valid Loss: 0.0953\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1276, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.70 seconds\n",
      "Epoch 4, Train Loss: 0.1151, Valid Loss: 0.0950\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1193, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 88.00 seconds\n",
      "Epoch 4, Train Loss: 0.5454, Valid Loss: 0.5032\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.4866, Valid Loss: 0.5429\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4141, Valid Loss: 0.4703\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4669, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.51 seconds\n",
      "Epoch 4, Train Loss: 0.6189, Valid Loss: 0.5312\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6623, Valid Loss: 0.5156\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.96 seconds\n",
      "Epoch 4, Train Loss: 0.6099, Valid Loss: 0.5021\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6322, Valid Loss: 0.5283\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6234, Valid Loss: 0.5203\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5718, Valid Loss: 0.4500\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5345, Valid Loss: 0.4045\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5986, Valid Loss: 0.6077\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.4655, Valid Loss: 0.4579\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 19.26 seconds\n",
      "Epoch 4, Train Loss: 1.9810, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9645, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9396, Valid Loss: 1.8299\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.42 seconds\n",
      "Epoch 4, Train Loss: 2.1116, Valid Loss: 1.8279\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0343, Valid Loss: 1.7823\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0902, Valid Loss: 1.8466\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1331, Valid Loss: 1.8487\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.13 seconds\n",
      "Epoch 4, Train Loss: 2.0699, Valid Loss: 1.8377\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0637, Valid Loss: 1.8321\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0122, Valid Loss: 1.8458\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.49 seconds\n",
      "Epoch 4, Train Loss: 0.1065, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1108, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.69 seconds\n",
      "Epoch 4, Train Loss: 0.1288, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1256, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.13 seconds\n",
      "Epoch 4, Train Loss: 0.1165, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1173, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.79 seconds\n",
      "Epoch 4, Train Loss: 0.5571, Valid Loss: 0.5087\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.4970, Valid Loss: 0.5532\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5694, Valid Loss: 0.5090\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.27 seconds\n",
      "Epoch 4, Train Loss: 0.6283, Valid Loss: 0.5261\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6438, Valid Loss: 0.5183\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6432, Valid Loss: 0.5279\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.35 seconds\n",
      "Epoch 4, Train Loss: 0.6181, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6112, Valid Loss: 0.5088\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.06 seconds\n",
      "Epoch 4, Train Loss: 2.1126, Valid Loss: 1.8340\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9439, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9645, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 1.9510, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.55 seconds\n",
      "Epoch 4, Train Loss: 2.0545, Valid Loss: 1.9108\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1361, Valid Loss: 1.8286\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1067, Valid Loss: 1.8654\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.23 seconds\n",
      "Epoch 4, Train Loss: 2.2906, Valid Loss: 1.9448\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9470, Valid Loss: 1.8734\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0654, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.52 seconds\n",
      "Epoch 4, Train Loss: 0.1152, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1098, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.70 seconds\n",
      "Epoch 4, Train Loss: 0.1229, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1218, Valid Loss: 0.0952\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.88 seconds\n",
      "Epoch 4, Train Loss: 0.1122, Valid Loss: 0.1006\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1169, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.76 seconds\n",
      "Epoch 4, Train Loss: 0.5705, Valid Loss: 0.5100\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5805, Valid Loss: 0.5214\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5348, Valid Loss: 0.5184\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5596, Valid Loss: 0.5081\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.50 seconds\n",
      "Epoch 4, Train Loss: 0.6372, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6554, Valid Loss: 0.5321\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6508, Valid Loss: 0.5234\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.38 seconds\n",
      "Epoch 4, Train Loss: 0.6043, Valid Loss: 0.5169\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6229, Valid Loss: 0.5196\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.43 seconds\n",
      "Epoch 4, Train Loss: 2.0395, Valid Loss: 1.8238\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9857, Valid Loss: 1.8293\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9417, Valid Loss: 1.8303\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.97 seconds\n",
      "Epoch 4, Train Loss: 2.0910, Valid Loss: 1.8479\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1127, Valid Loss: 1.8448\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0990, Valid Loss: 1.8486\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.84 seconds\n",
      "Epoch 4, Train Loss: 2.7317, Valid Loss: 1.8251\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0135, Valid Loss: 2.0281\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0501, Valid Loss: 1.8383\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.21 seconds\n",
      "Epoch 4, Train Loss: 0.1082, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1031, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.82 seconds\n",
      "Epoch 4, Train Loss: 0.1160, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1222, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.83 seconds\n",
      "Epoch 4, Train Loss: 0.1153, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1135, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.88 seconds\n",
      "Epoch 4, Train Loss: 0.5784, Valid Loss: 0.5081\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5661, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5785, Valid Loss: 0.5169\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.37 seconds\n",
      "Epoch 4, Train Loss: 0.6513, Valid Loss: 0.5131\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6131, Valid Loss: 0.5048\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6157, Valid Loss: 0.4955\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.5320, Valid Loss: 0.5060\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5693, Valid Loss: 0.4742\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5270, Valid Loss: 0.5213\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 16.23 seconds\n",
      "Epoch 4, Train Loss: 0.6094, Valid Loss: 0.5175\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6028, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.72 seconds\n",
      "Epoch 4, Train Loss: 1.9816, Valid Loss: 1.8194\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.7070, Valid Loss: 1.7388\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.4976, Valid Loss: 2.1212\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.3797, Valid Loss: 1.8044\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.34 seconds\n",
      "Epoch 4, Train Loss: 2.1241, Valid Loss: 1.8296\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1045, Valid Loss: 1.8154\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0147, Valid Loss: 1.7491\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1177, Valid Loss: 1.8386\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1147, Valid Loss: 1.8380\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.03 seconds\n",
      "Epoch 4, Train Loss: 2.0274, Valid Loss: 1.8193\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 3.1115, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0117, Valid Loss: 1.8452\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.49 seconds\n",
      "Epoch 4, Train Loss: 0.1042, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1115, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.96 seconds\n",
      "Epoch 4, Train Loss: 0.1184, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1207, Valid Loss: 0.0945\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.63 seconds\n",
      "Epoch 4, Train Loss: 0.1194, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1159, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.71 seconds\n",
      "Epoch 4, Train Loss: 0.5573, Valid Loss: 0.5110\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5569, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5624, Valid Loss: 0.5152\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5636, Valid Loss: 0.5102\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.95 seconds\n",
      "Epoch 4, Train Loss: 0.6281, Valid Loss: 0.5226\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6305, Valid Loss: 0.5194\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.74 seconds\n",
      "Epoch 4, Train Loss: 0.5908, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5930, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.70 seconds\n",
      "Epoch 4, Train Loss: 2.0173, Valid Loss: 1.8489\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.7564, Valid Loss: 1.9542\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9526, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9626, Valid Loss: 1.8223\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.71 seconds\n",
      "Epoch 4, Train Loss: 2.1837, Valid Loss: 1.8354\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0902, Valid Loss: 1.8293\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0789, Valid Loss: 1.7963\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1336, Valid Loss: 1.8501\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0808, Valid Loss: 1.8619\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.92 seconds\n",
      "Epoch 4, Train Loss: 2.2320, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9035, Valid Loss: 1.9665\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0506, Valid Loss: 1.8246\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0400, Valid Loss: 1.8213\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 13.45 seconds\n",
      "Epoch 4, Train Loss: 0.1040, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1026, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.80 seconds\n",
      "Epoch 4, Train Loss: 0.1148, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1166, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.45 seconds\n",
      "Epoch 4, Train Loss: 0.1144, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1148, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.96 seconds\n",
      "Epoch 4, Train Loss: 0.5478, Valid Loss: 0.5092\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5723, Valid Loss: 0.5111\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.87 seconds\n",
      "Epoch 4, Train Loss: 0.6462, Valid Loss: 0.5210\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6279, Valid Loss: 0.5168\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.29 seconds\n",
      "Epoch 4, Train Loss: 0.6003, Valid Loss: 0.5133\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6104, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5929, Valid Loss: 0.5160\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.38 seconds\n",
      "Epoch 4, Train Loss: 1.9746, Valid Loss: 1.8278\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9549, Valid Loss: 1.8223\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9229, Valid Loss: 1.8295\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9387, Valid Loss: 1.8296\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.45 seconds\n",
      "Epoch 4, Train Loss: 2.0800, Valid Loss: 1.8541\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0852, Valid Loss: 1.8755\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.4349, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.88 seconds\n",
      "Epoch 4, Train Loss: 2.0354, Valid Loss: 1.8352\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1430, Valid Loss: 1.8273\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0714, Valid Loss: 1.8238\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0195, Valid Loss: 1.8425\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0132, Valid Loss: 1.8395\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 16.35 seconds\n",
      "Epoch 4, Train Loss: 0.1158, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1080, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1030, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.54 seconds\n",
      "Epoch 4, Train Loss: 0.1256, Valid Loss: 0.0968\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1203, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1213, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.25 seconds\n",
      "Epoch 4, Train Loss: 0.1236, Valid Loss: 0.0964\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1174, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1140, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.47 seconds\n",
      "Epoch 4, Train Loss: 0.5777, Valid Loss: 0.5182\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5459, Valid Loss: 0.5105\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5713, Valid Loss: 0.5072\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.27 seconds\n",
      "Epoch 4, Train Loss: 0.6320, Valid Loss: 0.5242\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6275, Valid Loss: 0.5181\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6312, Valid Loss: 0.5203\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.95 seconds\n",
      "Epoch 4, Train Loss: 0.6080, Valid Loss: 0.5269\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6084, Valid Loss: 0.5151\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6051, Valid Loss: 0.5148\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 9.90 seconds\n",
      "Epoch 4, Train Loss: 2.1180, Valid Loss: 1.9375\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9932, Valid Loss: 1.8564\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8514, Valid Loss: 1.8111\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8102, Valid Loss: 1.7891\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7185, Valid Loss: 1.7456\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5735, Valid Loss: 1.7327\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.3410, Valid Loss: 2.0666\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5939, Valid Loss: 1.8683\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 23.78 seconds\n",
      "Epoch 4, Train Loss: 2.3061, Valid Loss: 1.8919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1490, Valid Loss: 1.8285\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0875, Valid Loss: 1.8213\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0401, Valid Loss: 1.8348\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0706, Valid Loss: 1.8080\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0541, Valid Loss: 1.7529\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9446, Valid Loss: 1.7867\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9463, Valid Loss: 1.7438\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8250, Valid Loss: 1.6383\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.8018, Valid Loss: 1.6438\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.9879, Valid Loss: 1.9681\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 2.0291, Valid Loss: 1.9611\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 31.70 seconds\n",
      "Epoch 4, Train Loss: 2.2724, Valid Loss: 1.9158\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1253, Valid Loss: 1.8252\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0092, Valid Loss: 1.8324\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0152, Valid Loss: 1.8132\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0049, Valid Loss: 1.8194\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.39 seconds\n",
      "Epoch 4, Train Loss: 0.1050, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1044, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1021, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.55 seconds\n",
      "Epoch 4, Train Loss: 0.1229, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1145, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1208, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1196, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.22 seconds\n",
      "Epoch 4, Train Loss: 0.1156, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1140, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1142, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.75 seconds\n",
      "Epoch 4, Train Loss: 0.5543, Valid Loss: 0.5085\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5597, Valid Loss: 0.5096\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5705, Valid Loss: 0.5096\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.37 seconds\n",
      "Epoch 4, Train Loss: 0.6406, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6331, Valid Loss: 0.5175\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6275, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.75 seconds\n",
      "Epoch 4, Train Loss: 0.5972, Valid Loss: 0.5127\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6023, Valid Loss: 0.5138\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5936, Valid Loss: 0.5070\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5868, Valid Loss: 0.5178\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.5822, Valid Loss: 0.4944\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5564, Valid Loss: 0.4908\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.4592, Valid Loss: 0.6596\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.6065, Valid Loss: 0.5129\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.6085, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 23.17 seconds\n",
      "Epoch 4, Train Loss: 2.0203, Valid Loss: 1.8646\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9393, Valid Loss: 1.8261\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8728, Valid Loss: 1.8138\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7306, Valid Loss: 1.7643\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.5217, Valid Loss: 1.8194\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5231, Valid Loss: 1.7983\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.0301, Valid Loss: 1.8859\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9641, Valid Loss: 1.8286\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 19.91 seconds\n",
      "Epoch 4, Train Loss: 2.2905, Valid Loss: 1.8730\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0845, Valid Loss: 1.8506\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0660, Valid Loss: 1.8286\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.06 seconds\n",
      "Epoch 4, Train Loss: 2.1989, Valid Loss: 1.8785\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0132, Valid Loss: 1.8155\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9671, Valid Loss: 1.8039\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9596, Valid Loss: 1.7622\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9709, Valid Loss: 1.7529\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9060, Valid Loss: 1.6853\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9790, Valid Loss: 1.8407\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9171, Valid Loss: 1.7457\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7458, Valid Loss: 1.5466\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7056, Valid Loss: 1.4878\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.4709, Valid Loss: 2.1614\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7079, Valid Loss: 1.4581\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 30.57 seconds\n",
      "Epoch 4, Train Loss: 0.1108, Valid Loss: 0.0954\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1088, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1042, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.57 seconds\n",
      "Epoch 4, Train Loss: 0.1236, Valid Loss: 0.0955\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1184, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1232, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.59 seconds\n",
      "Epoch 4, Train Loss: 0.1260, Valid Loss: 0.1001\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1136, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1206, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.00 seconds\n",
      "Epoch 4, Train Loss: 0.5584, Valid Loss: 0.5167\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5457, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5345, Valid Loss: 0.5105\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5563, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.94 seconds\n",
      "Epoch 4, Train Loss: 0.6313, Valid Loss: 0.5284\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6344, Valid Loss: 0.5219\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6026, Valid Loss: 0.5159\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6217, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 13.81 seconds\n",
      "Epoch 4, Train Loss: 0.6153, Valid Loss: 0.5228\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6013, Valid Loss: 0.5169\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5892, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5975, Valid Loss: 0.5139\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.31 seconds\n",
      "Epoch 4, Train Loss: 2.0779, Valid Loss: 1.9030\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9590, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9260, Valid Loss: 1.7938\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7952, Valid Loss: 1.8210\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7135, Valid Loss: 1.8302\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9743, Valid Loss: 1.8876\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9197, Valid Loss: 1.8681\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 23.34 seconds\n",
      "Epoch 4, Train Loss: 2.3811, Valid Loss: 1.9273\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1436, Valid Loss: 1.8332\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1113, Valid Loss: 1.8251\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0622, Valid Loss: 1.8434\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0978, Valid Loss: 1.8441\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 16.26 seconds\n",
      "Epoch 4, Train Loss: 2.3479, Valid Loss: 1.9608\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1587, Valid Loss: 1.8456\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1032, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0418, Valid Loss: 1.8313\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 15.07 seconds\n",
      "Epoch 4, Train Loss: 0.1093, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1120, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.81 seconds\n",
      "Epoch 4, Train Loss: 0.1246, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1246, Valid Loss: 0.1213\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1214, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.44 seconds\n",
      "Epoch 4, Train Loss: 0.1218, Valid Loss: 0.1202\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1243, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.04 seconds\n",
      "Epoch 4, Train Loss: 0.5702, Valid Loss: 0.5072\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5682, Valid Loss: 0.5242\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.23 seconds\n",
      "Epoch 4, Train Loss: 0.6647, Valid Loss: 0.5277\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6338, Valid Loss: 0.5185\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6372, Valid Loss: 0.5273\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.03 seconds\n",
      "Epoch 4, Train Loss: 0.6173, Valid Loss: 0.5102\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6194, Valid Loss: 0.5082\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.88 seconds\n",
      "Epoch 4, Train Loss: 3.5167, Valid Loss: 2.6584\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9047, Valid Loss: 2.4603\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9023, Valid Loss: 2.0400\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8414, Valid Loss: 3.0096\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.4401, Valid Loss: 3.3588\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.09 seconds\n",
      "Epoch 4, Train Loss: 5.5432, Valid Loss: 1.9877\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1423, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1117, Valid Loss: 1.8629\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0792, Valid Loss: 1.8725\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0930, Valid Loss: 1.7424\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 2.2907, Valid Loss: 2.5566\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.1051, Valid Loss: 1.8744\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 21.25 seconds\n",
      "Epoch 4, Train Loss: 2.0555, Valid Loss: 1.8283\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0611, Valid Loss: 1.8482\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0664, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.57 seconds\n",
      "Epoch 4, Train Loss: 0.1498, Valid Loss: 0.1020\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1059, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.78 seconds\n",
      "Epoch 4, Train Loss: 0.1366, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1346, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.23 seconds\n",
      "Epoch 4, Train Loss: 0.1406, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1351, Valid Loss: 0.0968\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.74 seconds\n",
      "Epoch 4, Train Loss: 0.6112, Valid Loss: 0.5379\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5537, Valid Loss: 0.5319\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5568, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.51 seconds\n",
      "Epoch 4, Train Loss: 0.9931, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6400, Valid Loss: 0.5172\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6357, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.65 seconds\n",
      "Epoch 4, Train Loss: 0.6302, Valid Loss: 0.5064\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6188, Valid Loss: 0.5160\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.56 seconds\n",
      "Epoch 4, Train Loss: 1.9334, Valid Loss: 1.8702\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0281, Valid Loss: 1.8431\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0057, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9447, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.68 seconds\n",
      "Epoch 4, Train Loss: 2.1818, Valid Loss: 1.8307\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1583, Valid Loss: 1.8255\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1089, Valid Loss: 1.8332\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.40 seconds\n",
      "Epoch 4, Train Loss: 2.0554, Valid Loss: 1.8555\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0544, Valid Loss: 1.8300\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.57 seconds\n",
      "Epoch 4, Train Loss: 0.1153, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1074, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.24 seconds\n",
      "Epoch 4, Train Loss: 0.1540, Valid Loss: 0.0993\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1328, Valid Loss: 0.0963\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1263, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.56 seconds\n",
      "Epoch 4, Train Loss: 0.1306, Valid Loss: 0.1072\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1202, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1209, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.49 seconds\n",
      "Epoch 4, Train Loss: 0.6961, Valid Loss: 0.5122\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6044, Valid Loss: 0.5111\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.80 seconds\n",
      "Epoch 4, Train Loss: 0.6553, Valid Loss: 0.5248\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6586, Valid Loss: 0.5126\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6273, Valid Loss: 0.5110\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.48 seconds\n",
      "Epoch 4, Train Loss: 0.6303, Valid Loss: 0.5126\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6714, Valid Loss: 0.5420\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 8.11 seconds\n",
      "Epoch 4, Train Loss: 2.0042, Valid Loss: 1.8312\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9720, Valid Loss: 1.8247\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.21 seconds\n",
      "Epoch 4, Train Loss: 2.1051, Valid Loss: 1.9295\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1187, Valid Loss: 1.9863\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.2544, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.80 seconds\n",
      "Epoch 4, Train Loss: 2.0607, Valid Loss: 1.9572\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0629, Valid Loss: 1.8320\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.81 seconds\n",
      "Epoch 4, Train Loss: 0.1027, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1056, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.03 seconds\n",
      "Epoch 4, Train Loss: 0.1194, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1207, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.92 seconds\n",
      "Epoch 4, Train Loss: 0.1188, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1185, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.97 seconds\n",
      "Epoch 4, Train Loss: 0.5723, Valid Loss: 0.5127\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.4856, Valid Loss: 0.4804\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4865, Valid Loss: 0.5227\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4346, Valid Loss: 0.5403\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.78 seconds\n",
      "Epoch 4, Train Loss: 0.6380, Valid Loss: 0.5136\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6561, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6047, Valid Loss: 0.5456\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6279, Valid Loss: 0.5286\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.16 seconds\n",
      "Epoch 4, Train Loss: 0.6226, Valid Loss: 0.5148\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6037, Valid Loss: 0.5056\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6055, Valid Loss: 0.5074\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5285, Valid Loss: 0.4321\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5189, Valid Loss: 0.3923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.4459, Valid Loss: 0.5197\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.4173, Valid Loss: 0.4533\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 19.47 seconds\n",
      "Epoch 4, Train Loss: 1.9318, Valid Loss: 1.8103\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8953, Valid Loss: 1.8118\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8457, Valid Loss: 1.9350\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.3841, Valid Loss: 2.4409\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0205, Valid Loss: 2.0472\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.32 seconds\n",
      "Epoch 4, Train Loss: 2.1062, Valid Loss: 1.8347\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0987, Valid Loss: 1.8688\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0668, Valid Loss: 1.8280\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.11 seconds\n",
      "Epoch 4, Train Loss: 2.0739, Valid Loss: 1.8122\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0404, Valid Loss: 1.8520\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9927, Valid Loss: 1.7605\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0749, Valid Loss: 1.8308\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0501, Valid Loss: 1.8522\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.99 seconds\n",
      "Epoch 4, Train Loss: 0.1075, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1086, Valid Loss: 0.0965\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.80 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1269, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1246, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.71 seconds\n",
      "Epoch 4, Train Loss: 0.1145, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1152, Valid Loss: 0.1060\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1213, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.41 seconds\n",
      "Epoch 4, Train Loss: 0.5517, Valid Loss: 0.5087\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5298, Valid Loss: 0.5010\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4604, Valid Loss: 0.5629\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4643, Valid Loss: 0.5975\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4980, Valid Loss: 0.5442\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.01 seconds\n",
      "Epoch 4, Train Loss: 0.6533, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6266, Valid Loss: 0.5040\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6427, Valid Loss: 0.5103\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6377, Valid Loss: 0.5254\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.12 seconds\n",
      "Epoch 4, Train Loss: 0.6230, Valid Loss: 0.5446\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6224, Valid Loss: 0.5116\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6086, Valid Loss: 0.5159\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.55 seconds\n",
      "Epoch 4, Train Loss: 1.9632, Valid Loss: 2.0071\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8197, Valid Loss: 1.9816\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8680, Valid Loss: 2.1701\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.97 seconds\n",
      "Epoch 4, Train Loss: 2.0561, Valid Loss: 1.8279\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0539, Valid Loss: 1.8804\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1099, Valid Loss: 1.9004\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.08 seconds\n",
      "Epoch 4, Train Loss: 2.1434, Valid Loss: 1.8019\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0317, Valid Loss: 1.8357\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0548, Valid Loss: 1.8438\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.12 seconds\n",
      "Epoch 4, Train Loss: 0.1147, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1105, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.65 seconds\n",
      "Epoch 4, Train Loss: 0.1278, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1226, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.38 seconds\n",
      "Epoch 4, Train Loss: 0.1212, Valid Loss: 0.0978\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1206, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.34 seconds\n",
      "Epoch 4, Train Loss: 0.5718, Valid Loss: 0.5257\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5657, Valid Loss: 0.5083\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.81 seconds\n",
      "Epoch 4, Train Loss: 0.6246, Valid Loss: 0.5154\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6338, Valid Loss: 0.5281\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6293, Valid Loss: 0.5203\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.78 seconds\n",
      "Epoch 4, Train Loss: 0.6364, Valid Loss: 0.5629\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6019, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.93 seconds\n",
      "Epoch 4, Train Loss: 2.5831, Valid Loss: 1.8288\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9472, Valid Loss: 1.8289\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9265, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9319, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 1.9253, Valid Loss: 1.8193\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 15.21 seconds\n",
      "Epoch 4, Train Loss: 2.1336, Valid Loss: 1.8722\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0501, Valid Loss: 1.8794\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1108, Valid Loss: 1.8517\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.48 seconds\n",
      "Epoch 4, Train Loss: 2.0768, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0788, Valid Loss: 1.8512\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0271, Valid Loss: 1.8529\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.20 seconds\n",
      "Epoch 4, Train Loss: 0.1150, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1084, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.35 seconds\n",
      "Epoch 4, Train Loss: 0.1290, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1251, Valid Loss: 0.0956\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.18 seconds\n",
      "Epoch 4, Train Loss: 0.1116, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1151, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.22 seconds\n",
      "Epoch 4, Train Loss: 0.5635, Valid Loss: 0.5111\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5631, Valid Loss: 0.5073\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4772, Valid Loss: 0.4786\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4342, Valid Loss: 0.4682\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4229, Valid Loss: 0.4721\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.3711, Valid Loss: 0.4896\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 16.26 seconds\n",
      "Epoch 4, Train Loss: 0.6418, Valid Loss: 0.5243\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6248, Valid Loss: 0.5071\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6053, Valid Loss: 0.5058\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6053, Valid Loss: 0.4695\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6225, Valid Loss: 0.4454\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5236, Valid Loss: 0.5053\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 16.73 seconds\n",
      "Epoch 4, Train Loss: 0.5986, Valid Loss: 0.5164\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6046, Valid Loss: 0.5146\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5654, Valid Loss: 0.5149\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5545, Valid Loss: 0.5528\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5337, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.4712, Valid Loss: 0.3918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.4442, Valid Loss: 0.4231\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.4725, Valid Loss: 0.3942\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 21.13 seconds\n",
      "Epoch 4, Train Loss: 1.9640, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.7227, Valid Loss: 1.7227\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.4700, Valid Loss: 1.8954\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.2256, Valid Loss: 1.8287\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.5281, Valid Loss: 2.2522\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.47 seconds\n",
      "Epoch 4, Train Loss: 2.0749, Valid Loss: 1.8377\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1252, Valid Loss: 1.8358\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0860, Valid Loss: 1.8506\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.49 seconds\n",
      "Epoch 4, Train Loss: 1.9856, Valid Loss: 1.8785\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1849, Valid Loss: 1.8275\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0458, Valid Loss: 1.8421\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 2.0534, Valid Loss: 1.8404\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.61 seconds\n",
      "Epoch 4, Train Loss: 0.1047, Valid Loss: 0.1000\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1033, Valid Loss: 0.0950\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.84 seconds\n",
      "Epoch 4, Train Loss: 0.1245, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1199, Valid Loss: 0.0992\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.14 seconds\n",
      "Epoch 4, Train Loss: 0.1163, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1163, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.92 seconds\n",
      "Epoch 4, Train Loss: 0.5731, Valid Loss: 0.5121\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5680, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.73 seconds\n",
      "Epoch 4, Train Loss: 0.6635, Valid Loss: 0.5512\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6129, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6386, Valid Loss: 0.5253\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.80 seconds\n",
      "Epoch 4, Train Loss: 0.6047, Valid Loss: 0.5076\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6081, Valid Loss: 0.4999\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6032, Valid Loss: 0.5131\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.96 seconds\n",
      "Epoch 4, Train Loss: 1.9122, Valid Loss: 1.7275\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9542, Valid Loss: 1.8233\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9296, Valid Loss: 1.8293\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.78 seconds\n",
      "Epoch 4, Train Loss: 2.0771, Valid Loss: 1.8527\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0805, Valid Loss: 1.8137\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.5654, Valid Loss: 1.8231\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0968, Valid Loss: 1.8487\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.64 seconds\n",
      "Epoch 4, Train Loss: 2.0778, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 4.1512, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0277, Valid Loss: 1.8284\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.20 seconds\n",
      "Epoch 4, Train Loss: 0.1072, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1019, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.88 seconds\n",
      "Epoch 4, Train Loss: 0.1317, Valid Loss: 0.0949\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1204, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.00 seconds\n",
      "Epoch 4, Train Loss: 0.1168, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1136, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.41 seconds\n",
      "Epoch 4, Train Loss: 0.5882, Valid Loss: 0.5269\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5556, Valid Loss: 0.5210\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.93 seconds\n",
      "Epoch 4, Train Loss: 0.6279, Valid Loss: 0.5238\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6319, Valid Loss: 0.5204\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.73 seconds\n",
      "Epoch 4, Train Loss: 0.6178, Valid Loss: 0.5221\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6108, Valid Loss: 0.5170\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.83 seconds\n",
      "Epoch 4, Train Loss: 1.9383, Valid Loss: 1.8316\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9219, Valid Loss: 1.8260\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9333, Valid Loss: 1.8296\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.00 seconds\n",
      "Epoch 4, Train Loss: 2.0951, Valid Loss: 1.8252\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1085, Valid Loss: 1.8411\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 2.0723, Valid Loss: 1.8451\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0736, Valid Loss: 1.8565\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.01 seconds\n",
      "Epoch 4, Train Loss: 2.0345, Valid Loss: 1.8361\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0619, Valid Loss: 1.8261\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0285, Valid Loss: 1.8556\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.59 seconds\n",
      "Epoch 4, Train Loss: 0.1070, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.0977, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1102, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.53 seconds\n",
      "Epoch 4, Train Loss: 0.1320, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1243, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1188, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.66 seconds\n",
      "Epoch 4, Train Loss: 0.1178, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1209, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1199, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.16 seconds\n",
      "Epoch 4, Train Loss: 0.5579, Valid Loss: 0.5124\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5475, Valid Loss: 0.5090\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5554, Valid Loss: 0.5057\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.70 seconds\n",
      "Epoch 4, Train Loss: 0.6371, Valid Loss: 0.5260\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6298, Valid Loss: 0.5200\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6137, Valid Loss: 0.5147\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6199, Valid Loss: 0.5166\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6234, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.83 seconds\n",
      "Epoch 4, Train Loss: 0.5836, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5739, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6080, Valid Loss: 0.5118\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5926, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.17 seconds\n",
      "Epoch 4, Train Loss: 2.1144, Valid Loss: 1.9329\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0086, Valid Loss: 1.8607\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8965, Valid Loss: 1.8171\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8731, Valid Loss: 1.8029\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8435, Valid Loss: 1.7623\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.7530, Valid Loss: 1.6892\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7124, Valid Loss: 1.7943\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.4622, Valid Loss: 1.8575\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 22.34 seconds\n",
      "Epoch 4, Train Loss: 2.3498, Valid Loss: 1.9025\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1902, Valid Loss: 1.8304\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0497, Valid Loss: 1.8252\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0648, Valid Loss: 1.8160\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0135, Valid Loss: 1.8118\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.96 seconds\n",
      "Epoch 4, Train Loss: 2.1985, Valid Loss: 1.8806\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0892, Valid Loss: 1.8304\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0377, Valid Loss: 1.8201\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0214, Valid Loss: 1.8322\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.26 seconds\n",
      "Epoch 4, Train Loss: 0.1072, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1009, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1030, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.08 seconds\n",
      "Epoch 4, Train Loss: 0.1194, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1222, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1188, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.58 seconds\n",
      "Epoch 4, Train Loss: 0.1156, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1133, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1141, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.72 seconds\n",
      "Epoch 4, Train Loss: 0.5502, Valid Loss: 0.5077\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5588, Valid Loss: 0.5060\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5536, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.59 seconds\n",
      "Epoch 4, Train Loss: 0.6256, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6318, Valid Loss: 0.5164\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6148, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6200, Valid Loss: 0.5166\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6183, Valid Loss: 0.5280\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5971, Valid Loss: 0.4996\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.6180, Valid Loss: 0.5124\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.5764, Valid Loss: 0.4826\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.5279, Valid Loss: 0.4934\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 40, Train Loss: 0.5324, Valid Loss: 0.5066\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 44, Train Loss: 0.5557, Valid Loss: 0.4892\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 48, Train Loss: 0.5174, Valid Loss: 0.4858\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Total training time: 32.09 seconds\n",
      "Epoch 4, Train Loss: 0.6109, Valid Loss: 0.5195\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6072, Valid Loss: 0.5104\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5964, Valid Loss: 0.5027\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.55 seconds\n",
      "Epoch 4, Train Loss: 2.1485, Valid Loss: 1.9622\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0121, Valid Loss: 1.8403\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8840, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8527, Valid Loss: 1.8121\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8332, Valid Loss: 2.0495\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.7360, Valid Loss: 1.7802\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.6081, Valid Loss: 1.6899\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5536, Valid Loss: 1.5285\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.2541, Valid Loss: 1.9685\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.4062, Valid Loss: 1.5430\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 27.43 seconds\n",
      "Epoch 4, Train Loss: 2.2075, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0318, Valid Loss: 1.8324\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0125, Valid Loss: 1.8415\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0300, Valid Loss: 1.8240\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9067, Valid Loss: 1.7520\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8855, Valid Loss: 1.7847\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7080, Valid Loss: 1.6396\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6928, Valid Loss: 1.4817\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6479, Valid Loss: 1.5171\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5277, Valid Loss: 1.3952\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train Loss: 1.8043, Valid Loss: 1.7504\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.4974, Valid Loss: 1.4294\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 35.72 seconds\n",
      "Epoch 4, Train Loss: 2.2344, Valid Loss: 1.8787\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0413, Valid Loss: 1.8430\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0134, Valid Loss: 1.8062\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9779, Valid Loss: 1.7472\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8689, Valid Loss: 1.6799\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.7223, Valid Loss: 1.5812\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.4122, Valid Loss: 2.2166\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 2.3349, Valid Loss: 1.9249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 2.0657, Valid Loss: 1.8185\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 22.37 seconds\n",
      "Epoch 4, Train Loss: 0.1056, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1053, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1023, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.40 seconds\n",
      "Epoch 4, Train Loss: 0.1235, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1268, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1234, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.17 seconds\n",
      "Epoch 4, Train Loss: 0.1186, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1145, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1121, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.41 seconds\n",
      "Epoch 4, Train Loss: 0.5684, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5682, Valid Loss: 0.5134\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5566, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5506, Valid Loss: 0.5120\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.68 seconds\n",
      "Epoch 4, Train Loss: 0.6380, Valid Loss: 0.5251\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6250, Valid Loss: 0.5241\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6353, Valid Loss: 0.5226\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.28 seconds\n",
      "Epoch 4, Train Loss: 0.6056, Valid Loss: 0.5216\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5906, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6168, Valid Loss: 0.5207\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6149, Valid Loss: 0.5188\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.84 seconds\n",
      "Epoch 4, Train Loss: 2.0553, Valid Loss: 1.8908\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9674, Valid Loss: 1.8302\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8900, Valid Loss: 1.8152\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8854, Valid Loss: 1.8049\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8272, Valid Loss: 1.7753\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5876, Valid Loss: 1.6912\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.2815, Valid Loss: 2.0275\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 2.0059, Valid Loss: 1.8406\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 25.22 seconds\n",
      "Epoch 4, Train Loss: 2.2425, Valid Loss: 1.8613\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1177, Valid Loss: 1.8247\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1302, Valid Loss: 1.8298\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0427, Valid Loss: 1.8351\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0854, Valid Loss: 1.8210\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 1.9840, Valid Loss: 1.7514\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8839, Valid Loss: 1.6915\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7638, Valid Loss: 1.4833\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7614, Valid Loss: 1.5229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7411, Valid Loss: 1.5365\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6465, Valid Loss: 1.4668\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.6310, Valid Loss: 2.1734\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 36.95 seconds\n",
      "Epoch 4, Train Loss: 2.1995, Valid Loss: 1.8784\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0980, Valid Loss: 1.8256\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0587, Valid Loss: 1.8138\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9774, Valid Loss: 1.7989\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9324, Valid Loss: 1.7123\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8947, Valid Loss: 1.8006\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7904, Valid Loss: 1.6652\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6943, Valid Loss: 1.4563\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.4766, Valid Loss: 1.2419\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5808, Valid Loss: 1.4028\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.3604, Valid Loss: 2.4953\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 33.45 seconds\n",
      "Epoch 4, Train Loss: 0.1287, Valid Loss: 0.0969\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1134, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1097, Valid Loss: 0.1018\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.31 seconds\n",
      "Epoch 4, Train Loss: 0.1417, Valid Loss: 0.0957\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1302, Valid Loss: 0.1271\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.52 seconds\n",
      "Epoch 4, Train Loss: 0.1352, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1209, Valid Loss: 0.1023\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.74 seconds\n",
      "Epoch 4, Train Loss: 0.6117, Valid Loss: 0.5411\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5534, Valid Loss: 0.5081\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.22 seconds\n",
      "Epoch 4, Train Loss: 0.6790, Valid Loss: 0.5096\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6585, Valid Loss: 0.5114\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6349, Valid Loss: 0.5177\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.67 seconds\n",
      "Epoch 4, Train Loss: 0.6315, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6662, Valid Loss: 0.5202\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6517, Valid Loss: 0.5273\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.06 seconds\n",
      "Epoch 4, Train Loss: 1.9847, Valid Loss: 1.8373\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9320, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9478, Valid Loss: 1.8253\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.48 seconds\n",
      "Epoch 4, Train Loss: 2.1552, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1485, Valid Loss: 1.8245\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.67 seconds\n",
      "Epoch 4, Train Loss: 2.1667, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0309, Valid Loss: 1.8253\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.73 seconds\n",
      "Epoch 4, Train Loss: 0.1406, Valid Loss: 0.0979\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1127, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1187, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.19 seconds\n",
      "Epoch 4, Train Loss: 0.1252, Valid Loss: 0.0965\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1284, Valid Loss: 0.1128\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.59 seconds\n",
      "Epoch 4, Train Loss: 0.1366, Valid Loss: 0.0966\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1310, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1201, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.27 seconds\n",
      "Epoch 4, Train Loss: 0.9046, Valid Loss: 0.5147\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5742, Valid Loss: 0.5083\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5649, Valid Loss: 0.5129\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5714, Valid Loss: 0.5200\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.73 seconds\n",
      "Epoch 4, Train Loss: 0.8217, Valid Loss: 0.5190\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6390, Valid Loss: 0.5854\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6722, Valid Loss: 0.5229\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.16 seconds\n",
      "Epoch 4, Train Loss: 0.6146, Valid Loss: 0.5132\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6283, Valid Loss: 0.5333\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.70 seconds\n",
      "Epoch 4, Train Loss: 1.9798, Valid Loss: 1.8557\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9490, Valid Loss: 1.8625\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9409, Valid Loss: 1.8232\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.11 seconds\n",
      "Epoch 4, Train Loss: 2.0588, Valid Loss: 1.8293\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0806, Valid Loss: 1.8292\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0880, Valid Loss: 1.8322\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.62 seconds\n",
      "Epoch 4, Train Loss: 2.1468, Valid Loss: 1.8568\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1048, Valid Loss: 1.8409\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0671, Valid Loss: 1.8698\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.37 seconds\n",
      "Epoch 4, Train Loss: 0.1249, Valid Loss: 0.0963\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1126, Valid Loss: 0.1093\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.78 seconds\n",
      "Epoch 4, Train Loss: 0.1536, Valid Loss: 0.0974\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1212, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1257, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1216, Valid Loss: 0.0943\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 14.40 seconds\n",
      "Epoch 4, Train Loss: 0.1314, Valid Loss: 0.0980\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1196, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.54 seconds\n",
      "Epoch 4, Train Loss: 0.5810, Valid Loss: 0.5402\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5844, Valid Loss: 0.5340\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5795, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5624, Valid Loss: 0.5088\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.76 seconds\n",
      "Epoch 4, Train Loss: 0.6660, Valid Loss: 0.5102\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6565, Valid Loss: 0.5089\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6360, Valid Loss: 0.5355\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.33 seconds\n",
      "Epoch 4, Train Loss: 0.6817, Valid Loss: 0.5143\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6271, Valid Loss: 0.5340\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5894, Valid Loss: 0.5114\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.36 seconds\n",
      "Epoch 4, Train Loss: 1.9383, Valid Loss: 1.8242\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9605, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9530, Valid Loss: 1.8239\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.44 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.2141, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1132, Valid Loss: 1.8311\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0914, Valid Loss: 1.8344\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.19 seconds\n",
      "Epoch 4, Train Loss: 2.0884, Valid Loss: 1.8417\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0520, Valid Loss: 1.8298\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0381, Valid Loss: 1.8289\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.42 seconds\n",
      "Epoch 4, Train Loss: 0.1183, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1038, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.65 seconds\n",
      "Epoch 4, Train Loss: 0.1224, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1336, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.65 seconds\n",
      "Epoch 4, Train Loss: 0.1211, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1240, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.65 seconds\n",
      "Epoch 4, Train Loss: 0.5860, Valid Loss: 0.5129\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5956, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.56 seconds\n",
      "Epoch 4, Train Loss: 0.6430, Valid Loss: 0.5389\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6410, Valid Loss: 0.5182\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.43 seconds\n",
      "Epoch 4, Train Loss: 0.6171, Valid Loss: 0.5210\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6186, Valid Loss: 0.5221\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.29 seconds\n",
      "Epoch 4, Train Loss: 1.9470, Valid Loss: 1.8142\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9404, Valid Loss: 1.8325\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.6978, Valid Loss: 1.7869\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7600, Valid Loss: 1.7958\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.4277, Valid Loss: 2.1478\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.24 seconds\n",
      "Epoch 4, Train Loss: 2.2602, Valid Loss: 1.8948\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0920, Valid Loss: 1.8267\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0438, Valid Loss: 1.8365\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.95 seconds\n",
      "Epoch 4, Train Loss: 2.0309, Valid Loss: 1.8166\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9937, Valid Loss: 1.8281\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0428, Valid Loss: 1.8457\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.90 seconds\n",
      "Epoch 4, Train Loss: 0.1154, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1102, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.52 seconds\n",
      "Epoch 4, Train Loss: 0.1239, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1291, Valid Loss: 0.0954\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.01 seconds\n",
      "Epoch 4, Train Loss: 0.1096, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1230, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.61 seconds\n",
      "Epoch 4, Train Loss: 0.5622, Valid Loss: 0.5087\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5587, Valid Loss: 0.5079\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.58 seconds\n",
      "Epoch 4, Train Loss: 0.6360, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6378, Valid Loss: 0.5197\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6540, Valid Loss: 0.5389\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.23 seconds\n",
      "Epoch 4, Train Loss: 0.5741, Valid Loss: 0.5124\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6214, Valid Loss: 0.5144\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5982, Valid Loss: 0.5148\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.24 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.9049, Valid Loss: 1.8220\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8153, Valid Loss: 1.9843\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0160, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.81 seconds\n",
      "Epoch 4, Train Loss: 2.2183, Valid Loss: 1.8202\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0179, Valid Loss: 1.5860\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1550, Valid Loss: 1.8339\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1439, Valid Loss: 1.8329\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.73 seconds\n",
      "Epoch 4, Train Loss: 2.2879, Valid Loss: 1.8529\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0703, Valid Loss: 1.8374\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0756, Valid Loss: 1.8294\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.00 seconds\n",
      "Epoch 4, Train Loss: 0.1024, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1121, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.22 seconds\n",
      "Epoch 4, Train Loss: 0.1313, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1176, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.44 seconds\n",
      "Epoch 4, Train Loss: 0.1324, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1212, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.29 seconds\n",
      "Epoch 4, Train Loss: 0.5681, Valid Loss: 0.5087\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5413, Valid Loss: 0.5140\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.19 seconds\n",
      "Epoch 4, Train Loss: 0.6464, Valid Loss: 0.5198\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6335, Valid Loss: 0.5370\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6148, Valid Loss: 0.5301\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.36 seconds\n",
      "Epoch 4, Train Loss: 0.5828, Valid Loss: 0.5114\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6136, Valid Loss: 0.5162\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.97 seconds\n",
      "Epoch 4, Train Loss: 2.1622, Valid Loss: 1.8733\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9709, Valid Loss: 1.8246\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9459, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9202, Valid Loss: 1.8246\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.92 seconds\n",
      "Epoch 4, Train Loss: 2.1481, Valid Loss: 1.9357\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1113, Valid Loss: 1.8383\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0765, Valid Loss: 1.8422\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.20 seconds\n",
      "Epoch 4, Train Loss: 2.0934, Valid Loss: 1.8302\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0909, Valid Loss: 1.8260\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0374, Valid Loss: 1.8419\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.14 seconds\n",
      "Epoch 4, Train Loss: 0.1169, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1154, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.0989, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.62 seconds\n",
      "Epoch 4, Train Loss: 0.1297, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1222, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.44 seconds\n",
      "Epoch 4, Train Loss: 0.1229, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1234, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.86 seconds\n",
      "Epoch 4, Train Loss: 0.5809, Valid Loss: 0.5112\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5503, Valid Loss: 0.5119\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5394, Valid Loss: 0.5256\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.75 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.6398, Valid Loss: 0.5118\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6095, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.84 seconds\n",
      "Epoch 4, Train Loss: 0.6383, Valid Loss: 0.5256\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6249, Valid Loss: 0.5220\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5953, Valid Loss: 0.5056\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.51 seconds\n",
      "Epoch 4, Train Loss: 1.9886, Valid Loss: 1.8153\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8000, Valid Loss: 2.1488\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.5596, Valid Loss: 1.8265\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.4299, Valid Loss: 1.7745\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.24 seconds\n",
      "Epoch 4, Train Loss: 2.1368, Valid Loss: 1.8196\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0900, Valid Loss: 1.8026\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0477, Valid Loss: 1.8096\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.3201, Valid Loss: 1.9839\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0314, Valid Loss: 1.7451\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.33 seconds\n",
      "Epoch 4, Train Loss: 2.2040, Valid Loss: 1.8378\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1304, Valid Loss: 1.8193\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8647, Valid Loss: 2.0066\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1110, Valid Loss: 1.8289\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0364, Valid Loss: 1.8254\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.28 seconds\n",
      "Epoch 4, Train Loss: 0.1073, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1084, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.66 seconds\n",
      "Epoch 4, Train Loss: 0.1255, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1287, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.59 seconds\n",
      "Epoch 4, Train Loss: 0.1237, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1125, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.42 seconds\n",
      "Epoch 4, Train Loss: 0.5716, Valid Loss: 0.5105\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5741, Valid Loss: 0.5122\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.54 seconds\n",
      "Epoch 4, Train Loss: 0.6599, Valid Loss: 0.5224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6436, Valid Loss: 0.5262\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.55 seconds\n",
      "Epoch 4, Train Loss: 0.6305, Valid Loss: 0.5461\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6167, Valid Loss: 0.5186\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5979, Valid Loss: 0.5049\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6042, Valid Loss: 0.5197\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5427, Valid Loss: 0.4771\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5719, Valid Loss: 0.5019\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.4675, Valid Loss: 0.4467\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.6544, Valid Loss: 0.4923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.5931, Valid Loss: 0.5021\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 40, Train Loss: 0.4717, Valid Loss: 0.4115\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 44, Train Loss: 0.6432, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 48, Train Loss: 0.4992, Valid Loss: 0.4515\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 31.08 seconds\n",
      "Epoch 4, Train Loss: 1.9567, Valid Loss: 1.8081\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9158, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9455, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.91 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.0598, Valid Loss: 1.8538\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0852, Valid Loss: 1.8573\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0701, Valid Loss: 1.8389\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.71 seconds\n",
      "Epoch 4, Train Loss: 2.1229, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0560, Valid Loss: 1.8322\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0511, Valid Loss: 1.8347\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.31 seconds\n",
      "Epoch 4, Train Loss: 0.1146, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1042, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1097, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.30 seconds\n",
      "Epoch 4, Train Loss: 0.1229, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1305, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1266, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.47 seconds\n",
      "Epoch 4, Train Loss: 0.1201, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1229, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.62 seconds\n",
      "Epoch 4, Train Loss: 0.5451, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5768, Valid Loss: 0.5135\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.73 seconds\n",
      "Epoch 4, Train Loss: 0.6330, Valid Loss: 0.5289\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6378, Valid Loss: 0.5155\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.33 seconds\n",
      "Epoch 4, Train Loss: 0.6286, Valid Loss: 0.5172\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6098, Valid Loss: 0.5222\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.69 seconds\n",
      "Epoch 4, Train Loss: 1.9738, Valid Loss: 1.8202\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0041, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9151, Valid Loss: 1.8308\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.81 seconds\n",
      "Epoch 4, Train Loss: 2.0206, Valid Loss: 1.8303\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0630, Valid Loss: 1.8375\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1313, Valid Loss: 1.8436\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.39 seconds\n",
      "Epoch 4, Train Loss: 2.1122, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1640, Valid Loss: 1.8495\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0104, Valid Loss: 1.8356\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.09 seconds\n",
      "Epoch 4, Train Loss: 0.1349, Valid Loss: 0.1050\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1101, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1054, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1010, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.95 seconds\n",
      "Epoch 4, Train Loss: 0.1423, Valid Loss: 0.1036\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1288, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1319, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1312, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 12.47 seconds\n",
      "Epoch 4, Train Loss: 0.1261, Valid Loss: 0.1002\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1162, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1225, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.37 seconds\n",
      "Epoch 4, Train Loss: 0.5900, Valid Loss: 0.5233\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5551, Valid Loss: 0.5108\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5549, Valid Loss: 0.5102\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.5354, Valid Loss: 0.5098\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.85 seconds\n",
      "Epoch 4, Train Loss: 0.6413, Valid Loss: 0.5494\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6467, Valid Loss: 0.5271\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6528, Valid Loss: 0.5244\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6162, Valid Loss: 0.5196\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6196, Valid Loss: 0.5196\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.6312, Valid Loss: 0.5195\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 15.29 seconds\n",
      "Epoch 4, Train Loss: 0.6237, Valid Loss: 0.5518\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6147, Valid Loss: 0.5298\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5988, Valid Loss: 0.5238\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5938, Valid Loss: 0.5202\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.69 seconds\n",
      "Epoch 4, Train Loss: 2.0987, Valid Loss: 1.9337\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0350, Valid Loss: 1.8982\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9930, Valid Loss: 1.8443\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9036, Valid Loss: 1.8066\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9406, Valid Loss: 1.7951\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8172, Valid Loss: 1.7837\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8002, Valid Loss: 1.7153\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7014, Valid Loss: 1.6948\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.5674, Valid Loss: 1.7171\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5302, Valid Loss: 1.7557\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5426, Valid Loss: 1.8232\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 27.94 seconds\n",
      "Epoch 4, Train Loss: 2.4076, Valid Loss: 1.9354\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2599, Valid Loss: 1.8729\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1271, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1585, Valid Loss: 1.8220\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1419, Valid Loss: 1.8257\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.05 seconds\n",
      "Epoch 4, Train Loss: 2.3552, Valid Loss: 1.9667\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2293, Valid Loss: 1.8906\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0908, Valid Loss: 1.8196\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0524, Valid Loss: 1.8124\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0225, Valid Loss: 1.7775\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0050, Valid Loss: 1.7368\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8753, Valid Loss: 1.7554\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8232, Valid Loss: 1.6935\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.9094, Valid Loss: 1.6724\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.6292, Valid Loss: 1.4910\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5621, Valid Loss: 1.6581\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.6484, Valid Loss: 1.2802\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 32.16 seconds\n",
      "Epoch 4, Train Loss: 0.1100, Valid Loss: 0.0954\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1060, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1112, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.32 seconds\n",
      "Epoch 4, Train Loss: 0.1349, Valid Loss: 0.0996\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1237, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1229, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.65 seconds\n",
      "Epoch 4, Train Loss: 0.1270, Valid Loss: 0.0970\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1165, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1178, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.74 seconds\n",
      "Epoch 4, Train Loss: 0.5647, Valid Loss: 0.5083\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5567, Valid Loss: 0.5103\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5518, Valid Loss: 0.5097\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.21 seconds\n",
      "Epoch 4, Train Loss: 0.6141, Valid Loss: 0.5254\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6448, Valid Loss: 0.5181\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6331, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.03 seconds\n",
      "Epoch 4, Train Loss: 0.6045, Valid Loss: 0.5255\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6164, Valid Loss: 0.5176\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6170, Valid Loss: 0.5169\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6020, Valid Loss: 0.5172\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6130, Valid Loss: 0.5159\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 14.46 seconds\n",
      "Epoch 4, Train Loss: 2.0460, Valid Loss: 1.8956\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9726, Valid Loss: 1.8401\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9468, Valid Loss: 1.7889\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8441, Valid Loss: 1.8063\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7358, Valid Loss: 1.7805\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9211, Valid Loss: 1.8492\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 17.08 seconds\n",
      "Epoch 4, Train Loss: 2.3186, Valid Loss: 1.8894\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1267, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1018, Valid Loss: 1.8111\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0756, Valid Loss: 1.7975\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0015, Valid Loss: 1.8558\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9428, Valid Loss: 1.7719\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8979, Valid Loss: 1.6871\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8873, Valid Loss: 1.6975\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7214, Valid Loss: 1.6676\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.6671, Valid Loss: 1.4055\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 2.6622, Valid Loss: 2.0677\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 2.3905, Valid Loss: 1.9584\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 30.36 seconds\n",
      "Epoch 4, Train Loss: 2.2885, Valid Loss: 1.9264\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0596, Valid Loss: 1.8198\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0176, Valid Loss: 1.8177\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0040, Valid Loss: 1.7741\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9616, Valid Loss: 1.7700\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9194, Valid Loss: 1.6988\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8641, Valid Loss: 1.6524\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7540, Valid Loss: 1.7002\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6241, Valid Loss: 1.6514\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5770, Valid Loss: 1.6022\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.3391, Valid Loss: 1.5472\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 31.10 seconds\n",
      "Epoch 4, Train Loss: 0.1752, Valid Loss: 0.1245\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1134, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1064, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1128, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 13.24 seconds\n",
      "Epoch 4, Train Loss: 0.1637, Valid Loss: 0.1173\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1299, Valid Loss: 0.0943\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1251, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1290, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 14.59 seconds\n",
      "Epoch 4, Train Loss: 0.1419, Valid Loss: 0.1111\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1208, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1265, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.37 seconds\n",
      "Epoch 4, Train Loss: 0.6106, Valid Loss: 0.5557\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5639, Valid Loss: 0.5161\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5665, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5622, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.00 seconds\n",
      "Epoch 4, Train Loss: 0.6706, Valid Loss: 0.5638\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6362, Valid Loss: 0.5344\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6324, Valid Loss: 0.5287\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6598, Valid Loss: 0.5273\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6493, Valid Loss: 0.5254\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.6370, Valid Loss: 0.5241\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 17.04 seconds\n",
      "Epoch 4, Train Loss: 0.6652, Valid Loss: 0.5612\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6278, Valid Loss: 0.5242\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6708, Valid Loss: 0.5211\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6054, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6174, Valid Loss: 0.5176\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.6466, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 18.33 seconds\n",
      "Epoch 4, Train Loss: 2.1694, Valid Loss: 1.9854\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0533, Valid Loss: 1.8908\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0911, Valid Loss: 1.8512\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9482, Valid Loss: 1.8351\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8981, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9374, Valid Loss: 1.8240\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9333, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 22.72 seconds\n",
      "Epoch 4, Train Loss: 2.3744, Valid Loss: 1.9213\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2375, Valid Loss: 1.8525\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1956, Valid Loss: 1.8244\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1109, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1001, Valid Loss: 1.8324\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 15.81 seconds\n",
      "Epoch 4, Train Loss: 2.1767, Valid Loss: 1.8652\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1187, Valid Loss: 1.8296\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0732, Valid Loss: 1.8201\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0408, Valid Loss: 1.8124\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0621, Valid Loss: 1.7991\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9999, Valid Loss: 1.7541\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9594, Valid Loss: 1.7513\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8408, Valid Loss: 1.8112\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6944, Valid Loss: 1.7913\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 2.4934, Valid Loss: 2.2047\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train Loss: 2.3822, Valid Loss: 1.9601\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 32.51 seconds\n",
      "Epoch 4, Train Loss: 0.1272, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1286, Valid Loss: 0.0961\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1187, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.89 seconds\n",
      "Epoch 4, Train Loss: 0.1315, Valid Loss: 0.1030\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1239, Valid Loss: 0.0981\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1273, Valid Loss: 0.1097\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.39 seconds\n",
      "Epoch 4, Train Loss: 0.1497, Valid Loss: 0.1107\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1139, Valid Loss: 0.0962\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.48 seconds\n",
      "Epoch 4, Train Loss: 0.6105, Valid Loss: 0.5571\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5543, Valid Loss: 0.5198\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5302, Valid Loss: 0.5251\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4991, Valid Loss: 0.6183\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.04 seconds\n",
      "Epoch 4, Train Loss: 0.6720, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6389, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.7614, Valid Loss: 0.5099\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.46 seconds\n",
      "Epoch 4, Train Loss: 0.6401, Valid Loss: 0.5282\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6752, Valid Loss: 0.5654\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6106, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6098, Valid Loss: 0.5259\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.87 seconds\n",
      "Epoch 4, Train Loss: 1.9365, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9497, Valid Loss: 1.8274\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9449, Valid Loss: 1.8235\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.65 seconds\n",
      "Epoch 4, Train Loss: 3.6332, Valid Loss: 1.9023\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1120, Valid Loss: 1.8310\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1139, Valid Loss: 1.8305\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0746, Valid Loss: 1.8453\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.34 seconds\n",
      "Epoch 4, Train Loss: 2.0572, Valid Loss: 1.8384\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0505, Valid Loss: 1.8378\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0522, Valid Loss: 1.8623\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.74 seconds\n",
      "Epoch 4, Train Loss: 0.1254, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1558, Valid Loss: 0.1044\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1073, Valid Loss: 0.1069\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.58 seconds\n",
      "Epoch 4, Train Loss: 0.1379, Valid Loss: 0.1089\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1312, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1359, Valid Loss: 0.1526\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.78 seconds\n",
      "Epoch 4, Train Loss: 0.1427, Valid Loss: 0.1221\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1238, Valid Loss: 0.1088\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.61 seconds\n",
      "Epoch 4, Train Loss: 0.6119, Valid Loss: 0.5123\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6482, Valid Loss: 0.5262\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6177, Valid Loss: 0.5247\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.83 seconds\n",
      "Epoch 4, Train Loss: 0.7022, Valid Loss: 0.5092\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6795, Valid Loss: 0.5328\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6381, Valid Loss: 0.5088\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 8.95 seconds\n",
      "Epoch 4, Train Loss: 0.6286, Valid Loss: 0.5082\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6131, Valid Loss: 0.5458\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6123, Valid Loss: 0.5157\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.47 seconds\n",
      "Epoch 4, Train Loss: 6.5894, Valid Loss: 1.9205\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0147, Valid Loss: 1.8227\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0276, Valid Loss: 1.8340\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.23 seconds\n",
      "Epoch 4, Train Loss: 2.1628, Valid Loss: 1.8556\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1286, Valid Loss: 1.8273\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0950, Valid Loss: 1.8550\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.18 seconds\n",
      "Epoch 4, Train Loss: 2.1426, Valid Loss: 1.8232\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0699, Valid Loss: 1.8246\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0706, Valid Loss: 1.8266\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.03 seconds\n",
      "Epoch 4, Train Loss: 0.1318, Valid Loss: 0.0948\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1207, Valid Loss: 0.1182\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1107, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.32 seconds\n",
      "Epoch 4, Train Loss: 0.1405, Valid Loss: 0.1421\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1301, Valid Loss: 0.0952\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1243, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.96 seconds\n",
      "Epoch 4, Train Loss: 0.1268, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1333, Valid Loss: 0.0983\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.82 seconds\n",
      "Epoch 4, Train Loss: 0.6759, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6504, Valid Loss: 0.5178\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5589, Valid Loss: 0.5191\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.13 seconds\n",
      "Epoch 4, Train Loss: 0.6536, Valid Loss: 0.5082\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6377, Valid Loss: 0.5330\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6241, Valid Loss: 0.5097\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.42 seconds\n",
      "Epoch 4, Train Loss: 0.6870, Valid Loss: 0.5553\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6590, Valid Loss: 0.6943\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.57 seconds\n",
      "Epoch 4, Train Loss: 3.0098, Valid Loss: 2.1340\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9895, Valid Loss: 1.8529\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9730, Valid Loss: 1.8443\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.83 seconds\n",
      "Epoch 4, Train Loss: 2.1114, Valid Loss: 1.8774\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0954, Valid Loss: 1.8356\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1026, Valid Loss: 1.9116\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.70 seconds\n",
      "Epoch 4, Train Loss: 2.0223, Valid Loss: 1.8505\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0360, Valid Loss: 1.8532\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0388, Valid Loss: 1.8344\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.93 seconds\n",
      "Epoch 4, Train Loss: 0.1077, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1171, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.80 seconds\n",
      "Epoch 4, Train Loss: 0.1392, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1267, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.87 seconds\n",
      "Epoch 4, Train Loss: 0.1260, Valid Loss: 0.0986\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1194, Valid Loss: 0.0972\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 6.77 seconds\n",
      "Epoch 4, Train Loss: 0.5904, Valid Loss: 0.5140\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.4778, Valid Loss: 0.5887\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4117, Valid Loss: 0.6540\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.45 seconds\n",
      "Epoch 4, Train Loss: 0.6412, Valid Loss: 0.5206\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6483, Valid Loss: 0.5185\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.84 seconds\n",
      "Epoch 4, Train Loss: 0.5948, Valid Loss: 0.6046\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5982, Valid Loss: 0.4911\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5981, Valid Loss: 0.5461\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.30 seconds\n",
      "Epoch 4, Train Loss: 1.9613, Valid Loss: 1.8167\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8992, Valid Loss: 1.8021\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.5506, Valid Loss: 1.9674\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.3958, Valid Loss: 2.3150\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.3762, Valid Loss: 2.9980\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.69 seconds\n",
      "Epoch 4, Train Loss: 2.0914, Valid Loss: 1.8355\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2315, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0179, Valid Loss: 1.6900\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8652, Valid Loss: 1.6020\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.6879, Valid Loss: 2.2559\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5773, Valid Loss: 1.7201\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.5964, Valid Loss: 1.7388\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6615, Valid Loss: 1.5807\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 20.90 seconds\n",
      "Epoch 4, Train Loss: 2.0960, Valid Loss: 1.7999\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0809, Valid Loss: 1.8223\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0454, Valid Loss: 1.8317\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.97 seconds\n",
      "Epoch 4, Train Loss: 0.1045, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1102, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1061, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.29 seconds\n",
      "Epoch 4, Train Loss: 0.1306, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1280, Valid Loss: 0.0969\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.82 seconds\n",
      "Epoch 4, Train Loss: 0.1236, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1254, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.68 seconds\n",
      "Epoch 4, Train Loss: 0.5776, Valid Loss: 0.5151\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5705, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.20 seconds\n",
      "Epoch 4, Train Loss: 0.6484, Valid Loss: 0.5240\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6456, Valid Loss: 0.5207\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.10 seconds\n",
      "Epoch 4, Train Loss: 0.6162, Valid Loss: 0.5075\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6113, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6275, Valid Loss: 0.5257\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.52 seconds\n",
      "Epoch 4, Train Loss: 3.1512, Valid Loss: 1.9990\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0112, Valid Loss: 1.8334\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9737, Valid Loss: 1.8254\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.34 seconds\n",
      "Epoch 4, Train Loss: 2.1172, Valid Loss: 1.8461\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0574, Valid Loss: 1.7536\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1205, Valid Loss: 1.8377\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 2.0884, Valid Loss: 1.8375\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.81 seconds\n",
      "Epoch 4, Train Loss: 2.1323, Valid Loss: 1.8365\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0676, Valid Loss: 1.8392\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0507, Valid Loss: 1.8264\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.43 seconds\n",
      "Epoch 4, Train Loss: 0.1173, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1141, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.83 seconds\n",
      "Epoch 4, Train Loss: 0.1183, Valid Loss: 0.0987\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1287, Valid Loss: 0.0991\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.67 seconds\n",
      "Epoch 4, Train Loss: 0.1184, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1242, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.97 seconds\n",
      "Epoch 4, Train Loss: 0.5699, Valid Loss: 0.5209\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5705, Valid Loss: 0.5151\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.51 seconds\n",
      "Epoch 4, Train Loss: 0.6326, Valid Loss: 0.5292\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6603, Valid Loss: 0.5353\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.68 seconds\n",
      "Epoch 4, Train Loss: 0.5985, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5702, Valid Loss: 0.5157\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6173, Valid Loss: 0.5144\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6416, Valid Loss: 0.5322\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.47 seconds\n",
      "Epoch 4, Train Loss: 1.9566, Valid Loss: 1.8203\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9252, Valid Loss: 1.8329\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9490, Valid Loss: 1.8238\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.36 seconds\n",
      "Epoch 4, Train Loss: 2.1945, Valid Loss: 1.8275\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1327, Valid Loss: 1.8581\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1195, Valid Loss: 1.8359\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.94 seconds\n",
      "Epoch 4, Train Loss: 2.0690, Valid Loss: 1.8382\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0418, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0510, Valid Loss: 1.8390\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.02 seconds\n",
      "Epoch 4, Train Loss: 0.1117, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1024, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.69 seconds\n",
      "Epoch 4, Train Loss: 0.1252, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1354, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.89 seconds\n",
      "Epoch 4, Train Loss: 0.1166, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1308, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.68 seconds\n",
      "Epoch 4, Train Loss: 0.5594, Valid Loss: 0.5111\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5105, Valid Loss: 0.5268\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5096, Valid Loss: 0.5388\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4683, Valid Loss: 0.5359\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.24 seconds\n",
      "Epoch 4, Train Loss: 0.6398, Valid Loss: 0.5483\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6324, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5799, Valid Loss: 0.5098\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5846, Valid Loss: 0.4882\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5051, Valid Loss: 0.4151\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.4950, Valid Loss: 0.4647\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 0.5102, Valid Loss: 0.4609\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.4716, Valid Loss: 0.4659\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 21.10 seconds\n",
      "Epoch 4, Train Loss: 0.6212, Valid Loss: 0.5262\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6168, Valid Loss: 0.5022\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.23 seconds\n",
      "Epoch 4, Train Loss: 2.0037, Valid Loss: 1.8545\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8386, Valid Loss: 1.7907\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.7461, Valid Loss: 1.6406\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.5309, Valid Loss: 1.9611\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.6490, Valid Loss: 2.0474\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.77 seconds\n",
      "Epoch 4, Train Loss: 2.0528, Valid Loss: 1.8131\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1127, Valid Loss: 1.9604\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0613, Valid Loss: 1.8410\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0241, Valid Loss: 1.8429\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.51 seconds\n",
      "Epoch 4, Train Loss: 2.1368, Valid Loss: 1.8198\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0529, Valid Loss: 1.7777\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9386, Valid Loss: 1.9061\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7163, Valid Loss: 1.5627\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.2892, Valid Loss: 3.2012\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5063, Valid Loss: 2.4262\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.4411, Valid Loss: 1.4989\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5629, Valid Loss: 1.4250\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.5553, Valid Loss: 1.5988\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.3663, Valid Loss: 1.5773\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 25.92 seconds\n",
      "Epoch 4, Train Loss: 0.1083, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1021, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.84 seconds\n",
      "Epoch 4, Train Loss: 0.1242, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1161, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.69 seconds\n",
      "Epoch 4, Train Loss: 0.1192, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1182, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.85 seconds\n",
      "Epoch 4, Train Loss: 0.5674, Valid Loss: 0.5096\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5589, Valid Loss: 0.5544\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4695, Valid Loss: 0.4570\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4162, Valid Loss: 0.6435\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4149, Valid Loss: 0.6914\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.63 seconds\n",
      "Epoch 4, Train Loss: 0.6540, Valid Loss: 0.5277\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6418, Valid Loss: 0.5224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.28 seconds\n",
      "Epoch 4, Train Loss: 0.6192, Valid Loss: 0.5233\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6137, Valid Loss: 0.5247\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.96 seconds\n",
      "Epoch 4, Train Loss: 2.0417, Valid Loss: 1.8302\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2703, Valid Loss: 1.9222\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0268, Valid Loss: 1.8231\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9146, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.63 seconds\n",
      "Epoch 4, Train Loss: 2.1465, Valid Loss: 1.8195\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0448, Valid Loss: 1.8132\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 2.1015, Valid Loss: 1.8685\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1196, Valid Loss: 1.8603\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.59 seconds\n",
      "Epoch 4, Train Loss: 2.1821, Valid Loss: 1.8214\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8390, Valid Loss: 2.2198\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0927, Valid Loss: 1.8266\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0601, Valid Loss: 1.8334\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.53 seconds\n",
      "Epoch 4, Train Loss: 0.1122, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1022, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.87 seconds\n",
      "Epoch 4, Train Loss: 0.1305, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1284, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.84 seconds\n",
      "Epoch 4, Train Loss: 0.1162, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1221, Valid Loss: 0.0967\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.02 seconds\n",
      "Epoch 4, Train Loss: 0.6269, Valid Loss: 0.5232\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5755, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.84 seconds\n",
      "Epoch 4, Train Loss: 0.6391, Valid Loss: 0.5202\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6879, Valid Loss: 0.5617\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6602, Valid Loss: 0.5455\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.28 seconds\n",
      "Epoch 4, Train Loss: 0.6105, Valid Loss: 0.5217\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6225, Valid Loss: 0.5231\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.79 seconds\n",
      "Epoch 4, Train Loss: 2.0857, Valid Loss: 1.8523\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9600, Valid Loss: 1.8247\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9836, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.17 seconds\n",
      "Epoch 4, Train Loss: 2.0894, Valid Loss: 1.8261\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1259, Valid Loss: 1.8397\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1090, Valid Loss: 1.8419\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.77 seconds\n",
      "Epoch 4, Train Loss: 2.0631, Valid Loss: 1.8197\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1162, Valid Loss: 1.8257\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0625, Valid Loss: 1.8297\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.68 seconds\n",
      "Epoch 4, Train Loss: 0.1075, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1130, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1164, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.04 seconds\n",
      "Epoch 4, Train Loss: 0.1348, Valid Loss: 0.1009\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1317, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1262, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.43 seconds\n",
      "Epoch 4, Train Loss: 0.1250, Valid Loss: 0.0961\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1223, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1169, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.10 seconds\n",
      "Epoch 4, Train Loss: 0.5759, Valid Loss: 0.5206\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5320, Valid Loss: 0.5102\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5408, Valid Loss: 0.5116\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5372, Valid Loss: 0.5104\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.96 seconds\n",
      "Epoch 4, Train Loss: 0.6509, Valid Loss: 0.5504\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6317, Valid Loss: 0.5225\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.6128, Valid Loss: 0.5206\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.29 seconds\n",
      "Epoch 4, Train Loss: 0.6195, Valid Loss: 0.5215\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5979, Valid Loss: 0.5139\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6135, Valid Loss: 0.5139\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6134, Valid Loss: 0.5116\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6049, Valid Loss: 0.5073\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5804, Valid Loss: 0.4819\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.5475, Valid Loss: 0.4766\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.4940, Valid Loss: 0.4381\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.4962, Valid Loss: 0.4016\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 40, Train Loss: 0.5188, Valid Loss: 0.4231\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 44, Train Loss: 0.4803, Valid Loss: 0.4211\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 30.29 seconds\n",
      "Epoch 4, Train Loss: 2.0717, Valid Loss: 1.9142\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0401, Valid Loss: 1.8892\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0156, Valid Loss: 1.8619\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9557, Valid Loss: 1.8302\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9037, Valid Loss: 1.8124\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8919, Valid Loss: 1.8082\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8900, Valid Loss: 1.7741\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8235, Valid Loss: 1.7743\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6592, Valid Loss: 1.8172\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.6188, Valid Loss: 1.7104\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5427, Valid Loss: 1.7241\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.5679, Valid Loss: 1.5954\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 33.58 seconds\n",
      "Epoch 4, Train Loss: 2.3700, Valid Loss: 1.9161\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2612, Valid Loss: 1.8698\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1607, Valid Loss: 1.8254\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0796, Valid Loss: 1.8251\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0699, Valid Loss: 1.8307\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 15.11 seconds\n",
      "Epoch 4, Train Loss: 2.1467, Valid Loss: 1.8525\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1003, Valid Loss: 1.8284\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0742, Valid Loss: 1.8154\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0280, Valid Loss: 1.8165\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.84 seconds\n",
      "Epoch 4, Train Loss: 0.1034, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1097, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1056, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.40 seconds\n",
      "Epoch 4, Train Loss: 0.1243, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1210, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1230, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.62 seconds\n",
      "Epoch 4, Train Loss: 0.1168, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1181, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1130, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.52 seconds\n",
      "Epoch 4, Train Loss: 0.5386, Valid Loss: 0.5085\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5730, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5659, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.37 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.6061, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6310, Valid Loss: 0.5159\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6296, Valid Loss: 0.5158\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.92 seconds\n",
      "Epoch 4, Train Loss: 0.6351, Valid Loss: 0.5105\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5974, Valid Loss: 0.5108\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6255, Valid Loss: 0.5134\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.32 seconds\n",
      "Epoch 4, Train Loss: 2.0985, Valid Loss: 1.9292\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9265, Valid Loss: 1.8161\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9012, Valid Loss: 1.7841\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8333, Valid Loss: 1.8345\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.6261, Valid Loss: 1.7578\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5454, Valid Loss: 1.7079\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.4845, Valid Loss: 1.8231\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.93 seconds\n",
      "Epoch 4, Train Loss: 2.2794, Valid Loss: 1.8672\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0898, Valid Loss: 1.8292\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0899, Valid Loss: 1.8273\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0206, Valid Loss: 1.8164\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9650, Valid Loss: 1.7708\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9406, Valid Loss: 1.7725\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9042, Valid Loss: 1.7767\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9733, Valid Loss: 1.6569\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7059, Valid Loss: 1.7395\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7833, Valid Loss: 1.8182\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6829, Valid Loss: 1.2854\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.6165, Valid Loss: 1.5040\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 32.12 seconds\n",
      "Epoch 4, Train Loss: 2.2119, Valid Loss: 1.8806\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0744, Valid Loss: 1.8108\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9570, Valid Loss: 1.8092\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9731, Valid Loss: 1.7748\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9467, Valid Loss: 1.7552\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9417, Valid Loss: 1.6700\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8024, Valid Loss: 1.6907\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7217, Valid Loss: 1.5263\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.5815, Valid Loss: 1.5262\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5905, Valid Loss: 1.6617\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5650, Valid Loss: 1.3095\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.6956, Valid Loss: 1.7356\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 32.89 seconds\n",
      "Epoch 4, Train Loss: 0.1209, Valid Loss: 0.0975\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1134, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1084, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.93 seconds\n",
      "Epoch 4, Train Loss: 0.1384, Valid Loss: 0.1019\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1221, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1317, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1308, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 20, Train Loss: 0.1229, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 14.03 seconds\n",
      "Epoch 4, Train Loss: 0.1359, Valid Loss: 0.0987\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1202, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1116, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.01 seconds\n",
      "Epoch 4, Train Loss: 0.5778, Valid Loss: 0.5251\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6031, Valid Loss: 0.5161\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5991, Valid Loss: 0.5147\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5790, Valid Loss: 0.5157\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5757, Valid Loss: 0.5155\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 15.50 seconds\n",
      "Epoch 4, Train Loss: 0.6357, Valid Loss: 0.5439\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6580, Valid Loss: 0.5260\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6424, Valid Loss: 0.5270\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6422, Valid Loss: 0.5267\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.96 seconds\n",
      "Epoch 4, Train Loss: 0.6284, Valid Loss: 0.5541\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6020, Valid Loss: 0.5271\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5928, Valid Loss: 0.5267\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5998, Valid Loss: 0.5257\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.12 seconds\n",
      "Epoch 4, Train Loss: 2.0069, Valid Loss: 1.8647\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9635, Valid Loss: 1.8359\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8873, Valid Loss: 1.8086\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7195, Valid Loss: 1.7764\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7032, Valid Loss: 1.7544\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.6000, Valid Loss: 1.7826\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.5851, Valid Loss: 1.7929\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5288, Valid Loss: 1.7959\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 23.74 seconds\n",
      "Epoch 4, Train Loss: 2.3139, Valid Loss: 1.8883\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1394, Valid Loss: 1.8213\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0925, Valid Loss: 1.8359\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0552, Valid Loss: 1.8261\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.37 seconds\n",
      "Epoch 4, Train Loss: 2.3165, Valid Loss: 1.9421\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0931, Valid Loss: 1.8222\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0132, Valid Loss: 1.8091\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0191, Valid Loss: 1.7797\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8984, Valid Loss: 1.6656\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8497, Valid Loss: 1.5963\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7379, Valid Loss: 1.6731\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6241, Valid Loss: 1.5221\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.4889, Valid Loss: 1.4245\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.3669, Valid Loss: 1.4156\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.3612, Valid Loss: 1.3761\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.2410, Valid Loss: 1.4474\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 35.96 seconds\n",
      "Epoch 4, Train Loss: 0.1485, Valid Loss: 0.0951\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1063, Valid Loss: 0.1209\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.20 seconds\n",
      "Epoch 4, Train Loss: 0.1320, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1225, Valid Loss: 0.1024\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1221, Valid Loss: 0.0899\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.68 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1442, Valid Loss: 0.1144\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1205, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.80 seconds\n",
      "Epoch 4, Train Loss: 0.8041, Valid Loss: 0.5697\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5760, Valid Loss: 0.5985\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6196, Valid Loss: 0.5588\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.67 seconds\n",
      "Epoch 4, Train Loss: 0.7033, Valid Loss: 0.5746\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6618, Valid Loss: 0.5093\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6429, Valid Loss: 0.5042\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6336, Valid Loss: 0.5131\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.60 seconds\n",
      "Epoch 4, Train Loss: 0.6302, Valid Loss: 0.5567\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6201, Valid Loss: 0.5338\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6172, Valid Loss: 0.5146\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6049, Valid Loss: 0.5092\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6055, Valid Loss: 0.5158\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.54 seconds\n",
      "Epoch 4, Train Loss: 1.9658, Valid Loss: 1.8317\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.7615, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9499, Valid Loss: 1.8325\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.73 seconds\n",
      "Epoch 4, Train Loss: 2.3543, Valid Loss: 1.8423\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0939, Valid Loss: 1.8282\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.5442, Valid Loss: 1.8311\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.71 seconds\n",
      "Epoch 4, Train Loss: 2.0692, Valid Loss: 1.8265\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0587, Valid Loss: 1.8729\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0490, Valid Loss: 1.8380\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.77 seconds\n",
      "Epoch 4, Train Loss: 0.1404, Valid Loss: 0.1198\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1145, Valid Loss: 0.1470\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1171, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.22 seconds\n",
      "Epoch 4, Train Loss: 0.1584, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1392, Valid Loss: 0.0955\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.45 seconds\n",
      "Epoch 4, Train Loss: 0.1455, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1482, Valid Loss: 0.1285\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.36 seconds\n",
      "Epoch 4, Train Loss: 0.5508, Valid Loss: 0.5286\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6346, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6120, Valid Loss: 0.5136\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.03 seconds\n",
      "Epoch 4, Train Loss: 0.7842, Valid Loss: 0.5939\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6476, Valid Loss: 0.5253\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6307, Valid Loss: 0.5133\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.66 seconds\n",
      "Epoch 4, Train Loss: 0.7048, Valid Loss: 0.5967\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6719, Valid Loss: 0.5230\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.66 seconds\n",
      "Epoch 4, Train Loss: 1.9356, Valid Loss: 1.8771\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9454, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.73 seconds\n",
      "Epoch 4, Train Loss: 2.0393, Valid Loss: 1.8273\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1049, Valid Loss: 1.8973\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0943, Valid Loss: 1.8599\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.19 seconds\n",
      "Epoch 4, Train Loss: 2.0659, Valid Loss: 1.9072\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.0660, Valid Loss: 1.8534\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.77 seconds\n",
      "Epoch 4, Train Loss: 0.1226, Valid Loss: 0.1047\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1319, Valid Loss: 0.1160\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1125, Valid Loss: 0.0981\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.28 seconds\n",
      "Epoch 4, Train Loss: 0.1349, Valid Loss: 0.1212\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1290, Valid Loss: 0.0964\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1193, Valid Loss: 0.1188\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.68 seconds\n",
      "Epoch 4, Train Loss: 0.1234, Valid Loss: 0.1030\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1176, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.95 seconds\n",
      "Epoch 4, Train Loss: 0.5677, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6175, Valid Loss: 0.5166\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.22 seconds\n",
      "Epoch 4, Train Loss: 0.6462, Valid Loss: 0.5100\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6412, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.20 seconds\n",
      "Epoch 4, Train Loss: 0.6413, Valid Loss: 0.5096\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6106, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.14 seconds\n",
      "Epoch 4, Train Loss: 1.9493, Valid Loss: 1.8250\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9869, Valid Loss: 1.8332\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9508, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.87 seconds\n",
      "Epoch 4, Train Loss: 2.1287, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1640, Valid Loss: 1.9415\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1179, Valid Loss: 1.8313\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.24 seconds\n",
      "Epoch 4, Train Loss: 2.1086, Valid Loss: 1.8427\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0335, Valid Loss: 1.8243\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0462, Valid Loss: 1.8542\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.38 seconds\n",
      "Epoch 4, Train Loss: 0.1123, Valid Loss: 0.1108\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1084, Valid Loss: 0.0945\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.81 seconds\n",
      "Epoch 4, Train Loss: 0.1261, Valid Loss: 0.0973\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1190, Valid Loss: 0.0956\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.86 seconds\n",
      "Epoch 4, Train Loss: 0.1181, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1148, Valid Loss: 0.0961\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.85 seconds\n",
      "Epoch 4, Train Loss: 0.5279, Valid Loss: 0.5115\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5578, Valid Loss: 0.5055\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4802, Valid Loss: 0.5580\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5189, Valid Loss: 0.5247\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4873, Valid Loss: 0.5311\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.66 seconds\n",
      "Epoch 4, Train Loss: 0.6299, Valid Loss: 0.5291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6307, Valid Loss: 0.5067\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5920, Valid Loss: 0.5608\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6128, Valid Loss: 0.5222\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4991, Valid Loss: 0.4295\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5381, Valid Loss: 0.5728\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.5498, Valid Loss: 0.3874\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.4957, Valid Loss: 0.4319\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train Loss: 0.4658, Valid Loss: 0.4753\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 26.89 seconds\n",
      "Epoch 4, Train Loss: 0.6161, Valid Loss: 0.5293\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5722, Valid Loss: 0.4874\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5782, Valid Loss: 0.4791\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6021, Valid Loss: 0.5319\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5753, Valid Loss: 0.4992\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 16.15 seconds\n",
      "Epoch 4, Train Loss: 1.9827, Valid Loss: 1.8216\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9663, Valid Loss: 1.8460\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9373, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.39 seconds\n",
      "Epoch 4, Train Loss: 2.1223, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.4562, Valid Loss: 2.1541\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0597, Valid Loss: 1.8925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8252, Valid Loss: 1.8693\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9544, Valid Loss: 1.9944\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.73 seconds\n",
      "Epoch 4, Train Loss: 2.0213, Valid Loss: 1.8506\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0535, Valid Loss: 1.7788\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8929, Valid Loss: 1.7563\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9199, Valid Loss: 1.7302\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.18 seconds\n",
      "Epoch 4, Train Loss: 0.1088, Valid Loss: 0.0963\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1187, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1115, Valid Loss: 0.1044\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.21 seconds\n",
      "Epoch 4, Train Loss: 0.1314, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1223, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.88 seconds\n",
      "Epoch 4, Train Loss: 0.1181, Valid Loss: 0.0951\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1228, Valid Loss: 0.0966\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.90 seconds\n",
      "Epoch 4, Train Loss: 0.6033, Valid Loss: 0.5092\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5775, Valid Loss: 0.5059\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.79 seconds\n",
      "Epoch 4, Train Loss: 0.6651, Valid Loss: 0.5436\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6374, Valid Loss: 0.5246\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6541, Valid Loss: 0.5358\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.47 seconds\n",
      "Epoch 4, Train Loss: 0.6131, Valid Loss: 0.5337\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6014, Valid Loss: 0.5038\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6727, Valid Loss: 0.5171\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6132, Valid Loss: 0.5161\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5839, Valid Loss: 0.5050\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.6000, Valid Loss: 0.5176\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.6214, Valid Loss: 0.5311\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 17.99 seconds\n",
      "Epoch 4, Train Loss: 3.5794, Valid Loss: 1.8235\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9761, Valid Loss: 1.8233\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9708, Valid Loss: 1.8236\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.00 seconds\n",
      "Epoch 4, Train Loss: 3.0496, Valid Loss: 1.8201\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0618, Valid Loss: 1.8275\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0173, Valid Loss: 1.9538\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.34 seconds\n",
      "Epoch 4, Train Loss: 2.0690, Valid Loss: 1.7998\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.0887, Valid Loss: 1.8344\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0546, Valid Loss: 1.8298\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.14 seconds\n",
      "Epoch 4, Train Loss: 0.1081, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1113, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1042, Valid Loss: 0.1011\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.22 seconds\n",
      "Epoch 4, Train Loss: 0.1343, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1283, Valid Loss: 0.0980\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.66 seconds\n",
      "Epoch 4, Train Loss: 0.1271, Valid Loss: 0.1116\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1238, Valid Loss: 0.1007\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.42 seconds\n",
      "Epoch 4, Train Loss: 0.5888, Valid Loss: 0.5335\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5568, Valid Loss: 0.5130\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.45 seconds\n",
      "Epoch 4, Train Loss: 0.6542, Valid Loss: 0.5190\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5977, Valid Loss: 0.5103\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.54 seconds\n",
      "Epoch 4, Train Loss: 0.6353, Valid Loss: 0.5292\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6192, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.45 seconds\n",
      "Epoch 4, Train Loss: 1.9322, Valid Loss: 1.8191\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.7946, Valid Loss: 1.7258\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.6055, Valid Loss: 1.7692\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.6234, Valid Loss: 1.8584\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.90 seconds\n",
      "Epoch 4, Train Loss: 2.2224, Valid Loss: 1.8678\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2913, Valid Loss: 1.8294\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1180, Valid Loss: 1.8546\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.15 seconds\n",
      "Epoch 4, Train Loss: 2.0376, Valid Loss: 1.8253\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1043, Valid Loss: 1.8663\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0530, Valid Loss: 1.8261\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.73 seconds\n",
      "Epoch 4, Train Loss: 0.1144, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1120, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.64 seconds\n",
      "Epoch 4, Train Loss: 0.1263, Valid Loss: 0.0959\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1217, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.76 seconds\n",
      "Epoch 4, Train Loss: 0.1202, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1282, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.76 seconds\n",
      "Epoch 4, Train Loss: 0.5368, Valid Loss: 0.5088\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5406, Valid Loss: 0.5162\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5349, Valid Loss: 0.5074\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4655, Valid Loss: 0.5562\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4043, Valid Loss: 0.5026\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 14.65 seconds\n",
      "Epoch 4, Train Loss: 0.6033, Valid Loss: 0.5263\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6229, Valid Loss: 0.5148\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.15 seconds\n",
      "Epoch 4, Train Loss: 0.6110, Valid Loss: 0.5220\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6031, Valid Loss: 0.5024\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6315, Valid Loss: 0.5258\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5291, Valid Loss: 0.5425\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4941, Valid Loss: 0.4873\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.4965, Valid Loss: 0.4839\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.4777, Valid Loss: 0.4686\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 17.38 seconds\n",
      "Epoch 4, Train Loss: 1.9453, Valid Loss: 1.8154\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1276, Valid Loss: 1.8711\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9705, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9277, Valid Loss: 1.8114\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.75 seconds\n",
      "Epoch 4, Train Loss: 2.1092, Valid Loss: 1.8236\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0672, Valid Loss: 1.8204\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9503, Valid Loss: 1.7699\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0692, Valid Loss: 1.8488\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0609, Valid Loss: 1.8198\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.05 seconds\n",
      "Epoch 4, Train Loss: 2.0880, Valid Loss: 1.8220\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0336, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.3288, Valid Loss: 3.0951\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.70 seconds\n",
      "Epoch 4, Train Loss: 0.1081, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1120, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.74 seconds\n",
      "Epoch 4, Train Loss: 0.1198, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1206, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.80 seconds\n",
      "Epoch 4, Train Loss: 0.1236, Valid Loss: 0.0968\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1158, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.81 seconds\n",
      "Epoch 4, Train Loss: 0.5481, Valid Loss: 0.5146\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5376, Valid Loss: 0.4782\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4588, Valid Loss: 0.5715\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4518, Valid Loss: 0.5042\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.98 seconds\n",
      "Epoch 4, Train Loss: 0.6211, Valid Loss: 0.5200\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6115, Valid Loss: 0.5163\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6068, Valid Loss: 0.5185\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6414, Valid Loss: 0.5354\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6036, Valid Loss: 0.5040\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.26 seconds\n",
      "Epoch 4, Train Loss: 0.6207, Valid Loss: 0.5312\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6573, Valid Loss: 0.5261\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6056, Valid Loss: 0.4939\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6081, Valid Loss: 0.5187\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.18 seconds\n",
      "Epoch 4, Train Loss: 1.9570, Valid Loss: 1.8304\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0477, Valid Loss: 1.8162\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8368, Valid Loss: 1.8089\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.3814, Valid Loss: 2.6483\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.80 seconds\n",
      "Epoch 4, Train Loss: 2.1394, Valid Loss: 1.8314\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0949, Valid Loss: 1.7193\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0668, Valid Loss: 1.8298\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0685, Valid Loss: 1.8256\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.79 seconds\n",
      "Epoch 4, Train Loss: 2.0996, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2928, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0675, Valid Loss: 1.8279\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 2.0498, Valid Loss: 1.8418\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.92 seconds\n",
      "Epoch 4, Train Loss: 0.1082, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1149, Valid Loss: 0.0973\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 862.64 seconds\n",
      "Epoch 4, Train Loss: 0.1319, Valid Loss: 0.0962\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1253, Valid Loss: 0.0947\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.33 seconds\n",
      "Epoch 4, Train Loss: 0.1182, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1154, Valid Loss: 0.0999\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.14 seconds\n",
      "Epoch 4, Train Loss: 0.6020, Valid Loss: 0.5263\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5743, Valid Loss: 0.5218\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5404, Valid Loss: 0.5201\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.77 seconds\n",
      "Epoch 4, Train Loss: 0.6909, Valid Loss: 0.5328\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6210, Valid Loss: 0.5185\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.10 seconds\n",
      "Epoch 4, Train Loss: 0.5641, Valid Loss: 0.5081\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6134, Valid Loss: 0.5204\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.49 seconds\n",
      "Epoch 4, Train Loss: 1.9664, Valid Loss: 1.8168\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9468, Valid Loss: 1.8235\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9192, Valid Loss: 1.8230\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.30 seconds\n",
      "Epoch 4, Train Loss: 2.1586, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1032, Valid Loss: 1.8387\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0821, Valid Loss: 1.8366\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.62 seconds\n",
      "Epoch 4, Train Loss: 2.0732, Valid Loss: 1.8282\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0641, Valid Loss: 1.8153\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1136, Valid Loss: 1.8285\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0334, Valid Loss: 1.8341\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.69 seconds\n",
      "Epoch 4, Train Loss: 0.1096, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1088, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1072, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.86 seconds\n",
      "Epoch 4, Train Loss: 0.1283, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1301, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1257, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.24 seconds\n",
      "Epoch 4, Train Loss: 0.1274, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1201, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1261, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.97 seconds\n",
      "Epoch 4, Train Loss: 0.5404, Valid Loss: 0.5117\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5742, Valid Loss: 0.5132\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5678, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.18 seconds\n",
      "Epoch 4, Train Loss: 0.6340, Valid Loss: 0.5230\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6476, Valid Loss: 0.5229\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6030, Valid Loss: 0.5109\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6065, Valid Loss: 0.5143\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6291, Valid Loss: 0.5036\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.36 seconds\n",
      "Epoch 4, Train Loss: 0.6515, Valid Loss: 0.5293\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6103, Valid Loss: 0.5172\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.5900, Valid Loss: 0.5164\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6018, Valid Loss: 0.5181\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6119, Valid Loss: 0.4999\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5703, Valid Loss: 0.4907\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.5462, Valid Loss: 0.4553\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.5309, Valid Loss: 0.4409\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.5218, Valid Loss: 0.4324\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 40, Train Loss: 0.4908, Valid Loss: 0.4265\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 24.66 seconds\n",
      "Epoch 4, Train Loss: 2.0370, Valid Loss: 1.8854\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0034, Valid Loss: 1.8518\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9518, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9242, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9147, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8362, Valid Loss: 1.8158\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8622, Valid Loss: 1.7392\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6687, Valid Loss: 1.6456\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.5500, Valid Loss: 1.7849\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.4203, Valid Loss: 1.9338\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 25.98 seconds\n",
      "Epoch 4, Train Loss: 2.2147, Valid Loss: 1.8534\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1437, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0877, Valid Loss: 1.8246\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1106, Valid Loss: 1.8306\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.42 seconds\n",
      "Epoch 4, Train Loss: 2.2056, Valid Loss: 1.8841\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1027, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0101, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0268, Valid Loss: 1.8230\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0121, Valid Loss: 1.8123\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9904, Valid Loss: 1.8205\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9815, Valid Loss: 1.8167\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7917, Valid Loss: 1.7478\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8462, Valid Loss: 1.7276\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7145, Valid Loss: 1.8556\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6788, Valid Loss: 1.6518\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.4091, Valid Loss: 1.8429\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 32.10 seconds\n",
      "Epoch 4, Train Loss: 0.1099, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1092, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1059, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.25 seconds\n",
      "Epoch 4, Train Loss: 0.1231, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1228, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1230, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.26 seconds\n",
      "Epoch 4, Train Loss: 0.1181, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1204, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1147, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.67 seconds\n",
      "Epoch 4, Train Loss: 0.5760, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5536, Valid Loss: 0.5100\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5782, Valid Loss: 0.5104\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.30 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.6298, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6406, Valid Loss: 0.5239\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6393, Valid Loss: 0.5206\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.19 seconds\n",
      "Epoch 4, Train Loss: 0.6105, Valid Loss: 0.5100\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5943, Valid Loss: 0.5094\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6144, Valid Loss: 0.5037\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.25 seconds\n",
      "Epoch 4, Train Loss: 2.0667, Valid Loss: 1.9030\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9349, Valid Loss: 1.8260\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8363, Valid Loss: 1.7958\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.6418, Valid Loss: 1.7526\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.6141, Valid Loss: 1.6532\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5143, Valid Loss: 1.8076\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9157, Valid Loss: 1.8433\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.20 seconds\n",
      "Epoch 4, Train Loss: 2.3089, Valid Loss: 1.8853\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0728, Valid Loss: 1.8327\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0854, Valid Loss: 1.8194\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0598, Valid Loss: 1.8254\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.28 seconds\n",
      "Epoch 4, Train Loss: 2.2469, Valid Loss: 1.8966\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0481, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9925, Valid Loss: 1.8114\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9590, Valid Loss: 1.7857\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0248, Valid Loss: 1.7865\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8631, Valid Loss: 1.6828\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8674, Valid Loss: 1.6562\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8278, Valid Loss: 1.5110\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6094, Valid Loss: 1.5597\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5335, Valid Loss: 1.3479\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.7297, Valid Loss: 1.4269\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.2686, Valid Loss: 1.0913\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 33.49 seconds\n",
      "Epoch 4, Train Loss: 0.1115, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1095, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1020, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.24 seconds\n",
      "Epoch 4, Train Loss: 0.1248, Valid Loss: 0.0956\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1321, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1191, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.66 seconds\n",
      "Epoch 4, Train Loss: 0.1286, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1153, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1198, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.20 seconds\n",
      "Epoch 4, Train Loss: 0.5510, Valid Loss: 0.5118\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5783, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5393, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.75 seconds\n",
      "Epoch 4, Train Loss: 0.6283, Valid Loss: 0.5376\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6184, Valid Loss: 0.5275\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6194, Valid Loss: 0.5291\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6309, Valid Loss: 0.5271\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 12.79 seconds\n",
      "Epoch 4, Train Loss: 0.5968, Valid Loss: 0.5191\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6376, Valid Loss: 0.5240\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6203, Valid Loss: 0.5181\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 674.19 seconds\n",
      "Epoch 4, Train Loss: 2.1547, Valid Loss: 1.9684\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0523, Valid Loss: 1.8756\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9302, Valid Loss: 1.8072\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8631, Valid Loss: 1.8312\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8279, Valid Loss: 1.7541\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.6728, Valid Loss: 1.7680\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.4817, Valid Loss: 1.8374\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 2.0180, Valid Loss: 1.8537\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 24.75 seconds\n",
      "Epoch 4, Train Loss: 2.2703, Valid Loss: 1.8660\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1151, Valid Loss: 1.8220\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1063, Valid Loss: 1.8349\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1117, Valid Loss: 1.8414\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.72 seconds\n",
      "Epoch 4, Train Loss: 2.2420, Valid Loss: 1.8874\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1111, Valid Loss: 1.8182\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0319, Valid Loss: 1.8074\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9606, Valid Loss: 1.7638\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9676, Valid Loss: 1.7496\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9094, Valid Loss: 1.6987\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8760, Valid Loss: 1.7597\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6812, Valid Loss: 1.4821\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7161, Valid Loss: 1.8159\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.4870, Valid Loss: 1.3119\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.2861, Valid Loss: 1.6082\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.1796, Valid Loss: 1.7684\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.5, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 36.32 seconds\n",
      "Epoch 4, Train Loss: 0.1171, Valid Loss: 0.2480\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1075, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.84 seconds\n",
      "Epoch 4, Train Loss: 0.1478, Valid Loss: 0.1125\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1290, Valid Loss: 0.1035\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1228, Valid Loss: 0.0998\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.51 seconds\n",
      "Epoch 4, Train Loss: 0.1518, Valid Loss: 0.1526\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1198, Valid Loss: 0.0991\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.31 seconds\n",
      "Epoch 4, Train Loss: 0.5639, Valid Loss: 0.5540\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5291, Valid Loss: 0.5688\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.24 seconds\n",
      "Epoch 4, Train Loss: 0.6860, Valid Loss: 0.5552\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6425, Valid Loss: 0.5111\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6769, Valid Loss: 0.5191\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.97 seconds\n",
      "Epoch 4, Train Loss: 0.6643, Valid Loss: 0.5078\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6168, Valid Loss: 0.5316\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.72 seconds\n",
      "Epoch 4, Train Loss: 1.9622, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9505, Valid Loss: 1.8240\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8220, Valid Loss: 3.4829\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 8.58 seconds\n",
      "Epoch 4, Train Loss: 2.1056, Valid Loss: 1.8328\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1312, Valid Loss: 1.8267\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0932, Valid Loss: 1.8383\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.41 seconds\n",
      "Epoch 4, Train Loss: 2.0596, Valid Loss: 1.8199\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.3866, Valid Loss: 1.8273\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0204, Valid Loss: 1.8637\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.47 seconds\n",
      "Epoch 4, Train Loss: 0.1610, Valid Loss: 0.1043\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1241, Valid Loss: 0.0947\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1165, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.12 seconds\n",
      "Epoch 4, Train Loss: 0.1453, Valid Loss: 0.0978\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1341, Valid Loss: 0.1088\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1325, Valid Loss: 0.0949\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.81 seconds\n",
      "Epoch 4, Train Loss: 0.1349, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1280, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.62 seconds\n",
      "Epoch 4, Train Loss: 0.6908, Valid Loss: 0.5373\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5965, Valid Loss: 0.5257\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.62 seconds\n",
      "Epoch 4, Train Loss: 0.6483, Valid Loss: 0.5284\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6979, Valid Loss: 0.5296\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.19 seconds\n",
      "Epoch 4, Train Loss: 0.6786, Valid Loss: 0.5087\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6336, Valid Loss: 0.5090\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6298, Valid Loss: 0.5177\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.96 seconds\n",
      "Epoch 4, Train Loss: 1.9625, Valid Loss: 1.8248\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 3.5757, Valid Loss: 4.1325\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.7525, Valid Loss: 1.8505\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.75 seconds\n",
      "Epoch 4, Train Loss: 2.2029, Valid Loss: 1.8375\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0924, Valid Loss: 1.8436\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.01 seconds\n",
      "Epoch 4, Train Loss: 1.9791, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0471, Valid Loss: 1.8283\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0599, Valid Loss: 1.8270\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.21 seconds\n",
      "Epoch 4, Train Loss: 0.1315, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1177, Valid Loss: 0.1095\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.67 seconds\n",
      "Epoch 4, Train Loss: 0.1555, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1215, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.26 seconds\n",
      "Epoch 4, Train Loss: 0.1370, Valid Loss: 0.0989\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1205, Valid Loss: 0.1066\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.70 seconds\n",
      "Epoch 4, Train Loss: 0.8951, Valid Loss: 0.6248\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5801, Valid Loss: 0.5085\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5550, Valid Loss: 0.5089\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.44 seconds\n",
      "Epoch 4, Train Loss: 0.7162, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6412, Valid Loss: 0.5193\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.59 seconds\n",
      "Epoch 4, Train Loss: 0.7111, Valid Loss: 0.5537\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6289, Valid Loss: 0.5276\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.89 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.0338, Valid Loss: 1.8260\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9485, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9276, Valid Loss: 1.8257\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.10 seconds\n",
      "Epoch 4, Train Loss: 2.0473, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9699, Valid Loss: 1.8233\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 4.0008, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.24 seconds\n",
      "Epoch 4, Train Loss: 2.0906, Valid Loss: 1.8449\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0734, Valid Loss: 1.8227\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.78 seconds\n",
      "Epoch 4, Train Loss: 0.1301, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1167, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.59 seconds\n",
      "Epoch 4, Train Loss: 0.1447, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1226, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.56 seconds\n",
      "Epoch 4, Train Loss: 0.1373, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1281, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.03 seconds\n",
      "Epoch 4, Train Loss: 0.5482, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5958, Valid Loss: 0.5190\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.77 seconds\n",
      "Epoch 4, Train Loss: 0.6844, Valid Loss: 0.5480\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6280, Valid Loss: 0.5239\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.34 seconds\n",
      "Epoch 4, Train Loss: 0.6530, Valid Loss: 0.5192\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6430, Valid Loss: 0.5200\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6806, Valid Loss: 0.5650\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.01 seconds\n",
      "Epoch 4, Train Loss: 2.0508, Valid Loss: 1.8566\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8557, Valid Loss: 1.8195\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8615, Valid Loss: 2.4146\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.6685, Valid Loss: 1.5768\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.3818, Valid Loss: 2.6104\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5012, Valid Loss: 2.2037\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 17.04 seconds\n",
      "Epoch 4, Train Loss: 2.1108, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1299, Valid Loss: 1.8570\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1032, Valid Loss: 1.8256\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.17 seconds\n",
      "Epoch 4, Train Loss: 2.0695, Valid Loss: 1.8089\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0544, Valid Loss: 1.8370\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0208, Valid Loss: 1.8377\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0513, Valid Loss: 1.8013\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0990, Valid Loss: 1.8231\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0168, Valid Loss: 1.7920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 16.41 seconds\n",
      "Epoch 4, Train Loss: 0.1199, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1143, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.78 seconds\n",
      "Epoch 4, Train Loss: 0.1244, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1276, Valid Loss: 0.1017\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.60 seconds\n",
      "Epoch 4, Train Loss: 0.1182, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1257, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.57 seconds\n",
      "Epoch 4, Train Loss: 0.5973, Valid Loss: 0.5075\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.6535, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5509, Valid Loss: 0.5121\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5055, Valid Loss: 0.5507\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.17 seconds\n",
      "Epoch 4, Train Loss: 0.6302, Valid Loss: 0.5414\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6596, Valid Loss: 0.5117\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.59 seconds\n",
      "Epoch 4, Train Loss: 0.5886, Valid Loss: 0.5353\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6408, Valid Loss: 0.5142\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.73 seconds\n",
      "Epoch 4, Train Loss: 1.8262, Valid Loss: 2.6769\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0561, Valid Loss: 1.8851\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9121, Valid Loss: 1.8303\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9163, Valid Loss: 1.8328\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9157, Valid Loss: 1.8428\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.13 seconds\n",
      "Epoch 4, Train Loss: 2.2457, Valid Loss: 1.8227\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0958, Valid Loss: 1.8343\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.2479, Valid Loss: 1.8368\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1409, Valid Loss: 1.8246\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.13 seconds\n",
      "Epoch 4, Train Loss: 2.1270, Valid Loss: 1.8445\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1998, Valid Loss: 1.8142\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1451, Valid Loss: 1.8232\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0429, Valid Loss: 1.8270\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.46 seconds\n",
      "Epoch 4, Train Loss: 0.1193, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1186, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.30 seconds\n",
      "Epoch 4, Train Loss: 0.1289, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1315, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.09 seconds\n",
      "Epoch 4, Train Loss: 0.1325, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1338, Valid Loss: 0.0951\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.64 seconds\n",
      "Epoch 4, Train Loss: 0.5494, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5279, Valid Loss: 0.5104\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.76 seconds\n",
      "Epoch 4, Train Loss: 0.6569, Valid Loss: 0.5355\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6370, Valid Loss: 0.5299\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.72 seconds\n",
      "Epoch 4, Train Loss: 0.6402, Valid Loss: 0.5434\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6702, Valid Loss: 0.5430\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.73 seconds\n",
      "Epoch 4, Train Loss: 2.0817, Valid Loss: 1.8341\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2374, Valid Loss: 1.8259\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9419, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.17 seconds\n",
      "Epoch 4, Train Loss: 2.1305, Valid Loss: 1.8232\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1799, Valid Loss: 1.8314\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.2208, Valid Loss: 2.1123\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0773, Valid Loss: 1.8475\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.25 seconds\n",
      "Epoch 4, Train Loss: 2.0703, Valid Loss: 1.8242\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1493, Valid Loss: 1.8274\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1826, Valid Loss: 1.8466\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0312, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 1.9923, Valid Loss: 1.8272\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.81 seconds\n",
      "Epoch 4, Train Loss: 0.1227, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1239, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1222, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.90 seconds\n",
      "Epoch 4, Train Loss: 0.1387, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1355, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1419, Valid Loss: 0.0952\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.47 seconds\n",
      "Epoch 4, Train Loss: 0.1247, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1379, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1293, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.94 seconds\n",
      "Epoch 4, Train Loss: 0.6273, Valid Loss: 0.5144\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5499, Valid Loss: 0.5070\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6442, Valid Loss: 0.5088\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5098, Valid Loss: 0.4909\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4725, Valid Loss: 0.5196\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5294, Valid Loss: 0.5412\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 16.96 seconds\n",
      "Epoch 4, Train Loss: 0.6434, Valid Loss: 0.5182\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6386, Valid Loss: 0.5237\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6259, Valid Loss: 0.5190\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6212, Valid Loss: 0.5196\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.61 seconds\n",
      "Epoch 4, Train Loss: 0.6085, Valid Loss: 0.5206\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5910, Valid Loss: 0.5275\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6305, Valid Loss: 0.5316\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.28 seconds\n",
      "Epoch 4, Train Loss: 2.0730, Valid Loss: 1.8925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9356, Valid Loss: 1.8053\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8792, Valid Loss: 1.8145\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.6506, Valid Loss: 1.8104\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.92 seconds\n",
      "Epoch 4, Train Loss: 2.4010, Valid Loss: 1.9037\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1546, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1066, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0770, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1846, Valid Loss: 1.8406\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0545, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 17.30 seconds\n",
      "Epoch 4, Train Loss: 2.1157, Valid Loss: 1.8315\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0364, Valid Loss: 1.7931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.2445, Valid Loss: 1.8768\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0271, Valid Loss: 1.8204\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0382, Valid Loss: 1.8236\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.85 seconds\n",
      "Epoch 4, Train Loss: 0.1184, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1137, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.95 seconds\n",
      "Epoch 4, Train Loss: 0.1294, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1239, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.11 seconds\n",
      "Epoch 4, Train Loss: 0.1310, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1222, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 7.60 seconds\n",
      "Epoch 4, Train Loss: 0.5801, Valid Loss: 0.5116\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5684, Valid Loss: 0.5168\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 323.65 seconds\n",
      "Epoch 4, Train Loss: 0.6318, Valid Loss: 0.5246\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6166, Valid Loss: 0.5198\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.46 seconds\n",
      "Epoch 4, Train Loss: 0.6207, Valid Loss: 0.5194\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6170, Valid Loss: 0.5226\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6153, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.35 seconds\n",
      "Epoch 4, Train Loss: 1.9796, Valid Loss: 1.8335\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0322, Valid Loss: 1.8187\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9277, Valid Loss: 1.8630\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9589, Valid Loss: 1.8332\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.50 seconds\n",
      "Epoch 4, Train Loss: 2.1929, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1936, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0968, Valid Loss: 1.8316\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1508, Valid Loss: 1.8575\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1174, Valid Loss: 1.8189\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0569, Valid Loss: 1.8667\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.59 seconds\n",
      "Epoch 4, Train Loss: 2.1701, Valid Loss: 1.8180\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1065, Valid Loss: 1.8097\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1157, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0970, Valid Loss: 1.8256\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.51 seconds\n",
      "Epoch 4, Train Loss: 0.1183, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1258, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1204, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.31 seconds\n",
      "Epoch 4, Train Loss: 0.1474, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1311, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1248, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.48 seconds\n",
      "Epoch 4, Train Loss: 0.1365, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1216, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1269, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.41 seconds\n",
      "Epoch 4, Train Loss: 0.5948, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5995, Valid Loss: 0.5236\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5995, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.25 seconds\n",
      "Epoch 4, Train Loss: 0.6377, Valid Loss: 0.5199\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6281, Valid Loss: 0.5180\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6345, Valid Loss: 0.5255\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.05 seconds\n",
      "Epoch 4, Train Loss: 0.6027, Valid Loss: 0.5136\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6290, Valid Loss: 0.5294\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6253, Valid Loss: 0.5384\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.46 seconds\n",
      "Epoch 4, Train Loss: 1.9951, Valid Loss: 1.8399\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0886, Valid Loss: 1.9548\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9164, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8566, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.38 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.2032, Valid Loss: 1.8324\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2038, Valid Loss: 1.8239\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1264, Valid Loss: 1.8278\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.92 seconds\n",
      "Epoch 4, Train Loss: 2.1650, Valid Loss: 1.8290\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.3327, Valid Loss: 1.9067\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0934, Valid Loss: 1.8233\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.59 seconds\n",
      "Epoch 4, Train Loss: 0.1727, Valid Loss: 0.1242\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1201, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1080, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1356, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.97 seconds\n",
      "Epoch 4, Train Loss: 0.1875, Valid Loss: 0.1267\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1540, Valid Loss: 0.0978\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1445, Valid Loss: 0.0943\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1519, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.07 seconds\n",
      "Epoch 4, Train Loss: 0.1631, Valid Loss: 0.1187\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1495, Valid Loss: 0.0974\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1325, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1340, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 12.29 seconds\n",
      "Epoch 4, Train Loss: 0.6692, Valid Loss: 0.5914\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5733, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5880, Valid Loss: 0.5176\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5674, Valid Loss: 0.5215\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.12 seconds\n",
      "Epoch 4, Train Loss: 0.6656, Valid Loss: 0.5447\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6050, Valid Loss: 0.5271\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6587, Valid Loss: 0.5306\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6576, Valid Loss: 0.5325\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.34 seconds\n",
      "Epoch 4, Train Loss: 0.6060, Valid Loss: 0.5289\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6316, Valid Loss: 0.5226\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6033, Valid Loss: 0.5192\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6493, Valid Loss: 0.5209\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6651, Valid Loss: 0.5396\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5754, Valid Loss: 0.5033\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.6237, Valid Loss: 0.5072\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.5896, Valid Loss: 0.4960\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.5402, Valid Loss: 0.5025\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 40, Train Loss: 0.6112, Valid Loss: 0.5065\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 44, Train Loss: 0.6234, Valid Loss: 0.5133\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 28.50 seconds\n",
      "Epoch 4, Train Loss: 2.0789, Valid Loss: 1.9095\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0536, Valid Loss: 1.8830\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0018, Valid Loss: 1.8613\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9478, Valid Loss: 1.8421\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9470, Valid Loss: 1.8307\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9193, Valid Loss: 1.8174\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9135, Valid Loss: 1.8283\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8838, Valid Loss: 1.8119\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7973, Valid Loss: 1.7938\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train Loss: 1.7977, Valid Loss: 1.7325\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6558, Valid Loss: 1.7733\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.6391, Valid Loss: 1.6685\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 30.86 seconds\n",
      "Epoch 4, Train Loss: 2.2124, Valid Loss: 1.8459\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1444, Valid Loss: 1.8322\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1188, Valid Loss: 1.8211\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1036, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0611, Valid Loss: 1.8293\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.62 seconds\n",
      "Epoch 4, Train Loss: 2.5202, Valid Loss: 2.0676\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.4150, Valid Loss: 1.9948\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.3496, Valid Loss: 1.9201\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.2457, Valid Loss: 1.8467\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0614, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.1513, Valid Loss: 1.8152\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.1381, Valid Loss: 1.7885\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9967, Valid Loss: 1.7443\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8687, Valid Loss: 1.6855\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.8547, Valid Loss: 1.7469\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.8349, Valid Loss: 1.7798\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7943, Valid Loss: 1.6042\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 33.77 seconds\n",
      "Epoch 4, Train Loss: 0.1163, Valid Loss: 0.0980\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1146, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1160, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.58 seconds\n",
      "Epoch 4, Train Loss: 0.1391, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1279, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1275, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.71 seconds\n",
      "Epoch 4, Train Loss: 0.1350, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1245, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1230, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.90 seconds\n",
      "Epoch 4, Train Loss: 0.5606, Valid Loss: 0.5162\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5987, Valid Loss: 0.5126\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5927, Valid Loss: 0.5134\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.46 seconds\n",
      "Epoch 4, Train Loss: 0.6273, Valid Loss: 0.5231\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5949, Valid Loss: 0.5200\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6382, Valid Loss: 0.5278\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.91 seconds\n",
      "Epoch 4, Train Loss: 0.6445, Valid Loss: 0.5236\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6004, Valid Loss: 0.5149\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5982, Valid Loss: 0.5119\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.21 seconds\n",
      "Epoch 4, Train Loss: 2.0457, Valid Loss: 1.8930\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0246, Valid Loss: 1.8731\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9841, Valid Loss: 1.8401\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9669, Valid Loss: 1.8090\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8554, Valid Loss: 1.8387\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8148, Valid Loss: 1.8753\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8978, Valid Loss: 1.7992\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8064, Valid Loss: 1.7917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 21.25 seconds\n",
      "Epoch 4, Train Loss: 2.3822, Valid Loss: 1.9309\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1469, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1370, Valid Loss: 1.8417\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0388, Valid Loss: 1.8415\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.37 seconds\n",
      "Epoch 4, Train Loss: 2.2455, Valid Loss: 1.9067\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2031, Valid Loss: 1.8823\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1564, Valid Loss: 1.8418\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0653, Valid Loss: 1.8202\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0211, Valid Loss: 1.8044\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0392, Valid Loss: 1.7958\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9402, Valid Loss: 1.7623\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9640, Valid Loss: 1.7449\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8922, Valid Loss: 1.7208\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.8820, Valid Loss: 1.7019\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.8824, Valid Loss: 1.6214\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.8709, Valid Loss: 1.6226\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 32.45 seconds\n",
      "Epoch 4, Train Loss: 0.1564, Valid Loss: 0.1127\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1219, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1331, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.15 seconds\n",
      "Epoch 4, Train Loss: 0.1860, Valid Loss: 0.1251\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1536, Valid Loss: 0.0960\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1465, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1305, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 13.21 seconds\n",
      "Epoch 4, Train Loss: 0.1703, Valid Loss: 0.1229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1379, Valid Loss: 0.0967\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1285, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1249, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 14.18 seconds\n",
      "Epoch 4, Train Loss: 0.6001, Valid Loss: 0.5513\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5579, Valid Loss: 0.5239\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5649, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6005, Valid Loss: 0.5193\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6072, Valid Loss: 0.5206\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 14.93 seconds\n",
      "Epoch 4, Train Loss: 0.6866, Valid Loss: 0.5864\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6551, Valid Loss: 0.5409\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6481, Valid Loss: 0.5304\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6595, Valid Loss: 0.5315\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6665, Valid Loss: 0.5314\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 15.90 seconds\n",
      "Epoch 4, Train Loss: 0.6398, Valid Loss: 0.5814\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6189, Valid Loss: 0.5504\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6099, Valid Loss: 0.5359\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6063, Valid Loss: 0.5391\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6257, Valid Loss: 0.5366\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 14.92 seconds\n",
      "Epoch 4, Train Loss: 2.1308, Valid Loss: 1.9525\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0064, Valid Loss: 1.8605\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0455, Valid Loss: 1.8419\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 1.9088, Valid Loss: 1.8150\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9092, Valid Loss: 1.8217\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9052, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9725, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 21.04 seconds\n",
      "Epoch 4, Train Loss: 2.4894, Valid Loss: 1.9851\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.4172, Valid Loss: 1.9392\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.3035, Valid Loss: 1.8599\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.2409, Valid Loss: 1.8242\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1647, Valid Loss: 1.8238\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.1818, Valid Loss: 1.8280\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.11 seconds\n",
      "Epoch 4, Train Loss: 2.2525, Valid Loss: 1.9090\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2118, Valid Loss: 1.8700\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1105, Valid Loss: 1.8245\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1094, Valid Loss: 1.8159\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0801, Valid Loss: 1.8076\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0075, Valid Loss: 1.7788\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8559, Valid Loss: 1.7315\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 2.0015, Valid Loss: 1.7242\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8406, Valid Loss: 1.6907\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.8010, Valid Loss: 1.5861\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.7271, Valid Loss: 1.5847\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7005, Valid Loss: 1.6376\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 36.94 seconds\n",
      "Epoch 4, Train Loss: 0.1079, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1068, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1085, Valid Loss: 0.1024\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.35 seconds\n",
      "Epoch 4, Train Loss: 0.1450, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1254, Valid Loss: 0.0949\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1223, Valid Loss: 0.0972\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1206, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.71 seconds\n",
      "Epoch 4, Train Loss: 0.1399, Valid Loss: 0.1221\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1207, Valid Loss: 0.0976\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1162, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.40 seconds\n",
      "Epoch 4, Train Loss: 0.5956, Valid Loss: 0.5100\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5684, Valid Loss: 0.5450\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.72 seconds\n",
      "Epoch 4, Train Loss: 0.6314, Valid Loss: 0.5196\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6366, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.85 seconds\n",
      "Epoch 4, Train Loss: 0.6381, Valid Loss: 0.5252\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6183, Valid Loss: 0.5187\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5898, Valid Loss: 0.5139\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.55 seconds\n",
      "Epoch 4, Train Loss: 1.9394, Valid Loss: 1.8235\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9606, Valid Loss: 1.8286\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9426, Valid Loss: 1.8411\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.72 seconds\n",
      "Epoch 4, Train Loss: 2.0946, Valid Loss: 1.8349\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1026, Valid Loss: 1.8430\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1013, Valid Loss: 1.8383\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.61 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.0330, Valid Loss: 1.8372\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0453, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0378, Valid Loss: 1.8309\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.27 seconds\n",
      "Epoch 4, Train Loss: 0.1537, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1157, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.99 seconds\n",
      "Epoch 4, Train Loss: 0.1590, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1408, Valid Loss: 0.1022\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1254, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.47 seconds\n",
      "Epoch 4, Train Loss: 0.1741, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1546, Valid Loss: 0.1205\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.78 seconds\n",
      "Epoch 4, Train Loss: 0.6802, Valid Loss: 0.5740\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6800, Valid Loss: 0.5102\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5692, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.18 seconds\n",
      "Epoch 4, Train Loss: 0.7154, Valid Loss: 0.5178\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6573, Valid Loss: 0.5769\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6314, Valid Loss: 0.5138\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.40 seconds\n",
      "Epoch 4, Train Loss: 0.7181, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6475, Valid Loss: 0.5815\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6214, Valid Loss: 0.5221\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.21 seconds\n",
      "Epoch 4, Train Loss: 2.0629, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9560, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9898, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.68 seconds\n",
      "Epoch 4, Train Loss: 2.1333, Valid Loss: 1.9054\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0822, Valid Loss: 1.8352\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0641, Valid Loss: 1.8450\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.87 seconds\n",
      "Epoch 4, Train Loss: 2.0189, Valid Loss: 1.8255\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0707, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0498, Valid Loss: 1.8352\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.95 seconds\n",
      "Epoch 4, Train Loss: 0.1182, Valid Loss: 0.0964\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1054, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1029, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.43 seconds\n",
      "Epoch 4, Train Loss: 0.1320, Valid Loss: 0.1044\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1235, Valid Loss: 0.1447\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.80 seconds\n",
      "Epoch 4, Train Loss: 0.1414, Valid Loss: 0.1009\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1191, Valid Loss: 0.0950\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1255, Valid Loss: 0.1190\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.08 seconds\n",
      "Epoch 4, Train Loss: 0.6474, Valid Loss: 0.5546\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5634, Valid Loss: 0.5081\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5584, Valid Loss: 0.5082\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.36 seconds\n",
      "Epoch 4, Train Loss: 0.6781, Valid Loss: 0.5265\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6477, Valid Loss: 0.5267\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6277, Valid Loss: 0.5293\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6275, Valid Loss: 0.5186\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 14.21 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.6539, Valid Loss: 0.5556\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6226, Valid Loss: 0.5235\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6129, Valid Loss: 0.5221\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.86 seconds\n",
      "Epoch 4, Train Loss: 1.9734, Valid Loss: 1.8252\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9613, Valid Loss: 1.8231\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.56 seconds\n",
      "Epoch 4, Train Loss: 2.0497, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1156, Valid Loss: 1.8473\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1184, Valid Loss: 1.8410\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.98 seconds\n",
      "Epoch 4, Train Loss: 2.0589, Valid Loss: 1.8570\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0911, Valid Loss: 1.9267\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0695, Valid Loss: 1.8711\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.82 seconds\n",
      "Epoch 4, Train Loss: 0.1199, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1182, Valid Loss: 0.1142\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.25 seconds\n",
      "Epoch 4, Train Loss: 0.1339, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1329, Valid Loss: 0.1096\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.64 seconds\n",
      "Epoch 4, Train Loss: 0.1252, Valid Loss: 0.0979\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1282, Valid Loss: 0.1019\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.69 seconds\n",
      "Epoch 4, Train Loss: 0.6003, Valid Loss: 0.5123\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5990, Valid Loss: 0.5885\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.76 seconds\n",
      "Epoch 4, Train Loss: 0.6795, Valid Loss: 0.5357\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6540, Valid Loss: 0.5839\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.73 seconds\n",
      "Epoch 4, Train Loss: 0.6516, Valid Loss: 0.5297\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6036, Valid Loss: 0.5108\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5873, Valid Loss: 0.4962\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6565, Valid Loss: 0.5558\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6056, Valid Loss: 0.5275\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.6594, Valid Loss: 0.5160\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 15.70 seconds\n",
      "Epoch 4, Train Loss: 1.9518, Valid Loss: 1.8696\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.7803, Valid Loss: 1.8056\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.7230, Valid Loss: 1.8794\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8187, Valid Loss: 2.1170\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.74 seconds\n",
      "Epoch 4, Train Loss: 2.1970, Valid Loss: 1.8157\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.3563, Valid Loss: 1.8119\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0920, Valid Loss: 1.7976\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9578, Valid Loss: 1.8360\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.4421, Valid Loss: 3.5152\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8929, Valid Loss: 1.8418\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7381, Valid Loss: 1.9163\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 21.06 seconds\n",
      "Epoch 4, Train Loss: 2.0967, Valid Loss: 1.8209\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.7169, Valid Loss: 2.2060\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9773, Valid Loss: 1.8115\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1919, Valid Loss: 1.8394\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.09 seconds\n",
      "Epoch 4, Train Loss: 0.1154, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1114, Valid Loss: 0.0943\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 6.62 seconds\n",
      "Epoch 4, Train Loss: 0.1367, Valid Loss: 0.0971\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1251, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.56 seconds\n",
      "Epoch 4, Train Loss: 0.1220, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1286, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.63 seconds\n",
      "Epoch 4, Train Loss: 0.5986, Valid Loss: 0.5244\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5581, Valid Loss: 0.5089\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5014, Valid Loss: 0.4714\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5306, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5614, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.18 seconds\n",
      "Epoch 4, Train Loss: 0.6682, Valid Loss: 0.5069\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6654, Valid Loss: 0.5156\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6503, Valid Loss: 0.5544\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.20 seconds\n",
      "Epoch 4, Train Loss: 0.6350, Valid Loss: 0.5335\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6513, Valid Loss: 0.5304\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5998, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6460, Valid Loss: 0.5374\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6034, Valid Loss: 0.4953\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.12 seconds\n",
      "Epoch 4, Train Loss: 2.0351, Valid Loss: 1.8633\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9788, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9408, Valid Loss: 1.8213\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7663, Valid Loss: 2.0101\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.2143, Valid Loss: 1.8561\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9491, Valid Loss: 1.8381\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.54 seconds\n",
      "Epoch 4, Train Loss: 2.5582, Valid Loss: 1.9161\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.4052, Valid Loss: 1.8643\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0646, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.11 seconds\n",
      "Epoch 4, Train Loss: 2.0990, Valid Loss: 1.7940\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0555, Valid Loss: 1.8165\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0957, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.52 seconds\n",
      "Epoch 4, Train Loss: 0.1177, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1057, Valid Loss: 0.0950\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.68 seconds\n",
      "Epoch 4, Train Loss: 0.1409, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1383, Valid Loss: 0.1079\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.42 seconds\n",
      "Epoch 4, Train Loss: 0.1291, Valid Loss: 0.0992\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1361, Valid Loss: 0.1164\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.84 seconds\n",
      "Epoch 4, Train Loss: 0.5675, Valid Loss: 0.5137\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5694, Valid Loss: 0.5184\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 161.26 seconds\n",
      "Epoch 4, Train Loss: 0.6636, Valid Loss: 0.5306\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6374, Valid Loss: 0.5258\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.82 seconds\n",
      "Epoch 4, Train Loss: 0.6174, Valid Loss: 0.5206\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6304, Valid Loss: 0.5274\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.76 seconds\n",
      "Epoch 4, Train Loss: 1.9779, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9467, Valid Loss: 1.8231\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 1.9225, Valid Loss: 1.8248\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.88 seconds\n",
      "Epoch 4, Train Loss: 2.1641, Valid Loss: 1.8313\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0890, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1207, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.73 seconds\n",
      "Epoch 4, Train Loss: 2.1904, Valid Loss: 1.8222\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1148, Valid Loss: 1.8114\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1002, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0950, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9762, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.18 seconds\n",
      "Epoch 4, Train Loss: 0.1192, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1215, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.77 seconds\n",
      "Epoch 4, Train Loss: 0.1389, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1356, Valid Loss: 0.0967\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.89 seconds\n",
      "Epoch 4, Train Loss: 0.1333, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1383, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.82 seconds\n",
      "Epoch 4, Train Loss: 0.5931, Valid Loss: 0.5239\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5276, Valid Loss: 0.5273\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.20 seconds\n",
      "Epoch 4, Train Loss: 0.6369, Valid Loss: 0.5214\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6296, Valid Loss: 0.5218\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6389, Valid Loss: 0.5221\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6403, Valid Loss: 0.5584\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6394, Valid Loss: 0.5282\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.6071, Valid Loss: 0.5352\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.5717, Valid Loss: 0.4995\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 18.27 seconds\n",
      "Epoch 4, Train Loss: 0.6101, Valid Loss: 0.5301\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6255, Valid Loss: 0.5414\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.72 seconds\n",
      "Epoch 4, Train Loss: 2.0061, Valid Loss: 1.8502\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9734, Valid Loss: 1.8550\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1005, Valid Loss: 1.8474\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.13 seconds\n",
      "Epoch 4, Train Loss: 2.1657, Valid Loss: 1.8276\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0865, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0862, Valid Loss: 1.8036\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0260, Valid Loss: 1.7301\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0297, Valid Loss: 1.7459\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9228, Valid Loss: 1.7419\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7565, Valid Loss: 1.8863\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5920, Valid Loss: 2.2068\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.4170, Valid Loss: 1.4837\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 2.0097, Valid Loss: 1.3868\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6718, Valid Loss: 1.1997\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7662, Valid Loss: 1.2900\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Total training time: 30.85 seconds\n",
      "Epoch 4, Train Loss: 2.1265, Valid Loss: 1.8330\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0075, Valid Loss: 1.8213\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9087, Valid Loss: 2.3886\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0479, Valid Loss: 1.8195\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 2.0892, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.84 seconds\n",
      "Epoch 4, Train Loss: 0.1179, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1156, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.04 seconds\n",
      "Epoch 4, Train Loss: 0.1283, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1282, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.68 seconds\n",
      "Epoch 4, Train Loss: 0.1271, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1182, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.68 seconds\n",
      "Epoch 4, Train Loss: 0.5565, Valid Loss: 0.5075\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5349, Valid Loss: 0.4815\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5013, Valid Loss: 0.5303\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4524, Valid Loss: 0.5220\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4017, Valid Loss: 0.5923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5587, Valid Loss: 0.4902\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 16.27 seconds\n",
      "Epoch 4, Train Loss: 0.6444, Valid Loss: 0.5332\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6635, Valid Loss: 0.5320\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.02 seconds\n",
      "Epoch 4, Train Loss: 0.6066, Valid Loss: 0.5182\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6105, Valid Loss: 0.5231\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6108, Valid Loss: 0.5138\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.22 seconds\n",
      "Epoch 4, Train Loss: 2.0300, Valid Loss: 1.8416\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8615, Valid Loss: 1.8210\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0349, Valid Loss: 1.8335\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9075, Valid Loss: 1.7534\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.6365, Valid Loss: 1.7660\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8079, Valid Loss: 1.8945\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9022, Valid Loss: 1.9163\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 17.71 seconds\n",
      "Epoch 4, Train Loss: 2.2219, Valid Loss: 1.8216\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0365, Valid Loss: 1.8299\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9804, Valid Loss: 1.7864\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0589, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1249, Valid Loss: 1.8222\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.45 seconds\n",
      "Epoch 4, Train Loss: 2.0912, Valid Loss: 1.8320\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0988, Valid Loss: 1.7882\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1532, Valid Loss: 1.8547\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0401, Valid Loss: 1.8211\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.10 seconds\n",
      "Epoch 4, Train Loss: 0.1236, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1228, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.61 seconds\n",
      "Epoch 4, Train Loss: 0.1290, Valid Loss: 0.0955\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1272, Valid Loss: 0.0957\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.73 seconds\n",
      "Epoch 4, Train Loss: 0.1305, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1242, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.12 seconds\n",
      "Epoch 4, Train Loss: 0.5765, Valid Loss: 0.5201\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5795, Valid Loss: 0.5224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.11 seconds\n",
      "Epoch 4, Train Loss: 0.6684, Valid Loss: 0.5301\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.6305, Valid Loss: 0.5282\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.99 seconds\n",
      "Epoch 4, Train Loss: 0.6551, Valid Loss: 0.5234\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6733, Valid Loss: 0.5394\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.38 seconds\n",
      "Epoch 4, Train Loss: 1.9832, Valid Loss: 1.8379\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0017, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9794, Valid Loss: 1.8239\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.66 seconds\n",
      "Epoch 4, Train Loss: 2.2333, Valid Loss: 1.8196\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0474, Valid Loss: 1.9552\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1216, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0497, Valid Loss: 1.8275\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.31 seconds\n",
      "Epoch 4, Train Loss: 2.1301, Valid Loss: 1.8219\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0472, Valid Loss: 1.8245\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0882, Valid Loss: 1.8292\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.35 seconds\n",
      "Epoch 4, Train Loss: 0.1434, Valid Loss: 0.1059\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1251, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1117, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1051, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.87 seconds\n",
      "Epoch 4, Train Loss: 0.1618, Valid Loss: 0.1070\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1347, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1371, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1368, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.44 seconds\n",
      "Epoch 4, Train Loss: 0.1408, Valid Loss: 0.0995\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1286, Valid Loss: 0.0943\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1235, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.52 seconds\n",
      "Epoch 4, Train Loss: 0.6057, Valid Loss: 0.5433\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5813, Valid Loss: 0.5235\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5898, Valid Loss: 0.5221\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5643, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.71 seconds\n",
      "Epoch 4, Train Loss: 0.6811, Valid Loss: 0.5898\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6491, Valid Loss: 0.5401\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6499, Valid Loss: 0.5317\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5837, Valid Loss: 0.5238\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6288, Valid Loss: 0.5354\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.33 seconds\n",
      "Epoch 4, Train Loss: 0.6205, Valid Loss: 0.5394\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6028, Valid Loss: 0.5262\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6325, Valid Loss: 0.5338\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6027, Valid Loss: 0.5321\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.77 seconds\n",
      "Epoch 4, Train Loss: 2.0279, Valid Loss: 1.8852\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0188, Valid Loss: 1.8618\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9646, Valid Loss: 1.8470\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9760, Valid Loss: 1.8337\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9490, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8793, Valid Loss: 1.8186\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8540, Valid Loss: 1.7689\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 1.7661, Valid Loss: 1.7798\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.5921, Valid Loss: 1.8745\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.6834, Valid Loss: 1.6960\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.4508, Valid Loss: 1.7446\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.4770, Valid Loss: 1.7973\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 37.16 seconds\n",
      "Epoch 4, Train Loss: 2.2843, Valid Loss: 1.8894\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2380, Valid Loss: 1.8583\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1508, Valid Loss: 1.8308\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0616, Valid Loss: 1.8233\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1188, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0923, Valid Loss: 1.8166\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 16.94 seconds\n",
      "Epoch 4, Train Loss: 2.2911, Valid Loss: 1.9315\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2099, Valid Loss: 1.8729\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1672, Valid Loss: 1.8363\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0525, Valid Loss: 1.8119\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0450, Valid Loss: 1.8197\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9823, Valid Loss: 1.8109\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 19.89 seconds\n",
      "Epoch 4, Train Loss: 0.1082, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1094, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1180, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.04 seconds\n",
      "Epoch 4, Train Loss: 0.1315, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1238, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1230, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.94 seconds\n",
      "Epoch 4, Train Loss: 0.1285, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1267, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1327, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.93 seconds\n",
      "Epoch 4, Train Loss: 0.5954, Valid Loss: 0.5140\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5741, Valid Loss: 0.5147\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5458, Valid Loss: 0.5152\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.21 seconds\n",
      "Epoch 4, Train Loss: 0.6650, Valid Loss: 0.5280\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6708, Valid Loss: 0.5263\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6032, Valid Loss: 0.5222\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 9.46 seconds\n",
      "Epoch 4, Train Loss: 0.5999, Valid Loss: 0.5247\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6238, Valid Loss: 0.5222\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6123, Valid Loss: 0.5217\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.40 seconds\n",
      "Epoch 4, Train Loss: 2.0936, Valid Loss: 1.9313\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0584, Valid Loss: 1.8829\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0009, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8881, Valid Loss: 1.8053\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8666, Valid Loss: 1.9399\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9159, Valid Loss: 1.8337\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9523, Valid Loss: 1.8280\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 20.35 seconds\n",
      "Epoch 4, Train Loss: 2.4054, Valid Loss: 1.9416\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2310, Valid Loss: 1.8353\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0021, Valid Loss: 1.8303\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 2.0088, Valid Loss: 1.8010\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1125, Valid Loss: 1.7836\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9857, Valid Loss: 1.7899\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9903, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 2.0730, Valid Loss: 1.7983\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.9919, Valid Loss: 1.7659\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.9467, Valid Loss: 1.7311\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.7936, Valid Loss: 1.7334\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.8549, Valid Loss: 1.5985\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 33.90 seconds\n",
      "Epoch 4, Train Loss: 2.3212, Valid Loss: 1.9419\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2079, Valid Loss: 1.8780\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9832, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0799, Valid Loss: 1.7912\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0649, Valid Loss: 1.7674\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9119, Valid Loss: 1.7501\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9358, Valid Loss: 1.6814\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9176, Valid Loss: 1.5643\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 2.5115, Valid Loss: 2.0245\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 2.2464, Valid Loss: 1.9120\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 29.91 seconds\n",
      "Epoch 4, Train Loss: 0.1423, Valid Loss: 0.1048\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1229, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1257, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1177, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 12.70 seconds\n",
      "Epoch 4, Train Loss: 0.1622, Valid Loss: 0.1117\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1533, Valid Loss: 0.0968\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1396, Valid Loss: 0.0960\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1338, Valid Loss: 0.0965\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.78 seconds\n",
      "Epoch 4, Train Loss: 0.1506, Valid Loss: 0.1098\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1293, Valid Loss: 0.0943\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1330, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1262, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.81 seconds\n",
      "Epoch 4, Train Loss: 0.5541, Valid Loss: 0.5284\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5711, Valid Loss: 0.5245\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5551, Valid Loss: 0.5231\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.93 seconds\n",
      "Epoch 4, Train Loss: 0.6657, Valid Loss: 0.5559\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6260, Valid Loss: 0.5387\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6444, Valid Loss: 0.5344\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6386, Valid Loss: 0.5376\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6410, Valid Loss: 0.5391\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 14.93 seconds\n",
      "Epoch 4, Train Loss: 0.6520, Valid Loss: 0.5573\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6447, Valid Loss: 0.5373\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5964, Valid Loss: 0.5270\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6297, Valid Loss: 0.5319\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6200, Valid Loss: 0.5350\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 17.23 seconds\n",
      "Epoch 4, Train Loss: 2.0319, Valid Loss: 1.8842\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 1.9964, Valid Loss: 1.8550\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9499, Valid Loss: 1.8235\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9644, Valid Loss: 1.8164\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9341, Valid Loss: 1.8096\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8285, Valid Loss: 1.7684\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7032, Valid Loss: 1.7444\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9670, Valid Loss: 1.8650\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.9781, Valid Loss: 1.8294\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 27.22 seconds\n",
      "Epoch 4, Train Loss: 2.3379, Valid Loss: 1.9042\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2338, Valid Loss: 1.8502\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1662, Valid Loss: 1.8223\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1536, Valid Loss: 1.8228\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1632, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 15.41 seconds\n",
      "Epoch 4, Train Loss: 2.1917, Valid Loss: 1.8740\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1313, Valid Loss: 1.8436\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0369, Valid Loss: 1.8209\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0614, Valid Loss: 1.8154\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9897, Valid Loss: 1.8058\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0282, Valid Loss: 1.7876\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9623, Valid Loss: 1.7307\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7856, Valid Loss: 1.6212\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7792, Valid Loss: 1.6822\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7219, Valid Loss: 1.6243\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6927, Valid Loss: 1.4629\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.6416, Valid Loss: 1.4805\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 37.63 seconds\n",
      "Epoch 4, Train Loss: 0.1126, Valid Loss: 0.0987\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1035, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1055, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.01 seconds\n",
      "Epoch 4, Train Loss: 0.1276, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1209, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1199, Valid Loss: 0.1015\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.08 seconds\n",
      "Epoch 4, Train Loss: 0.1220, Valid Loss: 0.0916\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1201, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.04 seconds\n",
      "Epoch 4, Train Loss: 0.5815, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5607, Valid Loss: 0.5103\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5675, Valid Loss: 0.5101\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.44 seconds\n",
      "Epoch 4, Train Loss: 0.7958, Valid Loss: 0.5675\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6290, Valid Loss: 0.5297\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6341, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6252, Valid Loss: 0.5155\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6327, Valid Loss: 0.5188\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.22 seconds\n",
      "Epoch 4, Train Loss: 0.6489, Valid Loss: 0.5427\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6174, Valid Loss: 0.5129\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6553, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.02 seconds\n",
      "Epoch 4, Train Loss: 1.9415, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 1.9960, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9519, Valid Loss: 1.8403\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.40 seconds\n",
      "Epoch 4, Train Loss: 2.1185, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1376, Valid Loss: 1.8020\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1810, Valid Loss: 1.8295\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0970, Valid Loss: 1.8588\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.01 seconds\n",
      "Epoch 4, Train Loss: 2.1079, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1122, Valid Loss: 1.8363\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0526, Valid Loss: 1.9934\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.36 seconds\n",
      "Epoch 4, Train Loss: 0.1571, Valid Loss: 0.1339\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1119, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1177, Valid Loss: 0.0957\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.23 seconds\n",
      "Epoch 4, Train Loss: 0.1469, Valid Loss: 0.0965\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1343, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1309, Valid Loss: 0.0963\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.21 seconds\n",
      "Epoch 4, Train Loss: 0.1533, Valid Loss: 0.1005\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1388, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1265, Valid Loss: 0.1087\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.79 seconds\n",
      "Epoch 4, Train Loss: 0.5801, Valid Loss: 0.5588\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5944, Valid Loss: 0.5773\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6303, Valid Loss: 0.5226\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.39 seconds\n",
      "Epoch 4, Train Loss: 0.8419, Valid Loss: 0.5356\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.7063, Valid Loss: 0.5849\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6347, Valid Loss: 0.5219\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6301, Valid Loss: 0.5215\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.23 seconds\n",
      "Epoch 4, Train Loss: 0.6460, Valid Loss: 0.5136\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6664, Valid Loss: 0.5287\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6182, Valid Loss: 0.5120\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6196, Valid Loss: 0.5063\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6060, Valid Loss: 0.5202\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.90 seconds\n",
      "Epoch 4, Train Loss: 2.1135, Valid Loss: 1.8348\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9302, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9328, Valid Loss: 1.8260\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.68 seconds\n",
      "Epoch 4, Train Loss: 2.2048, Valid Loss: 1.8380\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0975, Valid Loss: 1.8367\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1068, Valid Loss: 1.9251\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.16 seconds\n",
      "Epoch 4, Train Loss: 2.0701, Valid Loss: 1.8433\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0494, Valid Loss: 1.8746\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0550, Valid Loss: 1.8357\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.38 seconds\n",
      "Epoch 4, Train Loss: 0.1128, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1064, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1092, Valid Loss: 0.1219\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.96 seconds\n",
      "Epoch 4, Train Loss: 0.1287, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1170, Valid Loss: 0.1537\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.1197, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.46 seconds\n",
      "Epoch 4, Train Loss: 0.1283, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1314, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1198, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.17 seconds\n",
      "Epoch 4, Train Loss: 0.5649, Valid Loss: 0.5081\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5858, Valid Loss: 0.5098\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5757, Valid Loss: 0.5110\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.09 seconds\n",
      "Epoch 4, Train Loss: 0.6367, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6484, Valid Loss: 0.5401\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.78 seconds\n",
      "Epoch 4, Train Loss: 0.6375, Valid Loss: 0.5353\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6157, Valid Loss: 0.5122\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.82 seconds\n",
      "Epoch 4, Train Loss: 2.0251, Valid Loss: 1.8247\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9951, Valid Loss: 1.8295\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9426, Valid Loss: 1.8560\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.47 seconds\n",
      "Epoch 4, Train Loss: 2.1313, Valid Loss: 1.8571\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0985, Valid Loss: 1.8251\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0969, Valid Loss: 1.8495\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0933, Valid Loss: 1.8401\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.65 seconds\n",
      "Epoch 4, Train Loss: 2.8133, Valid Loss: 1.8917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0506, Valid Loss: 1.8742\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0493, Valid Loss: 1.8853\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.01, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.49 seconds\n",
      "Epoch 4, Train Loss: 0.1218, Valid Loss: 0.0985\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.0958, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.38 seconds\n",
      "Epoch 4, Train Loss: 0.1259, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1258, Valid Loss: 0.1292\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.52 seconds\n",
      "Epoch 4, Train Loss: 0.1317, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1216, Valid Loss: 0.1314\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.58 seconds\n",
      "Epoch 4, Train Loss: 0.6138, Valid Loss: 0.5202\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5485, Valid Loss: 0.5440\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5780, Valid Loss: 0.4939\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4786, Valid Loss: 0.5855\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.51 seconds\n",
      "Epoch 4, Train Loss: 0.6561, Valid Loss: 0.5204\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6635, Valid Loss: 0.5160\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6163, Valid Loss: 0.4756\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5913, Valid Loss: 0.5228\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5966, Valid Loss: 0.4657\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5919, Valid Loss: 0.4518\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.6333, Valid Loss: 0.5337\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.6379, Valid Loss: 0.5332\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 20.89 seconds\n",
      "Epoch 4, Train Loss: 0.6238, Valid Loss: 0.5515\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6165, Valid Loss: 0.4988\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5290, Valid Loss: 0.4335\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4804, Valid Loss: 0.4852\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6336, Valid Loss: 0.5323\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 12.93 seconds\n",
      "Epoch 4, Train Loss: 1.9779, Valid Loss: 1.8195\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8863, Valid Loss: 1.7681\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.3395, Valid Loss: 5.9734\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.4768, Valid Loss: 2.9500\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 11.07 seconds\n",
      "Epoch 4, Train Loss: 2.1009, Valid Loss: 1.8487\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0879, Valid Loss: 1.7976\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0521, Valid Loss: 1.8277\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0406, Valid Loss: 1.8264\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0193, Valid Loss: 1.8274\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0199, Valid Loss: 2.0376\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.0270, Valid Loss: 1.8023\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.43 seconds\n",
      "Epoch 4, Train Loss: 2.0695, Valid Loss: 1.8205\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0292, Valid Loss: 1.7938\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0274, Valid Loss: 1.8412\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0609, Valid Loss: 1.8264\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.13 seconds\n",
      "Epoch 4, Train Loss: 0.1218, Valid Loss: 0.0997\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1172, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.57 seconds\n",
      "Epoch 4, Train Loss: 0.1270, Valid Loss: 0.0943\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1233, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.28 seconds\n",
      "Epoch 4, Train Loss: 0.1214, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1289, Valid Loss: 0.1402\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.03 seconds\n",
      "Epoch 4, Train Loss: 0.6732, Valid Loss: 0.5170\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6083, Valid Loss: 0.5216\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5998, Valid Loss: 0.6341\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.84 seconds\n",
      "Epoch 4, Train Loss: 0.6582, Valid Loss: 0.5551\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6336, Valid Loss: 0.5130\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6688, Valid Loss: 0.5246\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6582, Valid Loss: 0.5391\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.28 seconds\n",
      "Epoch 4, Train Loss: 0.6529, Valid Loss: 0.5429\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6126, Valid Loss: 0.5248\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6165, Valid Loss: 0.5183\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.89 seconds\n",
      "Epoch 4, Train Loss: 2.3539, Valid Loss: 2.5797\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1257, Valid Loss: 1.8601\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9090, Valid Loss: 1.8575\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.90 seconds\n",
      "Epoch 4, Train Loss: 2.1072, Valid Loss: 1.8366\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 3.0655, Valid Loss: 2.8327\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9829, Valid Loss: 1.7577\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9438, Valid Loss: 1.6706\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.2835, Valid Loss: 1.9374\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.2107, Valid Loss: 1.8549\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 15.92 seconds\n",
      "Epoch 4, Train Loss: 2.1359, Valid Loss: 1.8090\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0816, Valid Loss: 1.8303\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0653, Valid Loss: 1.8168\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0159, Valid Loss: 1.8238\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 2.0496, Valid Loss: 1.8359\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.42 seconds\n",
      "Epoch 4, Train Loss: 0.1163, Valid Loss: 0.0982\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1107, Valid Loss: 0.1216\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.11 seconds\n",
      "Epoch 4, Train Loss: 0.1269, Valid Loss: 0.1071\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1316, Valid Loss: 0.1259\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.88 seconds\n",
      "Epoch 4, Train Loss: 0.1250, Valid Loss: 0.1049\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1179, Valid Loss: 0.1237\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.02 seconds\n",
      "Epoch 4, Train Loss: 0.6095, Valid Loss: 0.5549\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6106, Valid Loss: 0.5123\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5757, Valid Loss: 0.5207\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5979, Valid Loss: 0.5091\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.15 seconds\n",
      "Epoch 4, Train Loss: 0.6576, Valid Loss: 0.5654\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6404, Valid Loss: 0.5088\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6237, Valid Loss: 0.5143\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6343, Valid Loss: 0.5315\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 13.14 seconds\n",
      "Epoch 4, Train Loss: 0.6360, Valid Loss: 0.5561\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6209, Valid Loss: 0.5342\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.94 seconds\n",
      "Epoch 4, Train Loss: 1.9251, Valid Loss: 1.7946\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9949, Valid Loss: 1.8309\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0008, Valid Loss: 1.8248\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.03 seconds\n",
      "Epoch 4, Train Loss: 2.1124, Valid Loss: 1.8125\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1688, Valid Loss: 1.8277\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1131, Valid Loss: 1.8383\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.92 seconds\n",
      "Epoch 4, Train Loss: 2.0931, Valid Loss: 1.8247\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0352, Valid Loss: 1.8350\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0055, Valid Loss: 1.8386\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.81 seconds\n",
      "Epoch 4, Train Loss: 0.1140, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1197, Valid Loss: 0.1012\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.75 seconds\n",
      "Epoch 4, Train Loss: 0.1334, Valid Loss: 0.1008\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1284, Valid Loss: 0.1189\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.33 seconds\n",
      "Epoch 4, Train Loss: 0.1245, Valid Loss: 0.0970\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1235, Valid Loss: 0.1049\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.10 seconds\n",
      "Epoch 4, Train Loss: 0.6202, Valid Loss: 0.5259\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5411, Valid Loss: 0.5126\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4747, Valid Loss: 0.4837\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4906, Valid Loss: 0.5927\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.4317, Valid Loss: 0.5502\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.59 seconds\n",
      "Epoch 4, Train Loss: 0.6660, Valid Loss: 0.5497\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6496, Valid Loss: 0.5448\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6294, Valid Loss: 0.5333\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.35 seconds\n",
      "Epoch 4, Train Loss: 0.6138, Valid Loss: 0.5244\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5926, Valid Loss: 0.5503\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.7307, Valid Loss: 0.5290\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.6126, Valid Loss: 0.5323\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.72 seconds\n",
      "Epoch 4, Train Loss: 1.9901, Valid Loss: 1.8376\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9325, Valid Loss: 1.8634\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0370, Valid Loss: 1.8246\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8839, Valid Loss: 1.8223\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8862, Valid Loss: 1.8251\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.64 seconds\n",
      "Epoch 4, Train Loss: 2.0960, Valid Loss: 1.8215\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1279, Valid Loss: 1.8377\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0120, Valid Loss: 1.8356\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.84 seconds\n",
      "Epoch 4, Train Loss: 2.1088, Valid Loss: 1.8239\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0443, Valid Loss: 1.7589\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8851, Valid Loss: 1.9205\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7402, Valid Loss: 1.6245\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.5387, Valid Loss: 2.1777\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9557, Valid Loss: 3.3699\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.45 seconds\n",
      "Epoch 4, Train Loss: 0.1168, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1040, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.49 seconds\n",
      "Epoch 4, Train Loss: 0.1220, Valid Loss: 0.0948\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1231, Valid Loss: 0.0945\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.32 seconds\n",
      "Epoch 4, Train Loss: 0.1225, Valid Loss: 0.0974\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1218, Valid Loss: 0.0953\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.53 seconds\n",
      "Epoch 4, Train Loss: 0.5947, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5869, Valid Loss: 0.5205\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.79 seconds\n",
      "Epoch 4, Train Loss: 0.6641, Valid Loss: 0.5374\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6694, Valid Loss: 0.5408\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6399, Valid Loss: 0.5341\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.26 seconds\n",
      "Epoch 4, Train Loss: 0.6165, Valid Loss: 0.5281\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6232, Valid Loss: 0.5216\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5923, Valid Loss: 0.5140\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 728.78 seconds\n",
      "Epoch 4, Train Loss: 2.0942, Valid Loss: 1.8385\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0503, Valid Loss: 1.9941\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9443, Valid Loss: 1.8230\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0156, Valid Loss: 1.8604\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9388, Valid Loss: 1.8162\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0219, Valid Loss: 2.0114\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.5454, Valid Loss: 1.7650\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.3404, Valid Loss: 2.3461\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 22.05 seconds\n",
      "Epoch 4, Train Loss: 2.3046, Valid Loss: 1.8242\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0773, Valid Loss: 1.7908\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0330, Valid Loss: 1.8927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0198, Valid Loss: 2.0030\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1326, Valid Loss: 1.8334\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0588, Valid Loss: 1.8339\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.99 seconds\n",
      "Epoch 4, Train Loss: 2.0999, Valid Loss: 1.8082\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.0225, Valid Loss: 1.8402\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0046, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.74 seconds\n",
      "Epoch 4, Train Loss: 0.1292, Valid Loss: 0.0995\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1170, Valid Loss: 0.1020\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.44 seconds\n",
      "Epoch 4, Train Loss: 0.1360, Valid Loss: 0.1035\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1176, Valid Loss: 0.1098\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.54 seconds\n",
      "Epoch 4, Train Loss: 0.1222, Valid Loss: 0.0970\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1322, Valid Loss: 0.1067\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.95 seconds\n",
      "Epoch 4, Train Loss: 0.6177, Valid Loss: 0.5575\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5865, Valid Loss: 0.5434\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.83 seconds\n",
      "Epoch 4, Train Loss: 0.6226, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6288, Valid Loss: 0.5330\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6821, Valid Loss: 0.5614\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.64 seconds\n",
      "Epoch 4, Train Loss: 0.6234, Valid Loss: 0.5566\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6187, Valid Loss: 0.5454\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.91 seconds\n",
      "Epoch 4, Train Loss: 1.9861, Valid Loss: 1.8272\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8663, Valid Loss: 1.7472\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9950, Valid Loss: 1.8332\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9568, Valid Loss: 1.8214\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.93 seconds\n",
      "Epoch 4, Train Loss: 2.1178, Valid Loss: 1.8239\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0826, Valid Loss: 1.8279\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0492, Valid Loss: 1.8513\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.10 seconds\n",
      "Epoch 4, Train Loss: 2.1524, Valid Loss: 1.8222\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0648, Valid Loss: 1.8181\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 5.4076, Valid Loss: 1.8230\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1187, Valid Loss: 1.8767\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0005, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 16.13 seconds\n",
      "Epoch 4, Train Loss: 0.1372, Valid Loss: 0.0998\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1156, Valid Loss: 0.0952\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1187, Valid Loss: 0.0954\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.60 seconds\n",
      "Epoch 4, Train Loss: 0.1412, Valid Loss: 0.0978\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1345, Valid Loss: 0.0947\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1384, Valid Loss: 0.0959\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1244, Valid Loss: 0.0990\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 14.69 seconds\n",
      "Epoch 4, Train Loss: 0.1358, Valid Loss: 0.1002\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1217, Valid Loss: 0.0952\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1262, Valid Loss: 0.0961\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 11.86 seconds\n",
      "Epoch 4, Train Loss: 0.5727, Valid Loss: 0.5224\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5712, Valid Loss: 0.5183\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5666, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5466, Valid Loss: 0.5010\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5233, Valid Loss: 0.4954\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5141, Valid Loss: 0.4987\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.4731, Valid Loss: 0.4985\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 22.49 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.6689, Valid Loss: 0.5635\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6309, Valid Loss: 0.5304\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6441, Valid Loss: 0.5351\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6241, Valid Loss: 0.5239\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6175, Valid Loss: 0.5154\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5809, Valid Loss: 0.5052\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.5714, Valid Loss: 0.4609\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.5412, Valid Loss: 0.4336\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.5165, Valid Loss: 0.4505\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 40, Train Loss: 0.5576, Valid Loss: 0.4398\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 44, Train Loss: 0.5066, Valid Loss: 0.4288\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 35.69 seconds\n",
      "Epoch 4, Train Loss: 0.6100, Valid Loss: 0.5289\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6054, Valid Loss: 0.5213\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6229, Valid Loss: 0.5291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6132, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5920, Valid Loss: 0.5158\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5991, Valid Loss: 0.5050\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.5646, Valid Loss: 0.4869\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.5319, Valid Loss: 0.4678\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.5247, Valid Loss: 0.4955\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 40, Train Loss: 0.4806, Valid Loss: 0.4658\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 44, Train Loss: 0.4762, Valid Loss: 0.4697\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 48, Train Loss: 0.5036, Valid Loss: 0.4243\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 33.36 seconds\n",
      "Epoch 4, Train Loss: 2.0066, Valid Loss: 1.8708\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9774, Valid Loss: 1.8459\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9304, Valid Loss: 1.8357\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9416, Valid Loss: 1.8274\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9119, Valid Loss: 1.8283\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8013, Valid Loss: 1.8131\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7230, Valid Loss: 1.7268\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5905, Valid Loss: 1.7762\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6222, Valid Loss: 1.8272\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5043, Valid Loss: 1.7133\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 28.22 seconds\n",
      "Epoch 4, Train Loss: 2.3709, Valid Loss: 1.9250\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2310, Valid Loss: 1.8645\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0862, Valid Loss: 1.8188\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0558, Valid Loss: 1.8258\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0790, Valid Loss: 1.8233\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.59 seconds\n",
      "Epoch 4, Train Loss: 2.2315, Valid Loss: 1.8876\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1578, Valid Loss: 1.8543\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1016, Valid Loss: 1.8290\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0322, Valid Loss: 1.8160\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0694, Valid Loss: 1.8206\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0277, Valid Loss: 1.8150\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 17.15 seconds\n",
      "Epoch 4, Train Loss: 0.1089, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1196, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.1048, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.05 seconds\n",
      "Epoch 4, Train Loss: 0.1331, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1241, Valid Loss: 0.0935\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1344, Valid Loss: 0.0945\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.16 seconds\n",
      "Epoch 4, Train Loss: 0.1222, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1295, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1202, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.12 seconds\n",
      "Epoch 4, Train Loss: 0.5458, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5806, Valid Loss: 0.5019\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5404, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.4951, Valid Loss: 0.5268\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.20 seconds\n",
      "Epoch 4, Train Loss: 0.6761, Valid Loss: 0.5198\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6554, Valid Loss: 0.5251\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6526, Valid Loss: 0.5252\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.00 seconds\n",
      "Epoch 4, Train Loss: 0.6344, Valid Loss: 0.5136\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6239, Valid Loss: 0.5314\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5872, Valid Loss: 0.5188\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.50 seconds\n",
      "Epoch 4, Train Loss: 2.0801, Valid Loss: 1.9132\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0073, Valid Loss: 1.8558\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9431, Valid Loss: 1.8174\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9070, Valid Loss: 1.7837\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0164, Valid Loss: 1.8699\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8246, Valid Loss: 1.8071\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.6433, Valid Loss: 1.7278\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 2.0986, Valid Loss: 2.0112\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8446, Valid Loss: 1.7954\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 25.86 seconds\n",
      "Epoch 4, Train Loss: 2.3879, Valid Loss: 1.9241\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1579, Valid Loss: 1.8231\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0852, Valid Loss: 1.8221\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9572, Valid Loss: 1.7863\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1076, Valid Loss: 1.7802\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9854, Valid Loss: 1.7403\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8752, Valid Loss: 1.7336\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8882, Valid Loss: 1.6508\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.9008, Valid Loss: 1.6395\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7424, Valid Loss: 1.5358\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6676, Valid Loss: 1.7150\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7122, Valid Loss: 1.2193\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 32.37 seconds\n",
      "Epoch 4, Train Loss: 2.2801, Valid Loss: 1.9156\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1587, Valid Loss: 1.8540\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0537, Valid Loss: 1.8110\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0785, Valid Loss: 1.8144\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0574, Valid Loss: 1.7821\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9531, Valid Loss: 1.7871\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8542, Valid Loss: 1.7128\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 1.7901, Valid Loss: 1.6815\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6525, Valid Loss: 1.4905\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 2.2981, Valid Loss: 1.9717\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 2.1504, Valid Loss: 1.8524\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 28.34 seconds\n",
      "Epoch 4, Train Loss: 0.1149, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1214, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1082, Valid Loss: 0.0937\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.19 seconds\n",
      "Epoch 4, Train Loss: 0.1289, Valid Loss: 0.1020\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1440, Valid Loss: 0.0981\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1293, Valid Loss: 0.0980\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 10.03 seconds\n",
      "Epoch 4, Train Loss: 0.1289, Valid Loss: 0.0986\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1194, Valid Loss: 0.0960\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1274, Valid Loss: 0.0949\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1342, Valid Loss: 0.0986\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 14.39 seconds\n",
      "Epoch 4, Train Loss: 0.5928, Valid Loss: 0.5247\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6029, Valid Loss: 0.5242\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6068, Valid Loss: 0.5300\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 10.83 seconds\n",
      "Epoch 4, Train Loss: 0.6603, Valid Loss: 0.5490\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6729, Valid Loss: 0.5406\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6420, Valid Loss: 0.5444\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6674, Valid Loss: 0.5522\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 12.92 seconds\n",
      "Epoch 4, Train Loss: 0.6230, Valid Loss: 0.5398\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6209, Valid Loss: 0.5314\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6036, Valid Loss: 0.5262\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6196, Valid Loss: 0.5298\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6192, Valid Loss: 0.5366\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 15.64 seconds\n",
      "Epoch 4, Train Loss: 2.1180, Valid Loss: 1.9253\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0339, Valid Loss: 1.8746\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9929, Valid Loss: 1.8415\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9516, Valid Loss: 1.8203\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9089, Valid Loss: 1.8156\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8280, Valid Loss: 1.8216\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7379, Valid Loss: 1.7518\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6263, Valid Loss: 1.7708\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6352, Valid Loss: 1.6360\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.6215, Valid Loss: 1.7644\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5488, Valid Loss: 1.7974\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 33.83 seconds\n",
      "Epoch 4, Train Loss: 2.3326, Valid Loss: 1.8910\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1564, Valid Loss: 1.8272\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1309, Valid Loss: 1.8265\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.2071, Valid Loss: 1.8162\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0714, Valid Loss: 1.8219\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0540, Valid Loss: 1.8019\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.0125, Valid Loss: 1.7690\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 1.9500, Valid Loss: 1.7919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 2.0218, Valid Loss: 1.7779\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.9144, Valid Loss: 1.7529\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.8823, Valid Loss: 1.7555\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7135, Valid Loss: 1.7065\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 39.23 seconds\n",
      "Epoch 4, Train Loss: 2.2250, Valid Loss: 1.8936\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0525, Valid Loss: 1.8196\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0130, Valid Loss: 1.8187\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0668, Valid Loss: 1.8030\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9006, Valid Loss: 1.7848\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9177, Valid Loss: 1.7561\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8485, Valid Loss: 1.6676\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5216, Valid Loss: 1.6879\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.2977, Valid Loss: 1.8350\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.3322, Valid Loss: 1.1721\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.4120, Valid Loss: 2.3261\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.2548, Valid Loss: 2.5368\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=128, dropout_rate=0.7, learning_rate=0.0001, batch_size=4, pos_weight=100\n",
      "Total training time: 38.08 seconds\n",
      "Epoch 4, Train Loss: 0.1056, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1130, Valid Loss: 0.0982\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.57 seconds\n",
      "Epoch 4, Train Loss: 0.1198, Valid Loss: 0.1038\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1352, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1194, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.92 seconds\n",
      "Epoch 4, Train Loss: 0.1165, Valid Loss: 0.1085\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1304, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.46 seconds\n",
      "Epoch 4, Train Loss: 0.5860, Valid Loss: 0.5108\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5772, Valid Loss: 0.5085\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.46 seconds\n",
      "Epoch 4, Train Loss: 0.6501, Valid Loss: 0.5419\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6406, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6503, Valid Loss: 0.5413\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.81 seconds\n",
      "Epoch 4, Train Loss: 0.6478, Valid Loss: 0.5521\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6241, Valid Loss: 0.5096\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6242, Valid Loss: 0.5047\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.31 seconds\n",
      "Epoch 4, Train Loss: 2.0404, Valid Loss: 1.8263\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9726, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.46 seconds\n",
      "Epoch 4, Train Loss: 2.1434, Valid Loss: 1.8254\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0797, Valid Loss: 1.8456\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.51 seconds\n",
      "Epoch 4, Train Loss: 2.1450, Valid Loss: 1.8238\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0332, Valid Loss: 1.8513\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0374, Valid Loss: 1.8348\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.80 seconds\n",
      "Epoch 4, Train Loss: 0.1084, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1153, Valid Loss: 0.0960\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.43 seconds\n",
      "Epoch 4, Train Loss: 0.1451, Valid Loss: 0.1650\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1297, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.05 seconds\n",
      "Epoch 4, Train Loss: 0.1211, Valid Loss: 0.0945\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1190, Valid Loss: 0.1015\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1175, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.42 seconds\n",
      "Epoch 4, Train Loss: 0.6582, Valid Loss: 0.5134\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6100, Valid Loss: 0.5107\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6018, Valid Loss: 0.5151\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.37 seconds\n",
      "Epoch 4, Train Loss: 0.6651, Valid Loss: 0.5263\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6536, Valid Loss: 0.5668\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.22 seconds\n",
      "Epoch 4, Train Loss: 0.6607, Valid Loss: 0.5083\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6546, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6333, Valid Loss: 0.5180\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.56 seconds\n",
      "Epoch 4, Train Loss: 1.9791, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9456, Valid Loss: 1.8336\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9363, Valid Loss: 1.8229\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.49 seconds\n",
      "Epoch 4, Train Loss: 2.0781, Valid Loss: 1.8495\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0599, Valid Loss: 1.8295\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1345, Valid Loss: 1.8363\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.61 seconds\n",
      "Epoch 4, Train Loss: 2.0184, Valid Loss: 1.9899\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0204, Valid Loss: 1.8352\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0578, Valid Loss: 1.8283\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0516, Valid Loss: 1.8422\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.71 seconds\n",
      "Epoch 4, Train Loss: 0.1143, Valid Loss: 0.0955\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1063, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.92 seconds\n",
      "Epoch 4, Train Loss: 0.1269, Valid Loss: 0.0997\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1254, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1265, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.38 seconds\n",
      "Epoch 4, Train Loss: 0.1340, Valid Loss: 0.1173\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1183, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1154, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.69 seconds\n",
      "Epoch 4, Train Loss: 0.5869, Valid Loss: 0.5087\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5748, Valid Loss: 0.5347\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5771, Valid Loss: 0.5448\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.38 seconds\n",
      "Epoch 4, Train Loss: 0.6521, Valid Loss: 0.5183\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6276, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6400, Valid Loss: 0.5100\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6285, Valid Loss: 0.5119\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.05 seconds\n",
      "Epoch 4, Train Loss: 0.6438, Valid Loss: 0.5321\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6384, Valid Loss: 0.5368\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.78 seconds\n",
      "Epoch 4, Train Loss: 2.0066, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9574, Valid Loss: 1.8319\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.66 seconds\n",
      "Epoch 4, Train Loss: 2.0941, Valid Loss: 1.9129\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0830, Valid Loss: 1.8424\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0817, Valid Loss: 1.8960\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.83 seconds\n",
      "Epoch 4, Train Loss: 2.0788, Valid Loss: 1.8533\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.0643, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0507, Valid Loss: 1.8318\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.98 seconds\n",
      "Epoch 4, Train Loss: 0.1101, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1013, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.13 seconds\n",
      "Epoch 4, Train Loss: 0.1266, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1166, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1240, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.55 seconds\n",
      "Epoch 4, Train Loss: 0.1246, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1222, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.18 seconds\n",
      "Epoch 4, Train Loss: 0.5656, Valid Loss: 0.5084\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5578, Valid Loss: 0.5098\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.16 seconds\n",
      "Epoch 4, Train Loss: 0.6159, Valid Loss: 0.5161\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6387, Valid Loss: 0.5111\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6157, Valid Loss: 0.5038\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.58 seconds\n",
      "Epoch 4, Train Loss: 0.6325, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6148, Valid Loss: 0.5214\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.17 seconds\n",
      "Epoch 4, Train Loss: 1.9798, Valid Loss: 1.8254\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.7677, Valid Loss: 2.0723\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9279, Valid Loss: 1.8256\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9246, Valid Loss: 1.8307\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.56 seconds\n",
      "Epoch 4, Train Loss: 2.1469, Valid Loss: 1.8158\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0853, Valid Loss: 1.7615\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1503, Valid Loss: 1.8208\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9511, Valid Loss: 1.7727\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1445, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0251, Valid Loss: 1.8540\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.44 seconds\n",
      "Epoch 4, Train Loss: 2.0402, Valid Loss: 1.7653\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9201, Valid Loss: 1.8461\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0775, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0894, Valid Loss: 1.8311\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.63 seconds\n",
      "Epoch 4, Train Loss: 0.1022, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1056, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.14 seconds\n",
      "Epoch 4, Train Loss: 0.1254, Valid Loss: 0.0949\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1190, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.10 seconds\n",
      "Epoch 4, Train Loss: 0.1125, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1139, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.45 seconds\n",
      "Epoch 4, Train Loss: 0.5596, Valid Loss: 0.5093\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5508, Valid Loss: 0.5081\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.62 seconds\n",
      "Epoch 4, Train Loss: 0.6287, Valid Loss: 0.5184\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6219, Valid Loss: 0.5101\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.58 seconds\n",
      "Epoch 4, Train Loss: 0.6177, Valid Loss: 0.5236\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6154, Valid Loss: 0.5219\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.26 seconds\n",
      "Epoch 4, Train Loss: 1.9369, Valid Loss: 1.8190\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 1.9430, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8771, Valid Loss: 1.8290\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.74 seconds\n",
      "Epoch 4, Train Loss: 2.2274, Valid Loss: 1.9165\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0936, Valid Loss: 1.8706\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1114, Valid Loss: 1.8412\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.96 seconds\n",
      "Epoch 4, Train Loss: 2.0486, Valid Loss: 1.8320\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1873, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0867, Valid Loss: 1.8244\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.74 seconds\n",
      "Epoch 4, Train Loss: 0.1064, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1096, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.68 seconds\n",
      "Epoch 4, Train Loss: 0.1228, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1280, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.04 seconds\n",
      "Epoch 4, Train Loss: 0.1202, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1136, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.16 seconds\n",
      "Epoch 4, Train Loss: 0.5595, Valid Loss: 0.5115\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5780, Valid Loss: 0.5111\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.20 seconds\n",
      "Epoch 4, Train Loss: 0.6178, Valid Loss: 0.5133\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6342, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.17 seconds\n",
      "Epoch 4, Train Loss: 0.6191, Valid Loss: 0.5161\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5953, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5979, Valid Loss: 0.5209\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.56 seconds\n",
      "Epoch 4, Train Loss: 2.0431, Valid Loss: 1.8461\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9711, Valid Loss: 1.8300\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9361, Valid Loss: 1.8252\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.28 seconds\n",
      "Epoch 4, Train Loss: 2.1180, Valid Loss: 1.8333\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0945, Valid Loss: 1.8448\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1004, Valid Loss: 1.8401\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.07 seconds\n",
      "Epoch 4, Train Loss: 2.0941, Valid Loss: 1.8200\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0434, Valid Loss: 1.8520\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9685, Valid Loss: 1.8431\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.18 seconds\n",
      "Epoch 4, Train Loss: 0.1053, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1053, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1027, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.52 seconds\n",
      "Epoch 4, Train Loss: 0.1232, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1163, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1204, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.48 seconds\n",
      "Epoch 4, Train Loss: 0.1151, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1234, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1152, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.95 seconds\n",
      "Epoch 4, Train Loss: 0.5696, Valid Loss: 0.5151\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5564, Valid Loss: 0.5110\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5570, Valid Loss: 0.5078\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.00 seconds\n",
      "Epoch 4, Train Loss: 0.6096, Valid Loss: 0.5130\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.6307, Valid Loss: 0.5180\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6166, Valid Loss: 0.4952\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6527, Valid Loss: 0.5119\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6227, Valid Loss: 0.5208\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5658, Valid Loss: 0.4869\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 28, Train Loss: 0.5503, Valid Loss: 0.4325\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 32, Train Loss: 0.5792, Valid Loss: 0.5362\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 36, Train Loss: 0.5049, Valid Loss: 0.4701\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 15.83 seconds\n",
      "Epoch 4, Train Loss: 0.6004, Valid Loss: 0.5132\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6052, Valid Loss: 0.5142\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5968, Valid Loss: 0.5104\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5883, Valid Loss: 0.5032\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.51 seconds\n",
      "Epoch 4, Train Loss: 1.9765, Valid Loss: 1.8180\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.6978, Valid Loss: 1.8818\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.8120, Valid Loss: 1.7229\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.4883, Valid Loss: 1.7210\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.3104, Valid Loss: 1.7629\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.3942, Valid Loss: 2.6276\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.2492, Valid Loss: 2.0571\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 12.87 seconds\n",
      "Epoch 4, Train Loss: 2.1338, Valid Loss: 1.8372\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1533, Valid Loss: 1.8065\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0025, Valid Loss: 1.7395\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8470, Valid Loss: 1.5729\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7907, Valid Loss: 1.9779\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.2990, Valid Loss: 1.8540\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.88 seconds\n",
      "Epoch 4, Train Loss: 2.1047, Valid Loss: 1.8151\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9942, Valid Loss: 1.8281\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9505, Valid Loss: 1.7801\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.7305, Valid Loss: 1.6727\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7498, Valid Loss: 1.5500\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.4806, Valid Loss: 2.3359\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.2578, Valid Loss: 1.5840\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.5792, Valid Loss: 1.3879\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.5117, Valid Loss: 1.3645\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.4018, Valid Loss: 2.7384\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.4050, Valid Loss: 3.0571\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.20 seconds\n",
      "Epoch 4, Train Loss: 0.1016, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1037, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1044, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.80 seconds\n",
      "Epoch 4, Train Loss: 0.1226, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1186, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.53 seconds\n",
      "Epoch 4, Train Loss: 0.1185, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1162, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.48 seconds\n",
      "Epoch 4, Train Loss: 0.5496, Valid Loss: 0.5089\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5522, Valid Loss: 0.5092\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.55 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.6495, Valid Loss: 0.5160\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6241, Valid Loss: 0.5225\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.50 seconds\n",
      "Epoch 4, Train Loss: 0.6076, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6062, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6236, Valid Loss: 0.5186\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5985, Valid Loss: 0.5115\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.79 seconds\n",
      "Epoch 4, Train Loss: 2.0025, Valid Loss: 1.8291\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9159, Valid Loss: 1.8111\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9993, Valid Loss: 1.8347\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1987, Valid Loss: 1.9618\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.33 seconds\n",
      "Epoch 4, Train Loss: 2.0346, Valid Loss: 1.8497\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1056, Valid Loss: 1.8414\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0898, Valid Loss: 1.8476\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.86 seconds\n",
      "Epoch 4, Train Loss: 2.0555, Valid Loss: 1.8262\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0771, Valid Loss: 1.8279\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0162, Valid Loss: 1.8428\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.2049, Valid Loss: 1.8305\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0087, Valid Loss: 1.8458\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.21 seconds\n",
      "Epoch 4, Train Loss: 0.1050, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1066, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1069, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.05 seconds\n",
      "Epoch 4, Train Loss: 0.1233, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1206, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1276, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.07 seconds\n",
      "Epoch 4, Train Loss: 0.1146, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1149, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1189, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.15 seconds\n",
      "Epoch 4, Train Loss: 0.5523, Valid Loss: 0.5101\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5715, Valid Loss: 0.5108\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5739, Valid Loss: 0.5136\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.17 seconds\n",
      "Epoch 4, Train Loss: 0.6369, Valid Loss: 0.5218\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6179, Valid Loss: 0.5190\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6401, Valid Loss: 0.5239\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.22 seconds\n",
      "Epoch 4, Train Loss: 0.6135, Valid Loss: 0.5162\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6093, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6231, Valid Loss: 0.5223\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.31 seconds\n",
      "Epoch 4, Train Loss: 2.0088, Valid Loss: 1.8266\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9801, Valid Loss: 1.8241\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9412, Valid Loss: 1.8329\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.79 seconds\n",
      "Epoch 4, Train Loss: 2.1630, Valid Loss: 1.8233\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1392, Valid Loss: 1.8395\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0229, Valid Loss: 1.8505\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.24 seconds\n",
      "Epoch 4, Train Loss: 2.0970, Valid Loss: 1.8210\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.1568, Valid Loss: 1.8324\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0234, Valid Loss: 1.8303\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0281, Valid Loss: 1.8456\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.22 seconds\n",
      "Epoch 4, Train Loss: 0.1991, Valid Loss: 0.1570\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1120, Valid Loss: 0.0971\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1070, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1053, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.44 seconds\n",
      "Epoch 4, Train Loss: 0.2687, Valid Loss: 0.1945\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1335, Valid Loss: 0.1001\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1192, Valid Loss: 0.0936\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1247, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 20, Train Loss: 0.1174, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.22 seconds\n",
      "Epoch 4, Train Loss: 0.2489, Valid Loss: 0.1789\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1220, Valid Loss: 0.0967\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1084, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1159, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.25 seconds\n",
      "Epoch 4, Train Loss: 0.7004, Valid Loss: 0.6547\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5634, Valid Loss: 0.5194\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5800, Valid Loss: 0.5125\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5465, Valid Loss: 0.5105\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.02 seconds\n",
      "Epoch 4, Train Loss: 0.7842, Valid Loss: 0.6825\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6313, Valid Loss: 0.5280\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6252, Valid Loss: 0.5187\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6112, Valid Loss: 0.5171\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.29 seconds\n",
      "Epoch 4, Train Loss: 0.6737, Valid Loss: 0.5798\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6222, Valid Loss: 0.5270\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6091, Valid Loss: 0.5167\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5964, Valid Loss: 0.5153\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5946, Valid Loss: 0.5139\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.39 seconds\n",
      "Epoch 4, Train Loss: 2.1492, Valid Loss: 1.9680\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1077, Valid Loss: 1.9414\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0737, Valid Loss: 1.9140\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0129, Valid Loss: 1.8690\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9111, Valid Loss: 1.8226\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8956, Valid Loss: 1.8161\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8674, Valid Loss: 1.8171\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8699, Valid Loss: 1.7916\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7345, Valid Loss: 1.7567\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7091, Valid Loss: 1.7551\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5909, Valid Loss: 1.7481\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.5619, Valid Loss: 1.7743\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.30 seconds\n",
      "Epoch 4, Train Loss: 2.4376, Valid Loss: 1.9657\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.3342, Valid Loss: 1.9151\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.2540, Valid Loss: 1.8399\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1013, Valid Loss: 1.8184\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1260, Valid Loss: 1.8271\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 2.0512, Valid Loss: 1.8304\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.00 seconds\n",
      "Epoch 4, Train Loss: 2.3632, Valid Loss: 1.9803\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.3217, Valid Loss: 1.9516\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.2240, Valid Loss: 1.8768\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0924, Valid Loss: 1.8219\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0245, Valid Loss: 1.8170\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0092, Valid Loss: 1.7747\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9130, Valid Loss: 1.7300\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8511, Valid Loss: 1.7647\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.9293, Valid Loss: 1.7776\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7082, Valid Loss: 1.6311\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.7155, Valid Loss: 1.5676\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7001, Valid Loss: 1.5957\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Total training time: 18.90 seconds\n",
      "Epoch 4, Train Loss: 0.1318, Valid Loss: 0.1094\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1029, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1038, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.07 seconds\n",
      "Epoch 4, Train Loss: 0.1442, Valid Loss: 0.1131\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1204, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1218, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.23 seconds\n",
      "Epoch 4, Train Loss: 0.1316, Valid Loss: 0.1058\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1133, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1152, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1116, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.70 seconds\n",
      "Epoch 4, Train Loss: 0.5724, Valid Loss: 0.5243\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5707, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5731, Valid Loss: 0.5124\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5538, Valid Loss: 0.5105\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.41 seconds\n",
      "Epoch 4, Train Loss: 0.6378, Valid Loss: 0.5312\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6375, Valid Loss: 0.5212\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6219, Valid Loss: 0.5189\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6287, Valid Loss: 0.5204\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 7.63 seconds\n",
      "Epoch 4, Train Loss: 0.6168, Valid Loss: 0.5333\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6156, Valid Loss: 0.5179\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5962, Valid Loss: 0.5148\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5987, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.78 seconds\n",
      "Epoch 4, Train Loss: 2.0995, Valid Loss: 1.9275\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0507, Valid Loss: 1.8991\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9570, Valid Loss: 1.8289\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8879, Valid Loss: 1.8286\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9032, Valid Loss: 1.7963\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8226, Valid Loss: 1.7713\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.6822, Valid Loss: 1.7216\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9859, Valid Loss: 1.8862\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.5690, Valid Loss: 1.8425\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5937, Valid Loss: 1.6466\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5216, Valid Loss: 1.7765\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Train Loss: 1.5880, Valid Loss: 1.6026\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Total training time: 19.77 seconds\n",
      "Epoch 4, Train Loss: 2.3990, Valid Loss: 1.9388\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1597, Valid Loss: 1.8202\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0664, Valid Loss: 1.8383\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0742, Valid Loss: 1.8436\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.74 seconds\n",
      "Epoch 4, Train Loss: 2.3007, Valid Loss: 1.9415\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1591, Valid Loss: 1.8334\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0449, Valid Loss: 1.8251\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9821, Valid Loss: 1.8330\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.30 seconds\n",
      "Epoch 4, Train Loss: 0.1647, Valid Loss: 0.1308\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1101, Valid Loss: 0.0956\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1059, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1057, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.21 seconds\n",
      "Epoch 4, Train Loss: 0.1943, Valid Loss: 0.1466\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1296, Valid Loss: 0.0969\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1179, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1264, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 8.36 seconds\n",
      "Epoch 4, Train Loss: 0.2717, Valid Loss: 0.2198\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1343, Valid Loss: 0.1140\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1203, Valid Loss: 0.0973\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1229, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 20, Train Loss: 0.1153, Valid Loss: 0.0926\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.45 seconds\n",
      "Epoch 4, Train Loss: 0.6293, Valid Loss: 0.5808\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5797, Valid Loss: 0.5231\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5505, Valid Loss: 0.5141\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5556, Valid Loss: 0.5114\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5402, Valid Loss: 0.5095\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 24, Train Loss: 0.5512, Valid Loss: 0.5098\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 11.64 seconds\n",
      "Epoch 4, Train Loss: 0.6647, Valid Loss: 0.5696\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6390, Valid Loss: 0.5301\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6185, Valid Loss: 0.5216\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6209, Valid Loss: 0.5194\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.84 seconds\n",
      "Epoch 4, Train Loss: 0.6511, Valid Loss: 0.5731\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6172, Valid Loss: 0.5240\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6159, Valid Loss: 0.5193\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5804, Valid Loss: 0.5140\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.59 seconds\n",
      "Epoch 4, Train Loss: 2.0597, Valid Loss: 1.9005\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0080, Valid Loss: 1.8563\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9377, Valid Loss: 1.8096\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8874, Valid Loss: 1.7737\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8572, Valid Loss: 1.7755\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.7760, Valid Loss: 1.7566\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7010, Valid Loss: 1.7072\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6227, Valid Loss: 1.7540\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.6247, Valid Loss: 1.7543\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train Loss: 1.6097, Valid Loss: 1.7900\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 18.04 seconds\n",
      "Epoch 4, Train Loss: 2.4074, Valid Loss: 1.9391\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2530, Valid Loss: 1.8495\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1257, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0710, Valid Loss: 1.8286\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.1097, Valid Loss: 1.8371\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.32 seconds\n",
      "Epoch 4, Train Loss: 2.2196, Valid Loss: 1.8922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1465, Valid Loss: 1.8436\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0667, Valid Loss: 1.8234\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0362, Valid Loss: 1.8240\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0642, Valid Loss: 1.8281\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=32, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 10.26 seconds\n",
      "Epoch 4, Train Loss: 0.1195, Valid Loss: 0.1175\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1201, Valid Loss: 0.1025\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.23 seconds\n",
      "Epoch 4, Train Loss: 0.1329, Valid Loss: 0.0961\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1244, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1265, Valid Loss: 0.1002\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.10 seconds\n",
      "Epoch 4, Train Loss: 0.1200, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1151, Valid Loss: 0.0934\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1235, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.65 seconds\n",
      "Epoch 4, Train Loss: 0.5798, Valid Loss: 0.5228\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5949, Valid Loss: 0.5090\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6150, Valid Loss: 0.5308\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.35 seconds\n",
      "Epoch 4, Train Loss: 0.6640, Valid Loss: 0.5227\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6466, Valid Loss: 0.5489\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.55 seconds\n",
      "Epoch 4, Train Loss: 0.5917, Valid Loss: 0.5163\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6315, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6054, Valid Loss: 0.5038\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.42 seconds\n",
      "Epoch 4, Train Loss: 1.9431, Valid Loss: 1.8479\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9677, Valid Loss: 1.8526\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9641, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.31 seconds\n",
      "Epoch 4, Train Loss: 2.9075, Valid Loss: 1.8566\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0825, Valid Loss: 1.8561\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.49 seconds\n",
      "Epoch 4, Train Loss: 2.0489, Valid Loss: 1.8227\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0629, Valid Loss: 1.8285\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0406, Valid Loss: 1.8547\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.24 seconds\n",
      "Epoch 4, Train Loss: 0.1168, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1062, Valid Loss: 0.0970\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1102, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.56 seconds\n",
      "Epoch 4, Train Loss: 0.1342, Valid Loss: 0.1326\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1321, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.03 seconds\n",
      "Epoch 4, Train Loss: 0.1299, Valid Loss: 0.0945\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1247, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.06 seconds\n",
      "Epoch 4, Train Loss: 0.6114, Valid Loss: 0.5233\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.5731, Valid Loss: 0.5080\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.02 seconds\n",
      "Epoch 4, Train Loss: 0.7074, Valid Loss: 0.7582\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6530, Valid Loss: 0.5323\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.09 seconds\n",
      "Epoch 4, Train Loss: 0.5925, Valid Loss: 0.5181\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6264, Valid Loss: 0.5112\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5793, Valid Loss: 0.5188\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.46 seconds\n",
      "Epoch 4, Train Loss: 2.0715, Valid Loss: 1.8269\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9171, Valid Loss: 1.8337\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.07 seconds\n",
      "Epoch 4, Train Loss: 2.1633, Valid Loss: 1.8402\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1178, Valid Loss: 1.9430\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0697, Valid Loss: 1.8587\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0851, Valid Loss: 1.8349\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.39 seconds\n",
      "Epoch 4, Train Loss: 2.0746, Valid Loss: 1.8532\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0432, Valid Loss: 1.8392\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.20 seconds\n",
      "Epoch 4, Train Loss: 0.1207, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1170, Valid Loss: 0.0994\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.68 seconds\n",
      "Epoch 4, Train Loss: 0.1291, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1309, Valid Loss: 0.0947\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.68 seconds\n",
      "Epoch 4, Train Loss: 0.1363, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1303, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1240, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.10 seconds\n",
      "Epoch 4, Train Loss: 0.6174, Valid Loss: 0.5376\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5995, Valid Loss: 0.5109\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.68 seconds\n",
      "Epoch 4, Train Loss: 0.6514, Valid Loss: 0.5521\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6240, Valid Loss: 0.5087\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.76 seconds\n",
      "Epoch 4, Train Loss: 0.6280, Valid Loss: 0.5537\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6225, Valid Loss: 0.5128\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.82 seconds\n",
      "Epoch 4, Train Loss: 2.2920, Valid Loss: 1.9782\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9341, Valid Loss: 1.8243\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9517, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9446, Valid Loss: 1.8249\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.26 seconds\n",
      "Epoch 4, Train Loss: 2.1942, Valid Loss: 1.8232\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1472, Valid Loss: 1.8442\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.95 seconds\n",
      "Epoch 4, Train Loss: 2.0347, Valid Loss: 1.8318\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0753, Valid Loss: 1.8382\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0583, Valid Loss: 1.8363\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.01 seconds\n",
      "Epoch 4, Train Loss: 0.1051, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1101, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.34 seconds\n",
      "Epoch 4, Train Loss: 0.1217, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1141, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.12 seconds\n",
      "Epoch 4, Train Loss: 0.1176, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1200, Valid Loss: 0.0942\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.5667, Valid Loss: 0.5113\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5749, Valid Loss: 0.5213\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.25 seconds\n",
      "Epoch 4, Train Loss: 0.6282, Valid Loss: 0.5119\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6277, Valid Loss: 0.5380\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6028, Valid Loss: 0.4918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6293, Valid Loss: 0.5199\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.6252, Valid Loss: 0.5216\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.81 seconds\n",
      "Epoch 4, Train Loss: 0.6151, Valid Loss: 0.5154\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6140, Valid Loss: 0.5325\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6050, Valid Loss: 0.5094\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5968, Valid Loss: 0.5088\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5752, Valid Loss: 0.5442\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.90 seconds\n",
      "Epoch 4, Train Loss: 1.9602, Valid Loss: 1.8280\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9313, Valid Loss: 1.8276\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9630, Valid Loss: 1.8267\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9375, Valid Loss: 1.8275\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.38 seconds\n",
      "Epoch 4, Train Loss: 2.1408, Valid Loss: 1.8225\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1427, Valid Loss: 1.9985\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0548, Valid Loss: 1.8556\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0793, Valid Loss: 1.8441\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.45 seconds\n",
      "Epoch 4, Train Loss: 1.9648, Valid Loss: 1.7901\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9124, Valid Loss: 1.8131\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0224, Valid Loss: 1.8412\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0456, Valid Loss: 1.8450\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.39 seconds\n",
      "Epoch 4, Train Loss: 0.0999, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1091, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.20 seconds\n",
      "Epoch 4, Train Loss: 0.1220, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1238, Valid Loss: 0.0946\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.47 seconds\n",
      "Epoch 4, Train Loss: 0.1152, Valid Loss: 0.0966\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1218, Valid Loss: 0.0941\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.79 seconds\n",
      "Epoch 4, Train Loss: 0.5621, Valid Loss: 0.5107\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5835, Valid Loss: 0.5126\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5597, Valid Loss: 0.5119\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.31 seconds\n",
      "Epoch 4, Train Loss: 0.6450, Valid Loss: 0.5349\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6377, Valid Loss: 0.5192\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6375, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.01 seconds\n",
      "Epoch 4, Train Loss: 0.6197, Valid Loss: 0.5343\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6098, Valid Loss: 0.5204\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.21 seconds\n",
      "Epoch 4, Train Loss: 2.0521, Valid Loss: 1.8281\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9349, Valid Loss: 1.8248\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9558, Valid Loss: 1.8329\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.61 seconds\n",
      "Epoch 4, Train Loss: 2.1461, Valid Loss: 1.8239\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0950, Valid Loss: 1.8502\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0501, Valid Loss: 1.8518\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.1653, Valid Loss: 1.8312\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.3947, Valid Loss: 1.8235\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0307, Valid Loss: 1.8292\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0475, Valid Loss: 1.8333\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.87 seconds\n",
      "Epoch 4, Train Loss: 0.1013, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1083, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.24 seconds\n",
      "Epoch 4, Train Loss: 0.1194, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1241, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.12 seconds\n",
      "Epoch 4, Train Loss: 0.1185, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1190, Valid Loss: 0.0938\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.85 seconds\n",
      "Epoch 4, Train Loss: 0.5361, Valid Loss: 0.5114\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5815, Valid Loss: 0.5274\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.67 seconds\n",
      "Epoch 4, Train Loss: 0.6217, Valid Loss: 0.5109\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6588, Valid Loss: 0.5256\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.65 seconds\n",
      "Epoch 4, Train Loss: 0.6113, Valid Loss: 0.5219\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6078, Valid Loss: 0.5110\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.80 seconds\n",
      "Epoch 4, Train Loss: 1.9784, Valid Loss: 1.8339\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9429, Valid Loss: 1.8224\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9567, Valid Loss: 1.8261\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.48 seconds\n",
      "Epoch 4, Train Loss: 2.1073, Valid Loss: 1.8493\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0242, Valid Loss: 1.8399\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0899, Valid Loss: 1.8296\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.17 seconds\n",
      "Epoch 4, Train Loss: 2.0405, Valid Loss: 1.8441\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0163, Valid Loss: 1.8397\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0384, Valid Loss: 1.8402\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 5.10 seconds\n",
      "Epoch 4, Train Loss: 0.1060, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1041, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1030, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.46 seconds\n",
      "Epoch 4, Train Loss: 0.1223, Valid Loss: 0.0933\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1243, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.43 seconds\n",
      "Epoch 4, Train Loss: 0.1168, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1223, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1091, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.05 seconds\n",
      "Epoch 4, Train Loss: 0.5685, Valid Loss: 0.5068\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5679, Valid Loss: 0.5177\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.4975, Valid Loss: 0.5127\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.17 seconds\n",
      "Epoch 4, Train Loss: 0.6232, Valid Loss: 0.5101\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6217, Valid Loss: 0.5043\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5965, Valid Loss: 0.4999\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6096, Valid Loss: 0.5167\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5376, Valid Loss: 0.4904\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.32 seconds\n",
      "Epoch 4, Train Loss: 0.6166, Valid Loss: 0.5207\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6157, Valid Loss: 0.5257\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.5792, Valid Loss: 0.5065\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.68 seconds\n",
      "Epoch 4, Train Loss: 2.0373, Valid Loss: 1.8544\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8761, Valid Loss: 1.7871\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9941, Valid Loss: 1.8254\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9702, Valid Loss: 1.8362\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7881, Valid Loss: 1.7957\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.76 seconds\n",
      "Epoch 4, Train Loss: 2.1071, Valid Loss: 1.8485\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0545, Valid Loss: 1.8201\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0651, Valid Loss: 1.7856\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8473, Valid Loss: 1.6925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.6613, Valid Loss: 1.7497\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.8051, Valid Loss: 1.6078\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7326, Valid Loss: 1.4220\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.6413, Valid Loss: 1.8066\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 2.0512, Valid Loss: 1.7978\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.63 seconds\n",
      "Epoch 4, Train Loss: 2.0450, Valid Loss: 1.8147\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0609, Valid Loss: 1.8087\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0102, Valid Loss: 1.7832\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8982, Valid Loss: 1.7706\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.7033, Valid Loss: 1.6310\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5274, Valid Loss: 1.6172\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.7137, Valid Loss: 1.4181\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.3619, Valid Loss: 2.6698\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.3287, Valid Loss: 1.5867\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.3320, Valid Loss: 3.0631\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 16.19 seconds\n",
      "Epoch 4, Train Loss: 0.1035, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1050, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.59 seconds\n",
      "Epoch 4, Train Loss: 0.1242, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1197, Valid Loss: 0.0929\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.50 seconds\n",
      "Epoch 4, Train Loss: 0.1185, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1173, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.45 seconds\n",
      "Epoch 4, Train Loss: 0.5691, Valid Loss: 0.5114\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5797, Valid Loss: 0.5205\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.50 seconds\n",
      "Epoch 4, Train Loss: 0.6316, Valid Loss: 0.5138\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6198, Valid Loss: 0.5176\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.47 seconds\n",
      "Epoch 4, Train Loss: 0.6342, Valid Loss: 0.5128\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6143, Valid Loss: 0.5155\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.55 seconds\n",
      "Epoch 4, Train Loss: 1.9548, Valid Loss: 1.8025\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.8126, Valid Loss: 1.7897\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9766, Valid Loss: 1.8285\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9159, Valid Loss: 1.8256\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.54 seconds\n",
      "Epoch 4, Train Loss: 2.1304, Valid Loss: 1.8540\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0308, Valid Loss: 1.6990\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9537, Valid Loss: 2.0345\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9912, Valid Loss: 1.8486\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping activated!\n",
      "Total training time: 7.76 seconds\n",
      "Epoch 4, Train Loss: 2.0136, Valid Loss: 1.8274\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9749, Valid Loss: 1.9760\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1090, Valid Loss: 1.8296\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0436, Valid Loss: 1.8376\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 6.95 seconds\n",
      "Epoch 4, Train Loss: 0.1060, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1074, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.0992, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.50 seconds\n",
      "Epoch 4, Train Loss: 0.1196, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1168, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1204, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.11 seconds\n",
      "Epoch 4, Train Loss: 0.1187, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1160, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1148, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.06 seconds\n",
      "Epoch 4, Train Loss: 0.5701, Valid Loss: 0.5154\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5454, Valid Loss: 0.5106\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5676, Valid Loss: 0.5127\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.08 seconds\n",
      "Epoch 4, Train Loss: 0.6389, Valid Loss: 0.5275\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6290, Valid Loss: 0.5135\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6239, Valid Loss: 0.5172\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.57 seconds\n",
      "Epoch 4, Train Loss: 0.6079, Valid Loss: 0.5147\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6064, Valid Loss: 0.5239\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5833, Valid Loss: 0.5107\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.57 seconds\n",
      "Epoch 4, Train Loss: 1.9588, Valid Loss: 1.8312\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9360, Valid Loss: 1.8287\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9554, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9150, Valid Loss: 1.8274\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.51 seconds\n",
      "Epoch 4, Train Loss: 2.1094, Valid Loss: 1.8470\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0507, Valid Loss: 1.8389\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0679, Valid Loss: 1.8518\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1240, Valid Loss: 1.8350\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0874, Valid Loss: 1.8514\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.89 seconds\n",
      "Epoch 4, Train Loss: 2.0516, Valid Loss: 1.8310\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0133, Valid Loss: 1.7641\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0495, Valid Loss: 1.8365\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0266, Valid Loss: 1.8410\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0005, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.31 seconds\n",
      "Epoch 4, Train Loss: 0.1794, Valid Loss: 0.1317\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1062, Valid Loss: 0.0931\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1052, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1102, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.40 seconds\n",
      "Epoch 4, Train Loss: 0.1885, Valid Loss: 0.1367\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1193, Valid Loss: 0.0945\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1175, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1267, Valid Loss: 0.0924\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.88 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1728, Valid Loss: 0.1268\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1218, Valid Loss: 0.0940\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1190, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1193, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.61 seconds\n",
      "Epoch 4, Train Loss: 0.6206, Valid Loss: 0.5545\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5604, Valid Loss: 0.5098\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5532, Valid Loss: 0.5093\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5566, Valid Loss: 0.5075\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.79 seconds\n",
      "Epoch 4, Train Loss: 0.6741, Valid Loss: 0.5597\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6301, Valid Loss: 0.5214\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6176, Valid Loss: 0.5163\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6200, Valid Loss: 0.5149\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.07 seconds\n",
      "Epoch 4, Train Loss: 0.6789, Valid Loss: 0.5808\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6021, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6044, Valid Loss: 0.5150\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5987, Valid Loss: 0.5121\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 6.36 seconds\n",
      "Epoch 4, Train Loss: 2.2001, Valid Loss: 2.0092\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1246, Valid Loss: 1.9496\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0546, Valid Loss: 1.8996\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0309, Valid Loss: 1.8459\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9186, Valid Loss: 1.8245\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.9903, Valid Loss: 1.8235\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.8740, Valid Loss: 1.8091\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.7655, Valid Loss: 1.7793\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.7041, Valid Loss: 1.7881\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.5396, Valid Loss: 1.9042\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5441, Valid Loss: 1.9331\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.4266, Valid Loss: 1.9543\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Total training time: 18.68 seconds\n",
      "Epoch 4, Train Loss: 2.3780, Valid Loss: 1.9291\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.3062, Valid Loss: 1.8869\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1199, Valid Loss: 1.8240\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1000, Valid Loss: 1.8463\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0404, Valid Loss: 1.8396\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.83 seconds\n",
      "Epoch 4, Train Loss: 2.2818, Valid Loss: 1.9300\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2049, Valid Loss: 1.8866\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.1141, Valid Loss: 1.8380\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0259, Valid Loss: 1.8120\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9818, Valid Loss: 1.8219\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0486, Valid Loss: 1.8028\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9263, Valid Loss: 1.7974\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.8536, Valid Loss: 1.7443\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8479, Valid Loss: 1.6329\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.8781, Valid Loss: 1.5953\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.6373, Valid Loss: 1.4672\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.6542, Valid Loss: 1.3984\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Total training time: 18.73 seconds\n",
      "Epoch 4, Train Loss: 0.1156, Valid Loss: 0.0954\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1030, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1018, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.24 seconds\n",
      "Epoch 4, Train Loss: 0.1275, Valid Loss: 0.0965\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1242, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1267, Valid Loss: 0.0923\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.56 seconds\n",
      "Epoch 4, Train Loss: 0.1270, Valid Loss: 0.0994\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1153, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1142, Valid Loss: 0.0922\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.63 seconds\n",
      "Epoch 4, Train Loss: 0.5501, Valid Loss: 0.5108\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5606, Valid Loss: 0.5100\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5462, Valid Loss: 0.5097\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.38 seconds\n",
      "Epoch 4, Train Loss: 0.6265, Valid Loss: 0.5174\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6134, Valid Loss: 0.5177\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6289, Valid Loss: 0.5169\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.83 seconds\n",
      "Epoch 4, Train Loss: 0.6123, Valid Loss: 0.5198\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6033, Valid Loss: 0.5138\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5967, Valid Loss: 0.5130\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 5.31 seconds\n",
      "Epoch 4, Train Loss: 2.0599, Valid Loss: 1.8965\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0000, Valid Loss: 1.8449\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9063, Valid Loss: 1.8157\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8598, Valid Loss: 1.8101\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.6940, Valid Loss: 1.7302\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.5829, Valid Loss: 1.8069\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.4466, Valid Loss: 1.7264\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.4496, Valid Loss: 1.6917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.4409, Valid Loss: 1.7432\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 13.99 seconds\n",
      "Epoch 4, Train Loss: 2.3300, Valid Loss: 1.8999\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1992, Valid Loss: 1.8255\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0809, Valid Loss: 1.8408\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0881, Valid Loss: 1.8162\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 7.46 seconds\n",
      "Epoch 4, Train Loss: 2.1984, Valid Loss: 1.8783\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0854, Valid Loss: 1.8207\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0333, Valid Loss: 1.8287\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.9981, Valid Loss: 1.8522\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.9702, Valid Loss: 1.7870\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 2.0216, Valid Loss: 1.8542\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 2.0236, Valid Loss: 1.8067\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9875, Valid Loss: 1.7697\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 36, Train Loss: 1.8324, Valid Loss: 1.6406\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 40, Train Loss: 1.7346, Valid Loss: 1.5310\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 44, Train Loss: 1.5722, Valid Loss: 1.5938\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 48, Train Loss: 1.7406, Valid Loss: 1.5410\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Total training time: 20.55 seconds\n",
      "Epoch 4, Train Loss: 0.1620, Valid Loss: 0.1306\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1067, Valid Loss: 0.0939\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1071, Valid Loss: 0.0920\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.1094, Valid Loss: 0.0918\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 7.24 seconds\n",
      "Epoch 4, Train Loss: 0.1901, Valid Loss: 0.1375\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1282, Valid Loss: 0.0952\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1205, Valid Loss: 0.0927\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 16, Train Loss: 0.1257, Valid Loss: 0.0925\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.90 seconds\n",
      "Epoch 4, Train Loss: 0.1493, Valid Loss: 0.1144\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1176, Valid Loss: 0.0932\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1120, Valid Loss: 0.0921\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 6.47 seconds\n",
      "Epoch 4, Train Loss: 0.5835, Valid Loss: 0.5331\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5668, Valid Loss: 0.5144\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.5644, Valid Loss: 0.5117\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5692, Valid Loss: 0.5122\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 20, Train Loss: 0.5502, Valid Loss: 0.5104\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.70 seconds\n",
      "Epoch 4, Train Loss: 0.6429, Valid Loss: 0.5505\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6441, Valid Loss: 0.5283\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6354, Valid Loss: 0.5233\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.6359, Valid Loss: 0.5241\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.91 seconds\n",
      "Epoch 4, Train Loss: 0.6395, Valid Loss: 0.5558\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5950, Valid Loss: 0.5157\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 12, Train Loss: 0.6025, Valid Loss: 0.5124\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Epoch 16, Train Loss: 0.5877, Valid Loss: 0.5123\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 8.00 seconds\n",
      "Epoch 4, Train Loss: 2.1534, Valid Loss: 1.9690\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0478, Valid Loss: 1.8523\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 1.9138, Valid Loss: 1.8237\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 1.8877, Valid Loss: 1.7978\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 1.8685, Valid Loss: 1.7624\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 24, Train Loss: 1.7343, Valid Loss: 1.7482\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 28, Train Loss: 1.9979, Valid Loss: 1.8445\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 32, Train Loss: 1.9588, Valid Loss: 1.8318\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 14.95 seconds\n",
      "Epoch 4, Train Loss: 2.3237, Valid Loss: 1.8960\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.2037, Valid Loss: 1.8272\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0806, Valid Loss: 1.8283\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.1100, Valid Loss: 1.8413\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 8.42 seconds\n",
      "Epoch 4, Train Loss: 2.3038, Valid Loss: 1.9403\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.1225, Valid Loss: 1.8392\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0491, Valid Loss: 1.8223\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 16, Train Loss: 2.0530, Valid Loss: 1.8270\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Epoch 20, Train Loss: 2.0166, Valid Loss: 1.8332\n",
      "Used Parameters: lstm_sizes=[64, 32, 16], hidden_size=64, dropout_rate=0.3, learning_rate=0.0001, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 9.31 seconds\n",
      "Epoch 4, Train Loss: 0.1143, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1201, Valid Loss: 0.0919\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1094, Valid Loss: 0.0887\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 5.01 seconds\n",
      "Epoch 4, Train Loss: 0.1286, Valid Loss: 0.0928\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1247, Valid Loss: 0.0916\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 12, Train Loss: 0.1150, Valid Loss: 0.0862\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.1219, Valid Loss: 0.0930\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 20, Train Loss: 0.1197, Valid Loss: 0.0906\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 9.20 seconds\n",
      "Epoch 4, Train Loss: 0.1261, Valid Loss: 0.1197\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1200, Valid Loss: 0.0988\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.61 seconds\n",
      "Epoch 4, Train Loss: 0.5866, Valid Loss: 0.5083\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.5618, Valid Loss: 0.5173\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.52 seconds\n",
      "Epoch 4, Train Loss: 0.6676, Valid Loss: 0.5083\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.7507, Valid Loss: 0.5376\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.27 seconds\n",
      "Epoch 4, Train Loss: 0.6108, Valid Loss: 0.5254\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Epoch 8, Train Loss: 0.6157, Valid Loss: 0.5132\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=10\n",
      "Early stopping activated!\n",
      "Total training time: 4.16 seconds\n",
      "Epoch 4, Train Loss: 4.8772, Valid Loss: 5.9611\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 1.9844, Valid Loss: 1.8371\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.14 seconds\n",
      "Epoch 4, Train Loss: 2.0708, Valid Loss: 1.8242\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0911, Valid Loss: 1.8240\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.50 seconds\n",
      "Epoch 4, Train Loss: 2.1376, Valid Loss: 2.0487\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 8, Train Loss: 2.0896, Valid Loss: 1.8691\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Epoch 12, Train Loss: 2.0564, Valid Loss: 1.8436\n",
      "Used Parameters: lstm_sizes=[32, 16], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=100\n",
      "Early stopping activated!\n",
      "Total training time: 4.98 seconds\n",
      "Epoch 4, Train Loss: 0.1119, Valid Loss: 0.0944\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1117, Valid Loss: 0.0917\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.63 seconds\n",
      "Epoch 4, Train Loss: 0.1410, Valid Loss: 0.1179\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Epoch 8, Train Loss: 0.1215, Valid Loss: 0.0997\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n",
      "Early stopping activated!\n",
      "Total training time: 4.43 seconds\n",
      "Epoch 4, Train Loss: 0.1210, Valid Loss: 0.0950\n",
      "Used Parameters: lstm_sizes=[64, 32], hidden_size=128, dropout_rate=0.3, learning_rate=0.01, batch_size=8, pos_weight=1\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools, AllChem\n",
    "from molvecgen.vectorizers import SmilesVectorizer\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import time  # Import time for timing the training process\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('small_molecules_smiles_only_for_deep_learning_sm_10032024.csv')\n",
    "PandasTools.AddMoleculeColumnToFrame(df, 'canon_smiles', 'Molecule')\n",
    "\n",
    "smivec = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec.fit(df.Molecule.values)\n",
    "\n",
    "y = df['good'].values.reshape((-1, 1)).astype(np.float32)\n",
    "X = df.Molecule.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "class SMILESMolDataset(Dataset):\n",
    "    def __init__(self, molecules, y, vectorizer):\n",
    "        self.molecules = molecules\n",
    "        self.y = y\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.molecules)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        mols = self.molecules[idx]\n",
    "        sample = self.vectorizer.transform([mols])[0]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        return sample, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dimensions, lstm_sizes, hidden_size, dropout_rate, out_size=1):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        number_tokens = dimensions[1]\n",
    "\n",
    "        self.lstms = nn.ModuleList()\n",
    "        input_size = number_tokens\n",
    "        for lstm_size in lstm_sizes:\n",
    "            self.lstms.append(nn.LSTM(input_size=input_size, hidden_size=lstm_size, num_layers=1, batch_first=True))\n",
    "            input_size = lstm_size\n",
    "\n",
    "        self.dropouts = nn.Dropout(dropout_rate) if len(lstm_sizes) > 1 else None\n",
    "        self.fc1 = nn.Linear(lstm_sizes[-1], hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for lstm in self.lstms:\n",
    "            x, _ = lstm(x)\n",
    "\n",
    "        if self.dropouts:\n",
    "            x = self.dropouts(x)\n",
    "\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define a custom estimator class for use with GridSearchCV\n",
    "\n",
    "class PyTorchClassifier(BaseEstimator):\n",
    "    def __init__(self, vectorizer, lstm_sizes, hidden_size, dropout_rate, learning_rate, batch_size, pos_weight, patience=10, min_delta=0.01):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.lstm_sizes = lstm_sizes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.pos_weight = pos_weight\n",
    "        self.model = None\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Prepare dataset\n",
    "        dataset = SMILESMolDataset(X, y, self.vectorizer)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Initialize model\n",
    "        self.model = Net(dims, self.lstm_sizes, self.hidden_size, self.dropout_rate).to(self.device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([self.pos_weight], device=self.device))\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(50):  # Total epochs set to 50\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for smiles, labels in train_loader:\n",
    "                smiles, labels = smiles.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(smiles)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Calculate training loss\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loader = torch.utils.data.DataLoader(dataset=SMILESMolDataset(X_val, y_val, self.vectorizer), \n",
    "                                                          batch_size=self.batch_size, \n",
    "                                                          shuffle=False)\n",
    "                val_running_loss = 0.0\n",
    "                for smiles, labels in val_loader:\n",
    "                    smiles, labels = smiles.to(self.device), labels.to(self.device)\n",
    "                    val_outputs = self.model(smiles)\n",
    "                    val_loss = criterion(val_outputs, labels)\n",
    "                    val_running_loss += val_loss.item()\n",
    "                valid_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "            # Print losses and parameters every 5 epochs\n",
    "            if (epoch + 1) % 4 == 0:\n",
    "                print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "                print(f'Used Parameters: lstm_sizes={self.lstm_sizes}, hidden_size={self.hidden_size}, '\n",
    "                      f'dropout_rate={self.dropout_rate}, learning_rate={self.learning_rate}, '\n",
    "                      f'batch_size={self.batch_size}, pos_weight={self.pos_weight}')\n",
    "\n",
    "            # Early stopping logic\n",
    "            if valid_loss < best_val_loss - self.min_delta:\n",
    "                best_val_loss = valid_loss\n",
    "                epochs_without_improvement = 0\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                if epochs_without_improvement >= self.patience:\n",
    "                    print(\"Early stopping activated!\")\n",
    "                    break\n",
    "\n",
    "        # Calculate total time\n",
    "        total_time = time.time() - start_time\n",
    "        print(f'Total training time: {total_time:.2f} seconds')\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(self.vectorizer.transform(X), dtype=torch.float32).to(self.device)\n",
    "            outputs = self.model(X_tensor)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            return (preds > 0.5).astype(int)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'vectorizer': self.vectorizer,\n",
    "            'lstm_sizes': self.lstm_sizes,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'batch_size': self.batch_size,\n",
    "            'pos_weight': self.pos_weight,\n",
    "            'patience': self.patience,\n",
    "            'min_delta': self.min_delta\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'lstm_sizes': [[32, 16], [64, 32], [64, 32, 16]],\n",
    "    'hidden_size': [32, 64, 128],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'learning_rate': [0.01, 0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [4, 8, 16],\n",
    "    'pos_weight': [1, 10, 100]\n",
    "}\n",
    "\n",
    "# Create a scorer for evaluation\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    return -np.mean(np.abs(y_true - y_pred))  # Custom scoring can be adjusted\n",
    "\n",
    "scorer = make_scorer(custom_scorer, greater_is_better=False)\n",
    "\n",
    "# Prepare the GridSearchCV\n",
    "# Assuming `smivec` is your vectorizer instance\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=PyTorchClassifier(\n",
    "        vectorizer=smivec,      # Pass the vectorizer here\n",
    "        lstm_sizes=[32, 16],    # Placeholder; will be overridden by grid search\n",
    "        hidden_size=64,         # Placeholder; will be overridden by grid search\n",
    "        dropout_rate=0.5,       # Placeholder; will be overridden by grid search\n",
    "        learning_rate=1e-4,     # Placeholder; will be overridden by grid search\n",
    "        batch_size=4,           # Placeholder; will be overridden by grid search\n",
    "        pos_weight=1            # Placeholder; will be overridden by grid search\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=3  # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict and evaluate on test set\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900ba05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
